<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Principles of Distributed Ledgers - Outline</title>
      <link href="2021/03/16/Principles%20of%20Distributed%20Ledgers%20-%20Syllabus/"/>
      <url>2021/03/16/Principles%20of%20Distributed%20Ledgers%20-%20Syllabus/</url>
      
        <content type="html"><![CDATA[<p>This is an outline of emerging technology in distributed ledgers. If you want to know more about one topic, please refer to associated article.</p><h2 id="lecture-1">Lecture 1</h2><h3 id="cryptographic">Cryptographic</h3><ul><li><p>Cryptographic Hash Functions: Properties</p></li><li><p>Merkle Trees</p></li><li><p>Elliptic Curve Signature Algorithm (ECDSA): Nothing in Bitcoin is encrypted</p></li></ul><h3 id="addresses">Addresses</h3><ul><li>BTC Address conversion</li></ul><h3 id="transactions">Transactions</h3><ul><li><p>UTXO (Unspent transaction output): In cryptocurrencies such as Bitcoin, an unspent transaction output (UTXO) is an abstraction of electronic money. Each UTXO is analogous to a coin, and holds a certain amount of value in its respective currency. Each UTXO represents a chain of ownership implemented as a chain of digital signatures where the owner signs a message (transaction) transferring ownership of their UTXO to the receiver's public key.</p></li><li><p>Coinbase Transaction: First transaction in a Block, deﬁned by the miner. No inputs required.</p></li></ul><h3 id="script">Script</h3><ul><li><p>Former UTXO: OP_DUP OP_HASH160 &lt;PubKeyHash&gt; OP_EQUALVERIFY OP_CHECKSIG</p></li><li><p>Latter UTXO: &lt;Sig&gt; &lt;PubKey&gt;</p></li><li><p>If evals to true <span class="math inline">\(\rightarrow\)</span> Bitcoin transaction is valid</p></li><li><p>Execution time is critical to prevent DoS attacks</p></li><li><p>Transaction types: P2PKH; P2SH; Multisignature (m from n)</p></li></ul><h3 id="wallet">Wallet</h3><h3 id="chain-of-blocks">Chain of Blocks</h3><ul><li>Header: Block version; Hash of previous block's header; Merkle root; Unix time; Target; Nonce</li></ul><h3 id="lightweight-clients">Lightweight Clients</h3><ul><li>SPV Transaction veriﬁcation: Blockchain with headers only</li></ul><h2 id="lecture-2">Lecture 2</h2><h3 id="proof-of-work">Proof of Work</h3><ul><li><p>Find Nonce <span class="math inline">\(N\)</span>, s.t. Hash(Hash(<span class="math inline">\(B_{\rm former}\)</span>)|merkle root|<span class="math inline">\(N\)</span>) <span class="math inline">\(&lt;\)</span> target</p></li><li><p>Pool: Give proportional reward (pool's difficulty &lt; Bitcoin's difficulty)</p></li></ul><h3 id="merged-mining">Merged Mining</h3><ul><li><p>Assembles a transaction set for both block chains</p></li><li><p>Hash the final namecoin block</p></li><li><p>Creates a transaction containing this hash and inserts it in the Bitcoin transaction set at the tip of the tree (scriptSig)</p></li><li><p>Assembles the final Bitcoin header with this transaction in it and sends out the work units</p></li></ul><h3 id="mining-pool-dangers">Mining Pool Dangers</h3><ul><li><p>Influence which transactions enter the blockchain</p></li><li><p>Inﬂate transaction fees/Ethereum gas price</p></li><li><p>Collude with each other (to reach 51%, selfish mining)</p></li><li><p>Network layer attacks</p></li><li><p>Political and Regulatory danger</p></li><li><p>Pool operators are trusted to pay out reward</p></li><li><p>Influence voting mechanisms (cf. SegWit)</p></li></ul><h3 id="decentralised-mining">Decentralised Mining</h3><ul><li><p>Each block of the share chain is a share</p></li><li><p>Each share chain block has a lower difficulty than the bitcoin block chain</p></li><li><p>Once a share satisﬁes the same difficulty as Bitcoin, it's a valid Bitcoin block</p></li><li><p>Coinbase transaction is used for reward and tracking of share chain</p></li></ul><h3 id="forks">Forks</h3><ul><li><p><span class="math inline">\(\mathcal{P}\)</span>: protocol; <span class="math inline">\(\mathcal{V}\)</span>: Validity set; <span class="math inline">\(\mathcal{N}\)</span>: difference between <span class="math inline">\(\mathcal{V}\)</span> and <span class="math inline">\(\mathcal{V}^{\prime}\)</span></p></li><li><p>Hard fork: Previously invalid blocks/transactions are make valid (and vice-versa)</p></li><li><p>Soft fork: Only previously valid blocks/transactions are made invalid <span class="math inline">\(\rightarrow\)</span> reducing functionality</p></li><li><p>Segregated Witness</p></li><li><p>Vote through blocks</p></li></ul><h3 id="proof-of-stakesauthority">Proof of Stakes/Authority</h3><h2 id="lecture-3">Lecture 3</h2><h3 id="bitcoin-and-smart-contracts">Bitcoin and Smart Contracts</h3><ul><li><p>Bitcoin Script: No support for loops</p></li><li><p>Bitcoin Script Applications: Proof of Burn; Multisignature addresses; Pay-for-hash pre-image; Micropayment channels</p></li></ul><h3 id="namecoin">Namecoin</h3><h3 id="introduction-to-ethereum">Introduction to Ethereum</h3><ul><li>Account Based model: No need to go through whole history; Sequence between any two blocks can be verified; Light clients can sync up quickly</li></ul><h3 id="ethereum-blockchain-structure">Ethereum Blockchain Structure</h3><ul><li><p>Ethereum Blockchain Structure</p></li><li><p>Ethereum Merkle Patricia Tree</p></li></ul><h3 id="ethereum-accounts-and-transactions">Ethereum Accounts and Transactions</h3><ul><li>Types of transactions: send; create; call</li></ul><h3 id="ethereum-virtual-machine">Ethereum Virtual Machine</h3><ul><li><p>Stack of max depth of 1024</p></li><li><p>Memory is zero initialized</p></li><li><p>Storage is very expensive (The cost of storing 1 kb is currently 6.4 USD)</p></li></ul><h3 id="ethereum-transaction-fees">Ethereum Transaction Fees</h3><ul><li><p>Each opcode of the EVM has a certain gas cost</p></li><li><p>Maximum GAS_LIMIT per block</p></li><li><p>If GAS_LIMIT <span class="math inline">\(\times\)</span> GAS_PRICE &gt; accounts[from].balance, halt execution abruptly</p><ul><li><p>accounts[from].balance -= value + gas <span class="math inline">\(\times\)</span> gasprice</p></li><li><p>accounts[to].balance += value</p></li><li><p>execute(code)</p></li><li><p>accounts[from] += unusedGas <span class="math inline">\(\times\)</span> gasprice</p></li></ul></li><li><p>If remaining GAS is 0 before termination, throw out-of-gas, and pay miners</p></li></ul><h3 id="solidity">Solidity</h3><h2 id="lecture-4">Lecture 4</h2><h3 id="classical-consensus">Classical Consensus</h3><ul><li><p>In a fully asynchronous system, there is no deterministic consensus solution that tolerates one or more failures</p></li><li><p>No algorithm can always reach consensus in bounded time</p></li></ul><h3 id="blockchain-bootstrapping">Blockchain Bootstrapping</h3><ul><li><p>Bootstrap Methods: DNS (Domain Name System) Bootstrap; Hardcoded IPs; Chat/Forums (dangerous)</p></li><li><p>Bitcoin Node: TCP based, no authentication/encryption</p></li></ul><h3 id="network-denial-of-service-protection">Network Denial of Service Protection</h3><ul><li><p>DoS Protection Mechanism: Sanity checks (size, encoding); Signature validation; UTXO/double spending validation</p></li><li><p>DoS Protection Mechanism is a weakness (directly ban IP)</p></li></ul><h3 id="network-gossip-protocol">Network Gossip Protocol</h3><ul><li><p>Standard Transaction/Block advertisement: Hash (36 bytes); Get request; Block</p></li><li><p>Send Headers Block advertisement: Header (80 bytes); Get request; Block</p></li><li><p>Unsolicited Block Push: Block</p></li><li><p>Bitcoin Fibre: Block sketch; Construct; Correct error; Emit (UDP based)</p></li></ul><h3 id="network-security---eclipse-attacks">Network Security - Eclipse Attacks</h3><ul><li><p>Request timeouts: block: 20 min; transaction: 2 min</p></li><li><p>Blind victim &gt; 20 min: Double spending; Aggravated selfish mining; Network wide DoS</p></li><li><p>Being first: connections of adversary:victim <span class="math inline">\(=800:40\)</span>, approximately 90%</p></li><li><p>Transactions follow FIFO while Blocks don't</p></li></ul><h3 id="eclipse-attacks---delaying-blocks">Eclipse Attacks - Delaying Blocks</h3><ul><li><p>Occupy all open connections: not receive block header and version message</p></li><li><p>Different blocks timeout are independent</p></li></ul><h3 id="eclipse-attacks---double-spending">Eclipse Attacks - Double Spending</h3><ul><li><p>Double Spending 0 Confirmation Transactions: Very reliable attack</p></li><li><p>Double Spending 1 Confirmation Transactions: Collude with miners</p></li></ul><h3 id="eclipse-attacks---denial-of-service">Eclipse Attacks - Denial of Service</h3><ul><li><p>6000 reachable Bitcoin nodes</p></li><li><p>450,000 TCP connections required</p></li></ul><h3 id="eclipse-attacks---hardening-the-p2p-layer">Eclipse Attacks - Hardening the P2P Layer</h3><ul><li><p>Dynamic timeouts</p></li><li><p>Handling Transaction Advertisements: filter IP; randomly choose sender</p></li><li><p>Updating Block Advertisements: broadcast header instead of hash (so that PoW can be verified)</p></li><li><p>After 5 minutes, transaction is received, even if the adversary controls 95% of the inv</p></li></ul><h3 id="selﬁsh-mining-and-eclipse-attacks">Selﬁsh Mining and Eclipse Attacks</h3><ul><li><p>Instead of publishing, keep a block private</p></li><li><p>Other miners will perform wasteful computations</p></li><li><p>Combine with denying block <span class="math inline">\(\rightarrow\)</span> higher pool revenue</p></li></ul><h2 id="lecture-5">Lecture 5</h2><h3 id="blockchain-security">Blockchain Security</h3><ul><li>Multi-layer: Hardware; Network; Blockchain; Programming Language; Application</li></ul><h3 id="smart-contract-security">Smart Contract Security</h3><ul><li><p>Reentrancy: redefine payable() to call the withdraw repeatedly</p></li><li><p>Unprivileged write to storage: user may change the wallet's owner</p></li><li><p>Automated Security Analysis: Testing | Dynamic analysis; Symbolic execution | Static analysis; Formal verification</p></li></ul><h3 id="smart-contract-bug">Smart Contract Bug</h3><ul><li><p>Any variable is readable on the public Ethereum blockchain. Declaring a variable private only restricts the automatic creation of getter for that variable, but does not hide it</p></li><li><p>Balance should be changed before a transfer is made (to prevent reentrancy attack)</p></li></ul><h3 id="decentralized-autonomous-organization">Decentralized Autonomous Organization</h3><h3 id="comparing-quantitatively-layer-1-security">Comparing Quantitatively Layer 1 Security</h3><ul><li><p>Faster block generation <span class="math inline">\(\rightarrow\)</span> Faster payments (less security)</p></li><li><p>Bigger block size <span class="math inline">\(\rightarrow\)</span> More throughput/Slower propagation (less security)</p></li></ul><h3 id="modeling-a-blockchain-in-an-mdp">Modeling a Blockchain in an MDP</h3><h3 id="quantifying-security-with-an-mdp">Quantifying Security with an MDP</h3><ul><li>Double-Spending Threshold: transaction value, below which the optimal strategy is honest mining, above which the optimal strategy is double-spending attack</li></ul><h3 id="selﬁsh-mining-and-the-stale-block-rate">Selﬁsh Mining and the Stale Block Rate</h3><ul><li><p>The higher the stale block rate the higher the relative revenue of selfish mining</p></li><li><p>Selfish Mining yields fewer block rewards than honest mining under constant difficulty</p></li></ul><h3 id="blockchain-network-simulator">Blockchain Network Simulator</h3><ul><li><p>1 MB blocks, 1 min Block interval <span class="math inline">\(\rightarrow\)</span> No stale block rate increase</p></li><li><p>Drawbacks: TCP protocol (no congestion)</p></li></ul><h3 id="bitcoin-ng">Bitcoin-NG</h3><ul><li><p>The key block miner is the one mining the microblocks</p></li><li><p>60% <span class="math inline">\(\rightarrow\)</span> latter, 40% <span class="math inline">\(\rightarrow\)</span> former</p></li></ul><h2 id="lecture-6">Lecture 6</h2><h3 id="blockchain-scaling">Blockchain Scaling</h3><ul><li><p>Off Chain Transaction: Transaction outside the blockchain, secured by the blockchain</p></li><li><p>No consensus latency or mining fees, while still achieving non-custodial security</p></li><li><p>Backward compatibility</p></li></ul><h3 id="channel-networks">Channel Networks</h3><h3 id="channel-networks-state-replacement">Channel Networks State Replacement</h3><ul><li><p>Time Lock State Replacement: T=100,99,98,<span class="math inline">\(\cdots\)</span>, expiry</p></li><li><p>Revocation State Replacement: Agree on last state, keep all previous revoked states</p></li><li><p>State Replacement Techniques (2016+): State change, everyone signs</p></li></ul><h3 id="channel-networks-htlc">Channel Networks HTLC</h3><ul><li><p>Humble Conditional Transfer</p></li><li><p>Path-based Payments (HTLC): synchronise a payment among peers on the path</p></li><li><p>Path-based virtual Payment Channels (Perun): set up a virtual channel to avoid intermediary peers to be responsive</p></li></ul><h3 id="channel-networks-routing">Channel Networks Routing</h3><ul><li><p>Routing Properties: scalable; effective; efficient</p></li><li><p>Routing Approaches: Source-routing; Per-hop routing</p></li><li><p>Privacy: Value-Privacy; Transfer-Privacy</p></li></ul><h3 id="channel-networks-summary">Channel Networks Summary</h3><h3 id="channel-networks-trusted-execution-environments">Channel Networks Trusted Execution Environments</h3><ul><li><p>TEEs: Efficient and fast payments among peers</p></li><li><p>Privacy: Intermediary nodes are not visible outside the enclave</p></li><li><p>Offline Payments: Peers can remain offline!</p></li><li><p>Examples: Teechan, Teechain</p></li></ul><h3 id="payment-channel-hubs">Payment Channel Hubs</h3><ul><li>Payment Channel Hubs are great for instant ﬁnality and no trust. But expensive to run.</li></ul><h3 id="commit-chains">Commit-Chains</h3><ul><li><p>Off the chain transactions: Like on-chain transactions!</p></li><li><p>Constant-size checkpoint</p></li><li><p>Without Collateral: Eventual Finality</p></li><li><p>With Collateral: Instant Finality!</p></li><li><p>Join without on-chain Transaction</p></li><li><p>but a centralized Operator!</p></li></ul><h3 id="commit-chains-plasma-cash">Commit-Chains Plasma Cash</h3><ul><li><p>Non-Fungible Coins</p></li><li><p>Merkle Tree: Every leaf is a coin</p></li></ul><h3 id="commit-chains-nocust">Commit-Chains NOCUST</h3><ul><li><p>Deposit a coin: Balance credit in a Merkle Tree</p></li><li><p>ZKP: User can directly challenge through Smart Contract</p></li></ul><h3 id="commit-chains-nocust-security">Commit-Chains NOCUST Security</h3><ul><li><p>NOCUST server disappears: on-chain transactions are safe; use insurance pool to recover off-chain transactions</p></li><li><p>Users to attempt double-spending: central operator will reject</p></li><li><p>NOCUST server colludes with client to attempt double-spending (create or steal): Operator is challenged!</p></li></ul><h3 id="commit-chains-summary">Commit-Chains Summary</h3><h2 id="lecture-7">Lecture 7</h2><h3 id="blockchain-privacy">Blockchain Privacy</h3><ul><li>Blockchain Privacy is a Multilayer Challenge</li></ul><h3 id="blockchain-privacy-ethical-concerns">Blockchain Privacy Ethical Concerns</h3><h3 id="blockchain-privacy-network-layer">Blockchain Privacy Network Layer</h3><ul><li><p>Peer to Peer Network: Validating nodes / Lightweight clients / Miner</p></li><li><p>Network Privacy Leakages: IP; Client version; Port scan</p></li></ul><h3 id="blockchain-privacy-transaction-layer">Blockchain Privacy Transaction Layer</h3><ul><li><p>Change Address:If new, then likely a change address</p></li><li><p>Multi-input Transactions: All inputs can be signed by the same entity</p></li></ul><h3 id="blockchain-privacy-native-privacy-blockchain">Blockchain Privacy Native Privacy Blockchain</h3><ul><li><p>ZCash: Transparent Transactions/Shielded Transactions</p></li><li><p>Monero; CoinJoin: Stealth Addresses</p></li></ul><h3 id="blockchain-privacy-stealth-addresses">Blockchain Privacy Stealth Addresses</h3><ul><li><p>Hierarchical Deterministic (HD) Wallets: Addresses derived from the same key; From one address cannot derive the other addresses</p></li><li><p>Adversary can't see where this transaction is paid to, but port scanner can</p></li><li><p>Dark wallet</p></li></ul><h3 id="blockchain-privacy-ring-signatures">Blockchain Privacy Ring Signatures</h3><h3 id="blockchain-privacy-add-onmixer-privacy">Blockchain Privacy Add-on/Mixer Privacy</h3><ul><li><p>Coinjoin</p></li><li><p>Tornado Cash/Miximus/MicroMix</p></li></ul><h3 id="blockchain-privacy-lightweight-clients">Blockchain Privacy Lightweight Clients</h3><ul><li><p>Private Information Retrieval</p></li><li><p>Bloom Filter</p></li><li><p>TEEs</p></li></ul><h3 id="blockchain-privacy-bloom-filter-spv">Blockchain Privacy Bloom Filter &amp; SPV</h3><ul><li><p>Stair stepping: actual FPR <span class="math inline">\(\leq\)</span> target FPR</p></li><li><p>Resizing/Restarting: different FP <span class="math inline">\(\rightarrow\)</span> intersection</p></li><li><p>Multiple Bloom ﬁlters</p><ul><li><p>Same seed; Same size: no change</p></li><li><p>Same seed; Resize: improves the attack</p></li><li><p>Restart; Same Size: improves the attack</p></li><li><p>Restart; Resize: totally leaks</p></li></ul></li><li><p>Solution</p><ul><li><p>Pre-generate Bitcoin addresses and insert into ﬁlter</p></li><li><p>Keep state about outsourced Bloom ﬁlter</p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed Ledgers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Garbled Circuits</title>
      <link href="2020/11/16/Garbled%20Circuits/"/>
      <url>2020/11/16/Garbled%20Circuits/</url>
      
        <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2><ul><li>Gabled circuits express the function to be computed as an “encrypted” boolean circuit, e.g. with ANDs, ORs, XORs, etc</li><li>Garbled circuits are more efficient than for 2-party joint processing setups. They get too complex for more parties.</li><li>In this post, we will look at <strong>Yao's Garbled Circuits</strong></li></ul><p>Given two parties computations, Alice and Bob, they want to compute a function <span class="math inline">\(f(x,y)\)</span> where <span class="math inline">\(x\)</span> is Alice's input and <span class="math inline">\(y\)</span> is Bob's input. After the computation, <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> remain private unless revealed by the function <span class="math inline">\(f\)</span>.</p><h2 id="one-gate-garbled-circuit">One Gate Garbled Circuit</h2><p>WLOG, we consider a <span class="math inline">\(\text{AND}\)</span> gate in this section, i.e., <span class="math inline">\(f(x,y)=x\land y\)</span>. Alice will be the circuit garbler, and Bob will be the circuit evaluator. Denote the input bit of Alice and Bob as <span class="math inline">\(a,b\)</span>.</p><h3 id="step-by-step">Step by step</h3><ol type="1"><li>Alice compiles <span class="math inline">\(f\)</span>. into an acyclic boolean circuit, composed of logic gates like AND, OR, XOR etc.</li><li>Alice generates random keys <span class="math inline">\(k[A,0]\)</span>, <span class="math inline">\(k[A,1]\)</span>, <span class="math inline">\(k[B,0]\)</span>, <span class="math inline">\(k[B,1]\)</span>, <span class="math inline">\(k[C,0]\)</span>, <span class="math inline">\(k[C,1]\)</span>, each of which corresponds to a bit of a wire.<ul><li>For example, <span class="math inline">\(k[A,0]\)</span> for wire A, bit <span class="math inline">\(0\)</span>; <span class="math inline">\(k[C,1]\)</span> for wire C, bit <span class="math inline">\(1\)</span></li></ul></li><li>Alice garbles the circuit to produce a garbled circuit, essentially each gate will carry out its operation on encrypted input bits producing an encrypted output bit.<ul><li>For example, the AND garbled truth table entry for wire A input <span class="math inline">\(1\)</span> and wire B input <span class="math inline">\(0\)</span>, is key <span class="math inline">\(k[C,0]\)</span> doubly-encrypted by <span class="math inline">\(k[A,1]\)</span> and <span class="math inline">\(k[B,0]\)</span> <span class="math display">\[\text{GT}[1,0]=E_{k[A,1],k[B,0]}(k[C,\text{AND}(1,0)])=E_{k[A,1],k[B,0]}(k[C,0])\]</span></li></ul></li><li>Alice randomly permutates the the entries of the Garbled Table, since the truth-table order will leak information that could be used to learn Alice’s input.</li><li>Alice sends the permutated garbled gate table plus the encrypted bits for its input and a decryption mapping table that allows Bob to map the encrypted output of the circuit to its plaintext.<ul><li>For example, if <span class="math inline">\(a=1\)</span>, Alice will send <span class="math inline">\(k[A,1]\)</span> to Bob. Bob won't know the value of <span class="math inline">\(a\)</span> since all wire keys are random</li><li>The mapping should be <span class="math inline">\(k[C,0]\Rightarrow0\)</span>,<span class="math inline">\(k[C,1]\Rightarrow1\)</span></li></ul></li><li>Bob runs a 1-from-2 <em>oblivious transfer</em> (OT) protocol with Alice for Bob input bits. Bob will get the keys that corresponds to <span class="math inline">\(b\)</span> from Alice without Alice learning <span class="math inline">\(b\)</span>.<ul><li>For example, if <span class="math inline">\(b=1\)</span>, Bob will get <span class="math inline">\(k[B,1]\)</span>. Bob won't know <span class="math inline">\(k[B,0]\)</span> and Alice won't know <span class="math inline">\(b=1\)</span>.</li></ul></li><li>Bob doubly decrypts the garbled gate entry to learn the final encrypted result <span class="math inline">\(k[C,\text{AND}(a,b)]\)</span> and uses the decryption mapping table to map <span class="math inline">\(k[C,\text{AND}(a,b)]\)</span> to its plaintext bit <span class="math inline">\(\text{AND}(a,b)\)</span>. Bob sends this to Alice.</li></ol><h2 id="from-2-oblivious-transfer-protocol">1-from-2 Oblivious Transfer protocol</h2><p>Here is an illustrative example for 1-from-2 OT. There are many others protocols. What's more, 1-from-2 OT can be extended to k-from-n OT. WLOG, we assume that Alice has two messages <span class="math inline">\(m_1,m_2\)</span> and Bob wants to know <span class="math inline">\(m_1\)</span>.</p><h3 id="step-by-step-1">Step by step</h3><ol type="1"><li>Alice has two messages <span class="math inline">\(m_1,m_2\)</span></li><li>Alice generates two public-private key pairs <span class="math inline">\(\text{(Pub1,Priv1)}\)</span>, <span class="math inline">\(\text{(Pub2,Priv2)}\)</span>.</li><li>Alice <span class="math inline">\(\rightarrow\)</span> Bob: <span class="math inline">\(\text{Pub1,Pub2}\)</span></li><li>Bob generates a symmetric key <span class="math inline">\(k\)</span> and chooses <span class="math inline">\(\text{Pub1}\)</span>.</li><li>Bob <span class="math inline">\(\rightarrow\)</span> Alice: <span class="math inline">\(c=E_{\text{Pub1}}(k)\)</span></li><li>Alice does <span class="math inline">\(D_{\text{Priv1}}(c)=k\)</span>, <span class="math inline">\(D_{\text{Priv2}}(c)=u\neq k\)</span></li><li>Alice <span class="math inline">\(\rightarrow\)</span> Bob: <span class="math inline">\(c_1=E_k(m_1)\)</span>, <span class="math inline">\(c_2=E_u(m_2)\)</span></li><li>Bob does <span class="math inline">\(D_k(c_1)=D_k(E_k(m_1))=m_1\)</span> and <span class="math inline">\(D_k(c_2)=D_k(E_u(m_2))=\text{non sense}\)</span></li></ol><h3 id="conclusion">Conclusion</h3><ul><li>Bob learns <span class="math inline">\(m_1\)</span> in this example.</li><li>Alice doesn't know which message Bob knows.</li><li>Alice's messages need to have a structure that Bob can recognise to distinguish the good message <span class="math inline">\(m_1\)</span> from the gibberish message.</li></ul><h2 id="point-and-permutate-p-bit">Point-and-Permutate p-bit</h2><p>In the Step 7, Bob doubly decrypts the garbled gate entry to learn the final encrypted result. Bob could decrypt each entry if the underlying encryption method makes it obvious when decrypting which is the “correct” ciphertext. This is both inefficient and inelegant. The following trick is to pair a random <strong>point-and-permutate</strong> bit and its inverse to each of the keys of the wire (the <span class="math inline">\(0\)</span> key and <span class="math inline">\(1\)</span> key).</p><p>For example, if wire A has keys <span class="math inline">\(k[A,0],k[A,1]\)</span>, we would now have <span class="math inline">\((k[A,0],\text{pA})\)</span>, <span class="math inline">\((k[A,1],\text{not pA})\)</span>.</p><p>Here is the equivalent pseudo-code to show how Alice generates the <strong>point-and-permutate</strong> garbled table.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> each permutated PGT <span class="keyword">with</span> <span class="built_in">input</span> wires A, B <span class="keyword">and</span> output wire C</span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> [<span class="number">0</span>,<span class="number">1</span>] <span class="keyword">for</span> b <span class="keyword">in</span> [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">        x = a xor pbit[A]</span><br><span class="line">        y = b xor pbit[B]</span><br><span class="line">        z = GATE(x,y) <span class="comment"># e.g. AND, OR, XOR, NAND ...</span></span><br><span class="line">        k[C,z] = GATE(k[A,x], k[B,y])</span><br><span class="line">        zl = z xor pbit[C]</span><br><span class="line">        PGT[a][b] = E[k[A,x], k[B,y]](k[C,z], zl) <span class="comment"># double encrypt</span></span><br></pre></td></tr></table></figure><p>In Step 5, Alice sends both the encrypted bits and the pbit for its input. In Step 6, Bob obtains both his key and the pbit of his key by running OT. As a result, Bob learns <span class="math inline">\(k[A,a], \text{pA or not pA}\)</span> and <span class="math inline">\(k[B,b], \text{pB or not pB}\)</span>. Then Bob can directly doubly decrypts <span class="math inline">\(\text{PGT[pA][pB]}\)</span> to learn <span class="math inline">\(k[C,z], z^{\prime}\)</span>.</p><h3 id="example">Example</h3>For <span class="math inline">\(a=0,\text{pA}=1,b=1,\text{pB}=0\)</span><style>    th {        display: none;    }</style><center><table><tbody><tr class="odd"><td><span class="math inline">\(\text{PGT[1][1]}\)</span></td><td><span class="math inline">\(E_{k[A,0],k[B,1]}(k[C,0],0)\)</span></td></tr><tr class="even"><td><span class="math inline">\(\text{PGT[1][0]}\)</span></td><td><span class="math inline">\(E_{k[A,0],k[B,0]}(k[C,0],0)\)</span></td></tr><tr class="odd"><td><span class="math inline">\(\text{PGT[0][1]}\)</span></td><td><span class="math inline">\(E_{k[A,1],k[B,1]}(k[C,1],1)\)</span></td></tr><tr class="even"><td><span class="math inline">\(\text{PGT[0][0]}\)</span></td><td><span class="math inline">\(E_{k[A,1],k[B,0]}(k[C,0],0)\)</span></td></tr></tbody></table></center><p>Bob learns <span class="math inline">\(k[A,0],1\)</span> and <span class="math inline">\(k[B,1],1\)</span>. He locates and doubly decrypts <span class="math inline">\(\text{PGT[1,1]}\)</span> with <span class="math inline">\(k[A,0],k[B,1]\)</span> to learn <span class="math inline">\(k[C,0], 0\)</span>. Finally, he uses the decryption mapping table to map <span class="math inline">\(k[C,0]\)</span> to its plaintext <span class="math inline">\(0\)</span>.</p><h2 id="garbled-circuit-performance">Garbled circuit performance</h2><ul><li>Runs in a constant number of rounds.</li><li>Computation cost dominated by encryption function used. Typically hardware-assisted AES is used.</li><li>High communication costs - time to transfer circuit, plus time to complete oblivious transfers (later can be done in parallel).</li><li>Both Alice and Bob could cheat at various stages. Techniques such as zero-knowledge proofs and cut-and-choose can be used but have high overheads.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Privacy Engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Shamir Secret Sharing and BGW Protocol</title>
      <link href="2020/11/09/Shamir%20Secret%20Sharing%20and%20BGW%20Protocol/"/>
      <url>2020/11/09/Shamir%20Secret%20Sharing%20and%20BGW%20Protocol/</url>
      
        <content type="html"><![CDATA[<h2 id="mpc-multi-party-computation">MPC (Multi-party Computation)</h2><h3 id="definition">Definition</h3><p>Given <span class="math inline">\(n\)</span> parties, design a protocol which computes a public function <span class="math inline">\(f\)</span> over inputs from each party such that the inputs remain private unless they would be revealed by the function anyway.</p><h3 id="character">Character</h3><ul><li>Typically, all parties will receive the <strong>same</strong> output when the calculation finishes</li><li>MPC is typically considered when parties don’t trust either the others or a 3rd party</li><li>An MPC protocol can be shown equivalent to a protocol uses a trusted 3rd party</li></ul><p>There are many setups that can be used for MPC. However, in this post, we'll only take a look at <em>Secret Sharing</em> and its application <em>BGW protocol</em>.</p><h3 id="adversarial-models">Adversarial Models</h3><ul><li><strong>Honest-but-curious, Semi-Honest, Passive</strong>: Parties follow protocol, but are interested (i.e. curious) in breaking privacy of other parties. Also know as <strong>corrupt</strong> parties.</li><li><strong>Malicious, Byzantine, Active</strong>: Parties can deviate from the protocol e.g. lie about inputs, quit protocol early.</li></ul><h3 id="secure-type">Secure Type</h3><ul><li><strong>Information theoretically secure</strong>: system cannot be broken even if adversary has unlimited computational power. Also known as <strong>Perfect security</strong> and <strong>Unconditional security</strong>.</li><li><strong>Computationally secure</strong>: adversary would require an unreasonably large amount of computational power to break the system.</li></ul><h3 id="theoretical-limit-of-adversary-and-security">Theoretical Limit of Adversary and Security</h3><ul><li>Honest-but-curious adversary, Information theoretically secure: tolerate up to <span class="math inline">\(n/2\)</span> corrupt parties</li><li>Honest-but-curious adversary, Computationally secure: tolerate up to <span class="math inline">\(n-1\)</span> corrupt parties</li><li>Malicious adversary, Information theoretically secure: tolerate up to <span class="math inline">\(n/3\)</span> adversaries</li><li>Malicious adversary, Computationally secure: tolerate up to <span class="math inline">\(n/2\)</span> adversaries (unfair/un-robust protocol can tolerate up to <span class="math inline">\(n-1\)</span> adversaries)</li></ul><h2 id="lagrange-interpolation">Lagrange Interpolation</h2><h3 id="distribution-and-recombination">Distribution and Recombination</h3><ul><li>A polynomial <span class="math inline">\(P(x)\)</span> of degree <span class="math inline">\(T\)</span> can be uniquely determined by a set of <span class="math inline">\(T + 1\)</span> (or more) distinct points on the polynomial curve <span class="math inline">\(P(x)\)</span>.</li><li>A polynominal <span class="math inline">\(P(x)\)</span> of degree upto at most <span class="math inline">\(N − 1\)</span> there exist coefficients <span class="math inline">\(r = (r_1,\cdots,r_N )\)</span> (called the <em>recombination vector</em>) such that:</li></ul><p><span class="math display">\[P(0)=\sum_{i=1}^Nr_iP(i)\]</span></p><h3 id="lagrange-interpolation-1">Lagrange Interpolation</h3><p>Given <span class="math inline">\(T\)</span> points <span class="math inline">\((x_1,P(x_1)),\cdots,(x_n,P(x_n))\)</span>, the <strong>unique</strong> Lagrange Interpolation Polynomial of degree T is:</p><p><span class="math display">\[P(x)=\sum_{i=1}^{T+1}\delta_i(x)P(x_i),~\delta_i(x)=\prod_{j=1,j\neq i}^{T+1}\frac{x-x_j}{x_i-x_j}\]</span></p><p>We also have:</p><p><span class="math display">\[P(0)=\sum_{i=1}^{T+1}\delta_i(0)P(x_i)=\sum_{i=1}^{T+1}r_iP(x_i)\Rightarrow r_i=\prod_{j=1,j\neq i}^{T+1}\frac{x_j}{x_j-x_i}\]</span></p><p>And when <span class="math inline">\(x_i=i\)</span>:</p><p><span class="math display">\[r_i=\prod_{j=1,j\neq i}^{T+1}\frac{j}{j-i}\]</span></p><h3 id="secret-share">Secret Share</h3><p>You may have already noticed that <em>Lagrange Interpolation</em> can be used to share(split) secret. For example, if someone have a secret <span class="math inline">\(a_0\)</span>, and he randomly choose coefficients <span class="math inline">\(a_1,\cdots,a_T\)</span>, we obtain a polynomial <span class="math inline">\(P(x)=a_0+\sum_{i=1}^Ta_ix^i\)</span>. And if he sends <em>shares</em> <span class="math inline">\(P(1),\cdots,P(N)\)</span> to <span class="math inline">\(N\)</span> parties, then the only way to recover the secret is perform <em>recombination</em> on at least <span class="math inline">\(T+1\)</span> <em>shares</em> (from at least <span class="math inline">\(T+1\)</span> parties).</p><h2 id="bgw-protocol">BGW Protocol</h2><p>From the definition of MPC, we need to calculate a public function <span class="math inline">\(f\)</span>. For convenience, we consider <span class="math inline">\(f:\mathcal{N^*}\rightarrow\mathcal{N}\)</span> which is a polynomial over a finite field modulo a prime <span class="math inline">\(p\)</span>. Thus, we can only consider two gates(operations): <strong>Add</strong>(addition) and <strong>Mul</strong>(multiplication). In this post, we'll only take a look at the honest-but-curious version.</p><blockquote><p>Arithmetic over a finite field rules out the possibility of 'guessing' the secret. It makes us impossible to determine the range of the secret with less than <span class="math inline">\(T+1\)</span> shares. See <a href="https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing">wikipedia</a> for more details.</p></blockquote><p>We will look at a three-party example. Three parties are <span class="math inline">\((p_1,p_2,p_3)\)</span> and their secrets(private values) are <span class="math inline">\((x_1,x_2,x_3)=(10,20,30)\)</span>. They want to calculate <span class="math inline">\((x_1+x_2)\times x_3\)</span>. They choose prime <span class="math inline">\(p=101\)</span> and degree <span class="math inline">\(T=1\)</span>. We also need <span class="math inline">\(2T\leq N-1\)</span>, the reason of which is lied in the <strong>Mul</strong> gate.</p><h3 id="distribution">Distribution</h3><p>At first, each party needs to distribute it secret into <span class="math inline">\(N\)</span> shares and send them to <span class="math inline">\(N\)</span> parties (also include saving his own share).</p><ul><li>For <span class="math inline">\(p_1\)</span>, he chooses polynomial <span class="math inline">\(3x+10\)</span>, and the shares are <span class="math inline">\(13, 16, 19\)</span>.</li><li>For <span class="math inline">\(p_2\)</span>, he chooses polynomial <span class="math inline">\(2x+20\)</span>, and the shares are <span class="math inline">\(22, 24, 26\)</span>.</li><li>For <span class="math inline">\(p_3\)</span>, he chooses polynomial <span class="math inline">\(1x+30\)</span>, and the shares are <span class="math inline">\(31, 32, 33\)</span>.</li></ul><p>After distribution</p><ul><li><span class="math inline">\(p_1\)</span> has shares <span class="math inline">\(13,22,31\)</span></li><li><span class="math inline">\(p_2\)</span> has shares <span class="math inline">\(16,24,32\)</span></li><li><span class="math inline">\(p_3\)</span> has shares <span class="math inline">\(19,26,33\)</span></li></ul><h3 id="add-gate">Add Gate</h3><p>Suppose we have two secrets <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> which are shared using the polynomials: <span class="math display">\[f(x)=a+f_1x+\cdots,f_tx^T,g(x)=b+g_1x+\cdots,g_tx^T\]</span> Each of our parties has a share <span class="math inline">\(a^{(i)}=f(i)\)</span> and <span class="math inline">\(b^{(i)}=g(i)\)</span>. Now consider the polynomial: <span class="math display">\[h(x)=f(x)+g(x)\]</span> This polynomial provides a sharing of the sum <span class="math inline">\(c = a + b\)</span>, and we have <span class="math display">\[c^{(i)}=h(i)=f(i)+g(i)=a^{(i)}+b^{(i)}\]</span></p><p>Let's go into the example. We want to calculate <span class="math inline">\(x_1+x_2\)</span> first. And for each party, he needs to add the share from <span class="math inline">\(p_1\)</span> and the share from <span class="math inline">\(p_2\)</span>.</p><ul><li><span class="math inline">\(p_1\)</span> calculates <span class="math inline">\(a^{(1)}+b^{(1)}=13+22=35\)</span></li><li><span class="math inline">\(p_2\)</span> calculates <span class="math inline">\(a^{(2)}+b^{(2)}=16+24=40\)</span></li><li><span class="math inline">\(p_3\)</span> calculates <span class="math inline">\(a^{(3)}+b^{(3)}=19+26=45\)</span></li></ul><p>And you can see if we combine these values together by using the <em>recombination vector</em>, we have <span class="math inline">\([3,-3,1][35,40,45]^\top=30\)</span>, which equals to the 'true' value <span class="math inline">\(x_1+x_2=30\)</span>.</p><h3 id="multiplication-gate">Multiplication Gate</h3><p>To compute the Multiplication gate we perform the following four steps:</p><ul><li>Each party <span class="math inline">\(i\)</span> locally computes <span class="math inline">\(d^{(i)}=a^{(i)}\times b^{(i)}\)</span></li><li>Each party <span class="math inline">\(i\)</span> perform <em>distribution</em> of <span class="math inline">\(d^{(i)}\)</span> (party <span class="math inline">\(j\)</span> receives the sub-share <span class="math inline">\(d_{i,j}\)</span> from party <span class="math inline">\(i\)</span>) by polynomial <span class="math inline">\(\delta_i(x)\)</span> of degree <span class="math inline">\(T\)</span></li><li>Each party <span class="math inline">\(j\)</span> recombination the sub-shares as <span class="math inline">\(c^{(j)}=\sum_{i=1}^Nr_i\times d_{i,j}\)</span></li></ul><p>So why does this work? Consider the first step; here we are actually computing a polynomial of degree <span class="math inline">\(2T\)</span>. Hence, we need to 'reduce' the degree of this polynomial. Thus, we produce <span class="math inline">\(\delta_i(x)\)</span> in the second step. Consider what happens when we recombine them using the recombination vector, i.e. let: <span class="math display">\[h(x)=\sum_{i=1}^Nr_i\delta_i(x)\]</span> Then we have <span class="math display">\[h(0)=\sum_{i=1}^Nr_i\delta_i(0)=\sum_{i=1}^Nr_id^{(i)}=c\]</span> <span class="math display">\[h(j)=\sum_{i=1}^Nr_i\delta_i(j)=\sum_{i=1}^Nr_id_{i,j}=c^{(j)}\]</span> Thus, <span class="math inline">\(h(x)\)</span> is a polynomial which could be used to share the value of the product and underlies the sharing produced in the final step.</p><p>Let's take a look at the example.</p><ul><li><span class="math inline">\(p_1,p_2,p_3\)</span> calculates <span class="math inline">\(d^{(1)}=35\times31=75,d^{(2)}=68,d^{(3)}=71\)</span></li><li><span class="math inline">\(p_1\)</span> distributes <span class="math inline">\(78,81,84\)</span>, <span class="math inline">\(p_2\)</span> distributes <span class="math inline">\(70,72,74\)</span>, <span class="math inline">\(p_3\)</span> distributes <span class="math inline">\(72,73,74\)</span></li><li><span class="math inline">\(p_1\)</span> has shares <span class="math inline">\(78,70,72\)</span>, <span class="math inline">\(p_2\)</span> has shares <span class="math inline">\(81,72,73\)</span>, <span class="math inline">\(p_3\)</span> has shares <span class="math inline">\(84,74,74\)</span></li><li><span class="math inline">\(p_1,p_2,p_3\)</span> recombines as <span class="math inline">\(c^{(1)}=[3,-3,1][78,70,72]^\top=96,c^{(2)}=100,c^{(3)}=3\)</span></li></ul><h3 id="recombination">Recombination</h3><p>Each party <strong>broadcasts</strong> its value, and performs recombination.</p><p>As the end of the example, each party obtains <span class="math inline">\(96,100,3\)</span> and calculates the result as <span class="math inline">\([3,-3,1][96,100,3]^\top=92\)</span>, which equals to the 'true' value <span class="math inline">\((x_1+x_2)\times x_3=92\)</span>.</p><h2 id="reference">Reference</h2><p>Smart, Nigel P. Cryptography made simple. Springer, 2016.</p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Privacy Engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Differential Privacy</title>
      <link href="2020/11/02/Differential%20Privacy/"/>
      <url>2020/11/02/Differential%20Privacy/</url>
      
        <content type="html"><![CDATA[<h2 id="definition">Definition</h2><h3 id="neighboring-dataset">Neighboring dataset</h3><p>For any dataset <span class="math inline">\(D,D^{\prime}\in\mathcal{D}\)</span>, <span class="math inline">\(D,D^{\prime}\)</span> are neighboring datasets if and only if one of the following two statements is true:</p><ul><li><span class="math inline">\(\exists x\in D^{\prime}\)</span>, s.t. <span class="math inline">\(D^{\prime}=D\cup\{x\}\)</span></li><li><span class="math inline">\(\exists x\in D\)</span>, s.t. <span class="math inline">\(D=D^{\prime}\cup\{x\}\)</span></li></ul><p>Two neighboring datasets always have different sizes, i.e. <span class="math inline">\(|D_1|-|D_2|=\pm1\)</span></p><h3 id="differential-privacy">Differential privacy</h3><p>Let <span class="math inline">\(M:\mathcal{D}\rightarrow Y\)</span> be a randomized mechanism. <span class="math inline">\(M\)</span> is <span class="math inline">\(\varepsilon\)</span>-<strong>differentially private</strong> if, for any neighboring datasets <span class="math inline">\(D,D^{\prime}\in\mathcal{D}\)</span> and any <span class="math inline">\(S\subset \text{img }M\)</span>, we have:</p><p><span class="math display">\[\text{Pr}[M(D)\in S]\leq e^{\varepsilon}\text{Pr}[M(D^{\prime})\in S]\]</span></p><p>Differential privacy guarantees that the result of a certain query on the dataset must be essentially the same irrespective of the presence of any single individual in the dataset.</p><h2 id="laplace-mechanism">Laplace mechanism</h2><h3 id="global-sensitivity">Global sensitivity</h3><p>Let <span class="math inline">\(f:\mathcal{D}\rightarrow \mathbb{R}^k\)</span>, with <span class="math inline">\(f(D)=(f_1(D),f_2(D),\cdots,f_k(D))\)</span>. The global sensitivity of <span class="math inline">\(f\)</span> is:</p><p><span class="math display">\[\Delta f=\max_{D_1,D_2}||f(D_1)-f(D_2)||_1=\max_{D_1,D_2}\sum_{i=1}^k|f_i(D_1)-f_i(D_2)|\]</span></p><p>where <span class="math inline">\(D_1,D_2\)</span> can be any arbitrary neighboring datasets in <span class="math inline">\(\mathcal{D}~\)</span>.</p><h3 id="laplace-mechanism-1">Laplace mechanism</h3><p>For any <span class="math inline">\(f:\mathcal{D}\rightarrow\mathbb{R}^k\)</span>, the mechanism <span class="math inline">\(M:\mathcal{D}\rightarrow\mathbb{R}\)</span> defined by</p><p><span class="math display">\[M(D)=f(D)+\text{Lap}(\Delta f/\varepsilon)\]</span></p><p>is <span class="math inline">\(\varepsilon\)</span>-DP. This is called the Laplace mechanism.</p><p>When <span class="math inline">\(\Delta f\)</span> is unbounded (or very large), we cannot apply the simple Laplace mechanism without destroying utility. Fortunately, in many cases it is still possible to use other mechanisms.</p><h3 id="composition-theorem">Composition Theorem</h3><p>Let <span class="math inline">\(M_1,\cdots,M_k\)</span> be such that every <span class="math inline">\(M_i\)</span> is an <span class="math inline">\(\varepsilon_i\)</span>-DP mechanism. Then <span class="math inline">\((M_1,\cdots,M_k)\)</span> is an <span class="math inline">\(\sum_{i=1}^k\varepsilon_i\)</span>-DP mechanism.</p><p>This theorem is a corollary from the global sensitivity definition. Actually, we can decide on an <span class="math inline">\(\varepsilon\)</span>, called the privacy budget, which then defines the total number of queries anyone can run on the dataset and the noise added to the query results. For example, 10 queries at <span class="math inline">\(\varepsilon_i=0.1\)</span> can protect privacy as good as 2 queries at <span class="math inline">\(\varepsilon_i=0.5\)</span>, because they both have budget <span class="math inline">\(\varepsilon=1\)</span>.</p><h3 id="optimized-mechanism-for-histograms">Optimized mechanism for histograms</h3><p>A histogram consists of queries</p><p><span class="math display">\[\text{COUNT } Q_i: x\in X_i\]</span></p><p>where <span class="math inline">\(\cap_{i=1}^kX_i=\varnothing\)</span> .</p><p>If we add <span class="math inline">\(\text{Lap}(1/\varepsilon)\)</span> noise to each query result, then the whole mechanism is <span class="math inline">\(\varepsilon\)</span>-DP. This optimization is a corollary from the global sensitivity definiton.</p><h2 id="group-privacy">Group privacy</h2><p>Any <span class="math inline">\(\varepsilon\)</span>-DP mechanism <span class="math inline">\(M\)</span> is <span class="math inline">\(k\varepsilon\)</span>-DL for groups of size <span class="math inline">\(k\)</span>. This means that it's "<span class="math inline">\(k\varepsilon\)</span> hard" to determine whether any entire group of <span class="math inline">\(k\)</span> individuals belongs to the dataset, based on the output of <span class="math inline">\(M\)</span>.</p><h2 id="local-differential-privacy">Local differential privacy</h2><h3 id="introduction">Introduction</h3><p>In local differential privacy, every user “adds noise” to his own data (locally) and then shares the “privatized” data with the analyst. The analyst can then run any computation on these privatized data.</p><h3 id="local-differential-privacy-1">Local differential privacy</h3><p>Let <span class="math inline">\(R\)</span> be a set of responses. A randomized algorithm <span class="math inline">\(M:R\rightarrow Y\)</span> is <span class="math inline">\(\varepsilon\)</span>-<strong>local differentially private</strong> if, for responses <span class="math inline">\(r_1,r_2\in R\)</span> and any <span class="math inline">\(S\subset \text{img }M\)</span>, we have:</p><p><span class="math display">\[\text{Pr}[M(r_1)\in S]\leq e^{\varepsilon}\text{Pr}[M(r_2)\in S]\]</span></p><h3 id="example">Example</h3><p>Suppose a professor wants to conduct a survey among students asking the question: “Have you cheated at the exam?”. Every student is asked to answer YES or NO, following these steps:</p><ol type="1"><li>Flip a biased coin, with probability of tails <span class="math inline">\(p &gt; 0.5\)</span></li><li>If tails, then respond truthfully</li><li>If heads, then lie.</li></ol><p>For this mechanism</p><p><span class="math display">\[\varepsilon=\log(\frac{p}{1-p})\]</span></p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Privacy Engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Query-based System</title>
      <link href="2020/10/26/Query-based%20System/"/>
      <url>2020/10/26/Query-based%20System/</url>
      
        <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2><ul><li>Query-based systems aim at giving researchers and organizations anonymous access to the data without sharing with them the individual-level data</li><li>This can be through online interfaces, SQL queries, verified algorithms, etc. which would only return aggregated data</li><li>In this post, we only consider <code>COUNT</code> interface</li></ul><h2 id="query-size-restriction-qsr">Query size restriction (QSR)</h2><h3 id="definition">Definition</h3><p>A query <span class="math inline">\(Q\)</span> is a logical formula that selects a specific set of rows. Define:</p><p><span class="math display">\[Q= C_1\land \cdots \land C_h\]</span></p><p><span class="math display">\[\{Q\}_D=\{x|x\in D,Q(x)=\text{True}\}\]</span></p><p>where <span class="math inline">\(C_i\)</span> is an expression of the form "attribute ? value".</p><p>QSR imposes that every query such that <span class="math inline">\(|\{Q\}_D|\leq t\)</span> is blocked where <span class="math inline">\(t\)</span> is the threshold made by the data curator.</p><h3 id="intersection-attack">Intersection Attack</h3><blockquote><p>COUNT Q1: students in DoC AND code with Notepad?</p><p>COUNT Q2: students in DoC AND born on 1994-09-23 AND code with Notepad?</p></blockquote><p>Counting <span class="math inline">\(Q_1\)</span> and <span class="math inline">\(Q_2\)</span> are likely to have answers <span class="math inline">\(A_1,A_2&gt;t\)</span>, so they won’t be blocked by the query set size restriction. However, if <span class="math inline">\(A_1-A_2=0\)</span>, we will know that the person born on 1994-09-23 doesn’t code with Notepad.</p><p>Intersection attack uses the answers of multiple queries to learn information about a single individual. It has been shown that detecting any intersection attacks is an NP-hard problem.</p><h2 id="unbiased-noise-addition">Unbiased noise addition</h2><h3 id="bounded-noise">Bounded noise</h3><p>Bounded noise will leak information if the attacker knows the noise mechanism. For example, noise <span class="math inline">\(u\sim U[-2,2]\)</span> is added to the above intersection attack query. If we obtain the result <span class="math inline">\(\hat{A_1}=A_1+2=586,\hat{A_2}=A_2-2=581\)</span> and we know that only Bob born on that day, we will know <span class="math inline">\(A_1=584,A_2=583\)</span> <strong>with certainty</strong> because <span class="math inline">\(A_1,A_2\)</span> differs at most <span class="math inline">\(1\)</span>.</p><h3 id="unbounded-noise">Unbounded noise</h3><ul><li>Centered at 0, as to not introduce biases</li><li>Large perturbations are possible but unlikely</li></ul><h3 id="averaging-attack">Averaging attack</h3><p>Averaging attack asks the same question several times and takes the average to find the right value. Formally, this can be done in two ways (frequentist and Bayesian):</p><ul><li>Compute the average of the samples and apply the central limit theorem (CLT). CLT says that this average converges to the mean (i.e. the true value)</li><li>Use Bayes’ rule with multiple observations. This method immediately gives not only the most likely value (the average), but also a full posterior distribution</li></ul><blockquote><p>Assume Gaussian noise <span class="math inline">\(N(0,\sigma^2)\)</span> is added. We can conclude that if the attacker wants to decide whether Bob is in the dataset and his query number <span class="math inline">\(n\geq 4\sigma^2z_{\alpha}^2\)</span>, the attacker will have confidence (probability of making an incorrect prediction) <span class="math inline">\(\alpha\)</span> .</p></blockquote><h2 id="consistent-noise-addition">Consistent noise addition</h2><p>If our noises were to be consistent, we wouldn’t learn anything by asking the same question again. Consistent noise can be achieved through:</p><ul><li>Caching, basically making sure that we cache the noisy result of every query and return this if the same question is asked again</li><li>Seeded pseudorandom number generator (PRNG): in short, we seed our noise generator to ensure that when the query is the same, the exact same noise is added. The seed could e.g. be the hash of all the parameters of the query</li></ul><h3 id="semantic-attack">Semantic attack</h3><p>Tf the query language we use is expressive enough, there often exist multiple ways to ask the same questions:</p><blockquote><p>COUNT Q1: students in DoC AND code with Notepad AND born between 1994-09-23 00:00 and 1994-09-24 00:00?</p><p>COUNT Q2: students in DoC AND code with Notepad AND born between 1994-09-23 00:01 and 1994-09-24 00:01?</p></blockquote><p>When we get a great number of answers, we are able to cancel out the consistent noise by taking average.</p><h2 id="diffixs-sticky-noise">Diffix's sticky noise</h2><p>Diffix's output of counting <span class="math inline">\(Q\)</span> is:</p><p><span class="math display">\[\text{COUNT }\tilde{Q}(D)=\text{COUNT }Q(D)+\sum_{i=1}^h\text{static}[C_i]+\sum_{i=1}^h\text{dynamic}_Q[C_i]\]</span></p><h3 id="static-noise">Static noise</h3><p>For each condition <span class="math inline">\(C_i\)</span>, the noise value <span class="math inline">\(\text{static}[C_i]\)</span> is generated by drawing a random value from <span class="math inline">\(N(0,1)\)</span>. The random value is generated using a PRNG seeded with:</p><p><span class="math display">\[\text{static_seed}_{C_i}=\text{hash}(C_i,\text{salt})\]</span></p><h3 id="dynamic-noise">Dynamic noise</h3><p>For each condition <span class="math inline">\(C_i\)</span>, the noise value <span class="math inline">\(\text{dynamic}_Q[C_i]\)</span> is generated by drawing a random value from <span class="math inline">\(N(0,1)\)</span>. The random value is generated using a PRNG seeded with:</p><p><span class="math display">\[\text{dynamic_seed}_{C_i,Q}=\text{hash}(\text{static_seed}_{C_i},\{Q\}_D)\]</span></p><h3 id="bucket-suppression">Bucket suppression</h3><p>Besides sticky noise, Diffix includes another protection. This is called bucket suppression, and it is a more sophisticated version of QSR.</p><p>The idea is the same: block any query that selects a set of users with size smaller than a certain threshold. However, the threshold is not fixed, but noisy as well:</p><p>if <span class="math inline">\(|\{Q\}_D|\leq1\)</span>, the query gets suppressed; if <span class="math inline">\(|\{Q\}_D|&gt;1\)</span>, it draws a noisy threshold <span class="math inline">\(t\)</span> from <span class="math inline">\(N(4,1/2)\)</span> by the seed:</p><p><span class="math display">\[\text{threshold_seed}=\text{hash}(\{Q\}_D,salt)\]</span></p><h3 id="safe">Safe?</h3><p>Dynamic noise helps protect against many sophisticated attacks, see <a href="https://arxiv.org/abs/1806.02075">here</a>. However, the developers of Diffix do not have a mathematical proof that their system protects against any attack. And they acknowledge that.</p><p>In October 2018, Aloni Cohen and Kobbi Nissim published a report on their attack on Diffix. This attack is an adaptation of a reconstruction attack, proposed in 2003 by Dinur and Nissim.</p><p>In October 2018, some researchers from UCL and EPFL published a <a href="https://www.benthamsgaze.org/2018/10/02/on-location-time-and-membership-studying-how-aggregate-location-data-can-harm-users-privacy/">blogpost</a> about their attack on Diffix, based on a previous paper. There is no technical report available for this attack yet.</p><p>In April 2018, researchers from Imperial College London designed an attack to infer a user’s attribute with high accuracy, see [here] (https://cpg.doc.ic.ac.uk/blog/aircloak-diffix-signal-is-in-the-noise/). They called it a noise-exploitation attack.</p>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Privacy Engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data Pseudonymization and Anonymization</title>
      <link href="2020/10/19/Data%20Pseudonymization%20and%20Anonymization/"/>
      <url>2020/10/19/Data%20Pseudonymization%20and%20Anonymization/</url>
      
        <content type="html"><![CDATA[<h2 id="pseudonymization">Pseudonymization</h2><p>To remove all direct identifiers, e.g. name, phone number, address, social security number etc, and just give each person a unique id that cannot be linked to them:</p><ul><li>Lookup table<ul><li>quickly becomes cumbersome to save it and keep it up-to-date as new data arrives</li></ul></li><li>Secret formula<ul><li>easy to store</li><li>but easy to 'fit' the secret formula by only a few points</li><li>collisions are an issue</li></ul></li><li>Cryptographic hash functions<ul><li>easy to store, easy to compute, no collision, fixed length</li><li>hash function are not a secret information, thus the attacker is able to build a lookup table by iterating over all possible IDs</li></ul></li><li>Cryptographic hash functions with SALT<ul><li>salt is a fixed string of arbitrary length (but long!) that is added to the identifier before hashing it</li><li>salt must be kept secret</li><li>md5("19477") =&gt; md5("19477youwillneverguesswhatthissaltis")</li><li>if the salt is long enough (and secret) it cannot be brute-forced</li></ul></li></ul><p>However, even a properly pseudonymized table is <strong>not safe</strong>.</p><center><table><thead><tr class="header"><th>ID</th><th>Gender</th><th>DOB</th><th>Zip-code</th><th>Sensitive Data</th></tr></thead><tbody><tr class="odd"><td>f1f333...</td><td>Male</td><td>28-09-1955</td><td>4444</td><td>****</td></tr><tr class="even"><td>93db7...</td><td>Female</td><td>12-03-1959</td><td>4334</td><td>****</td></tr></tbody></table></center><p>What if I were to know that the person I’m searching for is a man born on 28-09-1955 and his zip-code is 4444? 63% of the US population is unique given a date of birth, zip code, and sex (Golle, 2006).</p><h2 id="terminology">Terminology</h2><ul><li>Sensitive information: A piece of information about an individual (e.g. disease, drug use) we’re trying to protect (but is relevant for the application).</li><li>Identifier: A piece of information that directly identifies a person (name, address, phone number, ip address, passport number, etc).</li><li>Quasi-identifier: A piece of information that does not directly identify a person (e.g. nationality, date of birth). But multiple quasi-identifiers taken together could uniquely identify a person. A set of quasi-identifiers could be known to an attacker for a certain individual (auxiliary info).</li><li>Auxiliary information: Information known to an attacker.</li></ul><h2 id="uniqueness-attack">Uniqueness Attack</h2><h3 id="definition">Definition</h3><p><strong>Uniqueness</strong> w.r.t. <span class="math inline">\(A\)</span>: fraction of the dataset that is uniquely identified by the set <span class="math inline">\(A\)</span> of quasi-identifiers.</p><h3 id="k-anonymity"><span class="math inline">\(k\)</span>-anonymity</h3><p>A table is <span class="math inline">\(k\)</span>-anonymous if every record in the table is indistinguishable from at least <span class="math inline">\(k-1\)</span> other records, with respect to every set of quasi-identifiers. This means that even if an attacker knows all possible quasi-identifiers, she cannot identify his target uniquely.</p><p>An <strong>equivalence class</strong> is a set of records that have the same values for all the quasi-identifiers.</p><h3 id="loss-of-information">Loss of information</h3><p><span class="math display">\[H(D)=\sum_{i=1}^k\frac{\#C_i}{N}\log\frac{\#C_i}{N}\]</span></p><p>where <span class="math inline">\(N\)</span> is the amount of rows in the dataset <span class="math inline">\(D\)</span>; <span class="math inline">\(C_1 ,\cdots, C_k\)</span> are the equivalence classes; <span class="math inline">\(\#C_i\)</span> indicates the number of rows that belong to <span class="math inline">\(Ci\)</span>. The higher the entropy, the more information is contained in <span class="math inline">\(D\)</span>.</p><h2 id="homogeneity-attack">Homogeneity Attack</h2><h3 id="definition-1">Definition</h3><p>A <strong>homogeneity attack</strong> can take place when individuals in the same equivalence class all have the same sensitive attribute value.</p><center><table><thead><tr class="header"><th>ID</th><th>Gender</th><th>DOB</th><th>Zip-code</th><th>Sensitive Data</th></tr></thead><tbody><tr class="odd"><td>f1f333...</td><td>Male</td><td>1955</td><td>Las Vegas</td><td>gastritis</td></tr><tr class="even"><td>34dera...</td><td>Male</td><td>1955</td><td>Las Vegas</td><td>gastritis</td></tr></tbody></table></center><p>What if I know that the person I’m searching for is a man, born in 1955, living in Las Vegas?</p><h3 id="l-diversity"><span class="math inline">\(l\)</span>-diversity</h3><p>An equivalence class is <span class="math inline">\(l\)</span>-diverse if it contains at least <span class="math inline">\(l\)</span> distinct values for the sensitive attributes. A table is <span class="math inline">\(l\)</span>-diverse if every equivalence class is <span class="math inline">\(l\)</span>-diverse.</p><h2 id="not-enough-yet...">Not enough yet...</h2><h3 id="definition-2">Definition</h3><p>A <strong>semantic attack</strong> can take place when sensitive attributes of individuals in an equivalence class are distinct but semantically similar. For example, skin cancer and breast cancer are both cancer.</p><p>A <strong>skewness attack</strong> (here it is probabilistic) takes place when the distribution of the sensitive attributes in a class is skewed. In the general population, 99% might test negative for illegal drugs but, in an equivalence class, only 15% test negative. I learned something about people in this class.</p><h3 id="t-closeness"><span class="math inline">\(t\)</span>-closeness</h3><p>An equivalence class is said to have <span class="math inline">\(t\)</span>-closeness if the distance between the distribution of a sensitive attribute in this class and the distribution of this attribute in the whole table is no more than a threshold <span class="math inline">\(t\)</span>. A table is said to have <span class="math inline">\(t\)</span>-closeness if all equivalence classes have <span class="math inline">\(t\)</span>-closeness.</p><h2 id="final-reminder">Final reminder</h2><ul><li>Anonymization is hard for small data and probably impossible for big data<ul><li>protect a dataset against a whole range of attacks: uniqueness, homogeneity, semantic, skewness, matching (unicity), profiling</li><li>by anonymizing it once and only once</li><li>all the while preserving utility (for all current and future uses)</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Computer Science </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Privacy Engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>好久不见</title>
      <link href="2020/10/14/hello/"/>
      <url>2020/10/14/hello/</url>
      
        <content type="html"><![CDATA[<p>许久不见啦！去年十月开始我忙于申请，然后紧接着又是毕业的相关事宜，以致我许久没有更新。我正在着手写一点关于我在清华四年的东西，希望能尽快发上来。与此同时，我也可能发一些我在IC的笔记（和以前一样）。</p><p>另外，我更新了博客的主题，希望大家都能喜欢 :)</p>]]></content>
      
      
      <categories>
          
          <category> Life </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Multi Armed Bandit</title>
      <link href="2019/10/28/Multi%20Armed%20Bandit/"/>
      <url>2019/10/28/Multi%20Armed%20Bandit/</url>
      
        <content type="html"><![CDATA[<h2 id="multi-armed-bandit">Multi Armed Bandit</h2><ul><li><span class="math inline">\(t=1,2,\cdots,N\)</span></li><li><span class="math inline">\(k\)</span> arm</li><li>at <span class="math inline">\(t\)</span>, choose arm <span class="math inline">\(i\)</span>, receive reward <span class="math inline">\(X_{i,t}\sim{}D_i\)</span>(iid unknown distribution)</li><li>Policy: <span class="math inline">\(\pi=\{i(t),t=1,2,\cdots,N\}\)</span></li><li>Goal: <span class="math inline">\(\max\mathbb{E}\{\sum_{t=1}^NX_{i,t}\}\)</span></li><li><span class="math inline">\({\rm OPT}=N\max_i\mu_i=N\mu,\mu_i=\mathbb{E}\{X_{i,t}\}\)</span></li><li><span class="math inline">\({\rm Reg}={\rm OPT}-\mathbb{E}\{\sum_{t=1}^NX_{i,t}|\pi\}\)</span></li></ul><a id="more"></a><h2 id="ucb-alg">UCB ALG</h2><ul><li>Initialize: play machine arm once</li><li>Loop: play machine <span class="math display">\[i=\arg\max\bar{x}_j+\sqrt{\frac{2\ln{}n}{n_j}}\]</span></li></ul><p>where <span class="math inline">\(\bar{x}_j={\rm avg}\)</span> reward of arm <span class="math inline">\(j\)</span>, <span class="math inline">\(n_j=\#\)</span> of times <span class="math inline">\(j\)</span> is played so far</p><h3 id="theorem">Theorem</h3><p>For all <span class="math inline">\(k&gt;1\)</span>, if UCB runs on <span class="math inline">\(k\)</span> arms with distributions <span class="math inline">\(P_1,P_2,\cdots,P_k\)</span> with support <span class="math inline">\([0,1]\)</span>, then the expected regrest after any <span class="math inline">\(n\)</span> is at most:</p><p><span class="math display">\[\delta\sum_{i,\mu_i&lt;\mu}\frac{\ln{}n}{\Delta_i}+(1+\frac{\pi^2}{3})\sum_{j=1}^k\Delta_j\]</span></p><p>where <span class="math inline">\(\Delta_i=\mu-\mu_i\)</span></p><hr /><p><em>Proof.</em><br> Define <span class="math inline">\(C_{t,s}=\sqrt{\frac{2\ln{}t}{s}}\)</span> <span class="math display">\[T_i(n)=1+\sum_{t=k+1}^n\{i(t)=t\}\leq{}l+\sum_{t=k+1}^n\{i(t)=i,T_i(t-1)\geq{}l\}\]</span> After some calculation, we found that <span class="math display">\[T_i(n)\leq{}l+\sum_{t}\sum_{s=1}^{t-1}\sum_{s_i=l}^{t-1}\{\bar{x}_s^\star+C_{t,s}\leq\bar{x}_i+C_{t,s_i}\}\]</span> Also, it's true that <span class="math display">\[\bar{x}_s^\star+C_{t,s}\leq\bar{x}_i+C_{t,s_i}\]</span> holds if at least one of following holds <span class="math display">\[\bar{x}_s^\star\leq\mu-C_{t,s},\bar{x}_{i,s_i}\geq\mu_i+C_{t,s},\mu&lt;\mu_i+2C_{t,s}\]</span> However, the first two probability can be bound by Chernoff bound and the last one is impossible (probability <span class="math inline">\(= 0\)</span>).<br> <span class="math display">\[{\rm Pr}\{\bar{x}_s^\star\leq\mu-C_{t,s}\}\leq{}e^{-4\ln{}t},{\rm Pr}\{\bar{x}_{i,s_i}\geq\mu_i+C_{t,s}\}\leq{}e^{-4\ln{}t}\]</span> Finally, choose <span class="math display">\[l=\lceil\frac{8\ln{}n}{\Delta_i^2}\rceil\]</span> <span class="math display">\[\mathbb{E}\{T_i(n)\}\leq{}l+\sum_{t}\sum_{s=1}^{t-1}\sum_{s_i=l}^{t-1}t^{-4}=l+1+\frac{\pi^2}{3}\]</span></p><h2 id="varepsilon-greedy-alg"><span class="math inline">\(\varepsilon\)</span>-greedy ALG</h2><ul><li>Parameter: <span class="math inline">\(c&gt;0,0&lt;d&lt;1\)</span></li><li>Initialize: Define <span class="math display">\[\varepsilon_n=\min\{1,\frac{ck}{d^2n}\}\]</span></li><li>Loop: <span class="math inline">\(\forall{}n=1,2,\cdots\)</span>, let <span class="math inline">\(i_n=\arg\max_j\bar{x}_{j,n}\)</span>. Play <span class="math inline">\(i_n\)</span> with probability <span class="math inline">\(1-\varepsilon_n\)</span> and random with probability <span class="math inline">\(\varepsilon_n\)</span></li></ul><h3 id="theorem-1">Theorem</h3><p>For all <span class="math inline">\(k&gt;1\)</span>, if <span class="math inline">\(\varepsilon\)</span>-greedy runs on <span class="math inline">\(k\)</span> arms with distributions <span class="math inline">\(P_1,P_2,\cdots,P_k\)</span> with support <span class="math inline">\([0,1]\)</span> and <span class="math inline">\(0&lt;d&lt;\min_{i,\mu_i&lt;\mu}\Delta_i\)</span>. Then, the probability that after <span class="math inline">\(n\geq{}ck/d\)</span> plays, <span class="math inline">\(\varepsilon\)</span>-greedy choose a sub-opt <span class="math inline">\(j\)</span> is at most <span class="math display">\[\mathcal{O}(\frac{c}{d^2n}+o(\frac{1}{n}))\]</span> for <span class="math inline">\(n\rightarrow\infty\)</span> and <span class="math inline">\(c&gt;5\)</span>.</p><h2 id="lower-bound">Lower Bound</h2><p>Consider two <span class="math inline">\(\Theta\)</span> values, i.e., <span class="math inline">\(\Theta=(\theta_1,\theta_2,\cdots,\theta_k)\)</span> with <span class="math inline">\(\mu_1&gt;\mu_2\geq\dots\geq\mu_k\)</span>; <span class="math inline">\(\Theta^{\prime}=(\theta_1,\theta_2^\prime,\cdots,\theta_k)\)</span> with <span class="math inline">\(\mu_2^{\prime}&gt;\mu_1\geq\dots\geq\mu_k\)</span>. Here we want to prove that it costs about <span class="math inline">\(\ln{}n\)</span> time to tell the difference between this two.<br> For a strategy - <span class="math inline">\(x_{j,s}\)</span>: reward for <span class="math inline">\(j\)</span> at <span class="math inline">\(s\)</span>-th slot - <span class="math inline">\(\mathbb{P}\)</span>: joint distribution over <span class="math inline">\(\{I_t,x_{j,s}\}\)</span> under <span class="math inline">\(\Theta\)</span> - <span class="math inline">\(\mathbb{P}^{\prime}\)</span>: joint distribution over <span class="math inline">\(\{I_t,x_{j,s}\}\)</span> under <span class="math inline">\(\Theta^\prime\)</span></p><hr /><p>Consider <span class="math inline">\(A\subset\{T_2(n)=n_2\}\)</span> <span class="math display">\[\mathbb{P}(A)=\int_A\prod_{s=1}^{n_2}\frac{d\mathbb{P}_{\theta_2^\prime}}{d\mathbb{P}_{\theta_2}}(x_{2,s})d\mathbb{P}=\int_A\exp\{\sum_{s=1}^{n_2}\ln\frac{d\mathbb{P}_{\theta_2^\prime}}{d\mathbb{P}_{\theta_2}}(x_{2,s})d\mathbb{P}\}=\int_Ae^{-L_{n_2}}d\mathbb{P}\]</span> <span class="math display">\[\mathbb{P}^\prime(A)\geq{}e^{-C_n}\mathbb{P}(A)\]</span></p><h2 id="thompson-sampling-alg">Thompson Sampling ALG</h2><p>Here we only consider Bernoulli Bandits with <span class="math inline">\(N=2\)</span>, because the overall analysis is really complex.</p><ul><li><span class="math inline">\(X_1,X_2\in\{0,1\}\)</span>, <span class="math inline">\(\mu_1\geq\mu_2\)</span></li><li>Initialize: for each <span class="math inline">\(i\)</span>, <span class="math inline">\(S_i=F_i=0\)</span></li><li>Loop: <span class="math inline">\(t=1,2,\cdots,d_0\)</span><ul><li>For each <span class="math inline">\(i\)</span>, sample <span class="math inline">\(\theta_i(t)\sim{\rm Beta}(S_i+1,F_i+1)\)</span></li><li>Play <span class="math inline">\(i(t)=\arg\max\theta_i(t)\)</span>, observe reward <span class="math inline">\(r_t\)</span></li><li>If <span class="math inline">\(r_t=1\)</span>, <span class="math inline">\(S_{i(t)}+=1\)</span>, else <span class="math inline">\(F_{i(t)}+=1\)</span></li></ul></li></ul><h3 id="theorem-2">Theorem</h3><p>In this <span class="math inline">\(2\)</span> Bernoulli Bandits, TS achieves</p><p><span class="math display">\[\mathbb{E}\{R(T)\}=\mathcal{O}(\frac{\ln{}T}{\Delta}+\frac{1}{\Delta^3})\]</span> where <span class="math inline">\(\Delta=\mu_\max-\mu_\min\)</span></p><hr /><p><em>Proof.</em></p><ul><li>Denote <span class="math inline">\(j_0=\#\)</span> of plays of arm <span class="math inline">\(1\)</span> until arm <span class="math inline">\(2\)</span> is played <span class="math inline">\(L=24\ln{}T/\Delta^2\)</span> times.</li><li>Let <span class="math inline">\(t_j=\)</span> time of the <span class="math inline">\(j^{\rm th}\)</span> play of arm <span class="math inline">\(1\)</span> (<span class="math inline">\(t_0=0\)</span>). Also, let <span class="math inline">\(y_j=t_j-t_{j-1}-1\)</span>, i.e., the interval play time.</li><li>Denote <span class="math inline">\(S(j)=\#\)</span> of success in the first <span class="math inline">\(j\)</span> plays of arm <span class="math inline">\(1\)</span></li><li>The expected <span class="math inline">\(\#\)</span> of play of arm <span class="math inline">\(2\)</span>: <span class="math display">\[\mathbb{E}\{K_2(T)\}\leq{}L+\mathbb{E}\{\sum_{j=j_0}^{T-1}y_j\}\]</span></li><li>Denote <span class="math inline">\(X(j,s,y)\)</span> to be the <span class="math inline">\(\#\)</span> of attempts before we get a sample from <span class="math inline">\({\rm Beta}(s+1,j-s+1)\)</span> to exceed <span class="math inline">\(y\)</span></li></ul><p>It can be seen that <span class="math inline">\(X(j,s,y)\)</span> is Geo with success probability <span class="math inline">\(1-F_{s+1,j-s+1}^{\rm beta}(y)\)</span></p><hr /><h4 id="lemma-1">Lemma 1</h4><p>For all non-negative <span class="math inline">\(j\)</span> an d <span class="math inline">\(s\leq{}j\)</span> and <span class="math inline">\(y\in[0,1]\)</span> <span class="math display">\[\mathbb{E}\{X(j,s,y)\}=\frac{1}{F_{j+1,y}^{\rm beta}(s)}-1\]</span></p><hr /><ul><li>Consider the <span class="math inline">\(\#\)</span> of steps before event <span class="math inline">\(\{\theta_1(t)&gt;\mu_2+\Delta/2\}\)</span> first happens</li><li>Given <span class="math inline">\(S(j)\)</span>, this has the same distribution as <span class="math inline">\(X(j,S(j),\mu_2+\Delta/2)\)</span></li><li><span class="math inline">\(y_j\)</span> can be larger than this <span class="math inline">\(\#\)</span> iff at some <span class="math inline">\(t\in(t_j,t_{j+1})\)</span>, <span class="math inline">\(\theta_2(t)&gt;\mu_2+\Delta/2\)</span></li><li>Thus: <span class="math display">\[\mathbb{E}\{y_j\}\leq\mathbb{E}\{\min(X(j,S(j),\mu_2+\Delta/2),T)\}+\mathbb{E}\{\sum_{t=t_j+1}^{t_{j+1}-1}T\cdot{}I\{\theta_2&gt;\mu_2+\Delta/2\}I\{j&gt;j_0\}\}\]</span></li></ul><p>Sum it up from <span class="math inline">\(j=j_0\)</span> to <span class="math inline">\(T-1\)</span> and define event:</p><p><span class="math display">\[E_2(t)=\{\theta_2(t)\leq\mu_2+\Delta/2\lor{}K_2(t)\leq{}L\}\]</span></p><hr /><h4 id="lemma-2">Lemma 2</h4><p><span class="math display">\[\mathbb{P}(E_2(t))\geq1-\frac{2}{T^2}\]</span></p><h4 id="lemma-3">Lemma 3</h4><p>Consider any <span class="math inline">\(y&lt;\mu_1\)</span>, let <span class="math inline">\(\Delta^1=\mu_1y\)</span>, let <span class="math inline">\(R=\frac{\mu_1(1-y)}{y(1-\mu_1)}&gt;1\)</span> and <span class="math inline">\(D=D(y||\mu_1)=y\ln\frac{y}{\mu_1}+(1-y)\ln\frac{1-y}{1-\mu_1}\)</span>, we have:</p><p><span class="math display">\[\mathbb{E}\{\mathbb{E}\{\min(X(j,S(j),y),T)|S(j)\}\}\leq\frac{16}{T}\quad{\rm for }\quad{}j\geq\frac{4\ln{}T}{(\Delta^1)^2}\]</span></p><hr /><p>Substitute Lemma 2 and Lemma 3 into the sum-up result (which we omit) and the inequality <span class="math display">\[\mathbb{E}\{K_2(T)\}\leq{}L+\mathbb{E}\{\sum_{j=j_0}^{T-1}y_j\}\]</span> we have (skip lots lots of calculation): <span class="math display">\[\mathbb{E}\{K_2(T)\}\leq{}\frac{40\ln{}T}{\Delta^2}+\frac{48}{\Delta^4}+18\]</span> <span class="math display">\[\mathbb{E}\{R(T)\}=\mathcal{O}(\frac{\ln{}T}{\Delta}+\frac{1}{\Delta^3})\]</span></p><h2 id="non-stochastic-alg-exp3">Non Stochastic: ALG EXP3</h2><ul><li><span class="math inline">\(K\)</span> actions</li><li><span class="math inline">\(X(i)=(X_i(1),X_i(2),\cdots),X_i(t)\in[0,1]\)</span></li><li>ALG <span class="math inline">\(=i_1,i_2,\cdots,\)</span></li><li><span class="math inline">\(G_A(T)=\sum_{t=1}^TX_{i_t}(t)\)</span></li><li>Regret <span class="math inline">\(=\max_j\sum_{t=1}^TX_j(t)-G_A(T)\)</span></li></ul><p><strong>ALG EXP3</strong></p><ul><li>Parameter: Real <span class="math inline">\(\gamma\in[0,1]\)</span></li><li>Initialize: <span class="math inline">\(w_i(1)=1,\forall{}i=1,2,\cdots,K\)</span></li><li>Loop: for each <span class="math inline">\(t=1,2,\cdots\)</span><ul><li>Set <span class="math display">\[P_i(t)=(1-\gamma)\frac{w_i(t)}{\sum{}w_i(t)}+\frac{\gamma}{K}\]</span></li><li>Draw <span class="math inline">\(i_t\)</span> randomly <span class="math inline">\(\sim{}P_1(t),\cdots,P_K(t)\)</span></li><li>Get reward <span class="math inline">\(X_{i_t}\in[0,1]\)</span></li><li>For <span class="math inline">\(j=1,2,\cdots,k\)</span></li></ul></li></ul><p><span class="math display">\[\hat{X}_j(t)=\left\{\begin{aligned}&amp;\frac{X_j(t)}{P_j(t)}&amp;j=i_t\\&amp;0&amp;\text{otherwise}\end{aligned}\right.\quad\quad{}w_j(t+1)=w_j(t)\exp(\frac{\gamma\hat{X}_j(t)}{K})\]</span></p><h3 id="theorem-3">Theorem</h3><p>For any <span class="math inline">\(K\)</span> and any <span class="math inline">\(\gamma\in[0,1]\)</span>, <span class="math display">\[G_\max-\mathbb{E}\{G_{\rm exp3}\}\leq(e-1)\gamma{}G_\max+\frac{K\ln{}K}{\gamma}\]</span> for any reward assignments</p><h4 id="corollary">Corollary</h4><p>Assume <span class="math inline">\(g\geq{}G_\max\)</span> and <span class="math inline">\(\gamma=\min\{1,\sqrt{\frac{K\ln{}K}{(e-1)g}}\}\)</span>, then <span class="math display">\[G_\max-\mathbb{E}\{G_{\rm exp3}\}\leq2.63\sqrt{gK\ln{}K}\]</span></p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network Optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Heavy Traffic Analysis</title>
      <link href="2019/09/23/Heavy%20Traffic/"/>
      <url>2019/09/23/Heavy%20Traffic/</url>
      
        <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2><ul><li>Single Hop System, <span class="math inline">\(L\)</span> Queues</li><li><span class="math inline">\(Q_l(t=1)=(Q_l(t)+A_l(t)-S_l(t))^+=Q_l(t)+A_l(t)-S_l(t)+U_l(t)\)</span></li><li><span class="math inline">\(U_l(t)=\max\{0,S_l(t)-A_l(t)-Q_l(t)\}\)</span></li></ul><a id="more"></a><h3 id="section"><span class="math inline">\(~\)</span></h3><h4 id="lemma-1">Lemma 1</h4><p>For an aperiodic and irreducible Markov Chain, over a countable state-space, suppose <span class="math inline">\(Z:\mathcal{X}\rightarrow{}R\)</span> is a non-negative Lyapunor function. Define</p><p><span class="math display">\[\Delta(Z(X))=[Z(X[t+1])-Z(X[t])]I(X(t)=x)\]</span></p><p>Suppose</p><ul><li><span class="math inline">\(\exists\eta&gt;0\)</span> and <span class="math inline">\(k&lt;\infty\)</span> s.t.</li></ul><p><span class="math display">\[\mathbb{E}\{\Delta(Z(X))|X(t)=x\}\leq-\eta\text{ for all }X\in\mathcal{X},Z(X)\geq{}k\]</span></p><ul><li><span class="math inline">\(\exists{}D\leq\infty\)</span> s.t.</li></ul><p><span class="math display">\[Pr\{|\Delta(Z(X))\leq0\}=1,~\forall{}X\in\mathcal{X}\]</span></p><p>Then <span class="math inline">\(\exists\theta^*&gt;0\)</span> and <span class="math inline">\(c^*&lt;\infty\)</span> s.t.</p><p><span class="math display">\[\lim\sup_{t\rightarrow\infty}\mathbb{E}\{\exp\{\theta^*Z(X[t])\}\}\leq{}c^*\]</span></p><p>If also <span class="math inline">\(X(t)\)</span> is positive recurrent, then <span class="math inline">\(Z(X(t))\)</span> converges in distribution to <span class="math inline">\(\bar{Z}\)</span> with <span class="math inline">\(\mathbb{E}\{\exp\{\theta^*\bar{Z}\}\}\leq{}c^*\)</span></p><h2 id="join-the-shortest-queue-jsq">Join the Shortest Queue (JSQ)</h2><ul><li><span class="math inline">\(A_{\Sigma}(t),S_l(t)\)</span> iid</li><li><span class="math inline">\(A_\Sigma(t)\in[0,A_\max],S_l(t)\in[0,S_\max]\)</span></li><li><span class="math inline">\(\lambda_\Sigma=\mathbb{E}\{A_\Sigma(t)\},\sigma_\Sigma^2=D\{A_\Sigma(t)\}\)</span></li><li><span class="math inline">\(\mu_l=\mathbb{E}\{S_l(t)\},v_l^2=D\{S_l(t)\}\)</span></li><li><span class="math inline">\(\mu_\Sigma=\sum_l\mu_l,v_\Sigma^2=\sum_lv_l^2\)</span></li></ul><p>And the policy is <span class="math inline">\(A(t)=(A_1(t),\cdots,A_L(t))\)</span> <span class="math display">\[A(t)=\text{RAND}\{\arg\min_{A\geq0,\sum_lA_l=A_\Sigma(t)}&lt;A,Q(t)&gt;\}\]</span></p><h3 id="conclusion">Conclusion</h3><ul><li><span class="math inline">\(\lambda_\Sigma&gt;\mu_\Sigma\)</span>, unstable</li><li><span class="math inline">\(\lambda_\Sigma&lt;\mu_\Sigma\)</span>, JSQ stablizes that system <span class="math inline">\(\{Q(t)\}\)</span> converges in distribution to a random variable <span class="math inline">\(\bar{Q}\)</span> whose all moments are bounded, i.e. <span class="math inline">\(\mathbb{E}\{||\bar{Q}||^r\}=M_r\)</span></li></ul><h3 id="analysis-of-stability">Analysis of Stability</h3><p><span class="math inline">\(Z(X)=V(Q)=||Q||\)</span></br> <span class="math inline">\(W(Q)=||Q||^2\)</span></br> <span class="math display">\[e=\mu_\Sigma-\lambda_\Sigma,\frac{e}{L}=\mu_l-\lambda_l\]</span> <span class="math display">\[\begin{split}\mathbb{E}\{\Delta(W(Q))|Q\}&amp;=\mathbb{E}\{||Q(t+1)||^2-||Q(t)||^2~|Q\}\\&amp;=\mathbb{E}\{||Q+A-S+U||^2-||Q||^2~|Q\}\\&amp;=\mathbb{E}\{||Q+A-S||^2+2&lt;Q+A_S,U&gt;+||U||^2-||Q||^2~|Q\}\\&amp;\leq{}\mathbb{E}\{||Q+A-S||^2-||Q||^2~|Q\}\\&amp;=\mathbb{E}\{2&lt;Q,A-S&gt;+||A-S||^2~|Q\}\\&amp;=\mathbb{E}\{2&lt;Q,A-S&gt;|Q\}+k_1\\&amp;=2&lt;Q,\mathbb{E}\{A|Q\}-\lambda&gt;-&lt;Q,\mu-\lambda&gt;+k_1\\&amp;=&lt;Q,\mathbb{E}\{A|Q\}-\lambda&gt;-\frac{2e}{L}&lt;Q,1&gt;+k_1\\&amp;=2\mathbb{E}\{A_\Sigma|Q\}Q_\min-2&lt;Q,\lambda&gt;-\frac{2e}{L}||Q||_1+k_1\\&amp;=2\lambda_\Sigma{}Q_\min-2\sum_l\lambda_lQ_l-\frac{2e}{L}||Q||+k_1\\&amp;=-2\sum_l\lambda_l(Q_l-Q_\min)-\frac{2e}{L}||Q||+k_1\\&amp;\leq\frac{2e}{L}||Q||+k_1\end{split}\]</span></p><p><span class="math display">\[\begin{split}\mathbb{E}\{\Delta{}V(Q)|Q(t)=Q\}=&amp;\mathbb{E}\{||Q(t+1)||-||Q(t)||~|Q(t)=Q\}\\\leq&amp;\frac{1}{2||Q||}\mathbb{E}\{||Q(t+1)||^2-||Q(t)||^2~|Q(t)=Q\}\\\leq&amp;\frac{e}{L}+\frac{k_1}{2||Q||}\end{split}\]</span></p><h3 id="lower-bound">Lower Bound</h3><p>Consider <span class="math inline">\(Q_\Sigma(t)\)</span> and <span class="math inline">\(S_\Sigma(t)=\sum{}S_l(t)\)</span> which is a single server, obviously: <span class="math display">\[Q_\Sigma(t)\leq\sum_lQ_l(t)\]</span></p><ul><li><span class="math inline">\(\alpha(t)&lt;\alpha_\max\)</span></li><li><span class="math inline">\(\beta(t)&lt;\beta_\max\)</span></li><li><span class="math inline">\(\Phi(t+1)=[\Phi(t)+\alpha(t)-\beta(t)]^+\)</span></li></ul><h4 id="lemma-2">Lemma 2</h4><p>Suppose <span class="math inline">\(\{\alpha^e(t)\}\)</span> satisfies <span class="math inline">\(e=\beta-\alpha^e\)</span>. Let the queue process <span class="math inline">\(\{\Phi^e(t)\}\)</span>. Then</p><ul><li><span class="math inline">\(\{\Phi^e(t)\}\)</span> is a positive recurrent Markov Chain and <span class="math inline">\(\{\Phi^e(t)\}\rightarrow{}\bar{\Phi}^e\)</span> with <span class="math inline">\(\mathbb{E}\{||\bar{\Phi}^e||\}\leq{}M_r\)</span></li><li><span class="math display">\[\mathbb{E}\{\bar{\Phi}^e\}\geq\frac{\xi^e}{2e}-B_1\]</span></li></ul><p>where <span class="math inline">\(\xi^e=\sigma_{\alpha^e}^2+\sigma_\beta^2+e^2,B_1=\frac{\beta_\max}{2}\)</span></p><ul><li>In the heavy traffic limit, <span class="math inline">\(e\rightarrow0\)</span> <span class="math display">\[\lim_{e\rightarrow0}\inf{}e\mathbb{E}\{||\bar{\Phi}^e||\}\geq\frac{\xi}{2}\]</span></li></ul><hr /><p><span class="math display">\[\begin{split}\Phi(t+1)=\Phi(t)+\alpha(t)-\beta(t)+\chi(t),\chi(t)=-\max\{0,\beta-\alpha-\Phi\}\end{split}\]</span> <span class="math display">\[\begin{split}W(\Phi)=||\Phi||^2\end{split}\]</span> <span class="math display">\[\begin{split}\mathbb{E}\{\Delta{}W(\Phi)|\Phi(t)\}&amp;=\mathbb{E}\{(\Phi+\alpha-\beta)^2+2(\Phi+\alpha-\beta)\chi+\chi^2-\Phi^2|\Phi)\}\\&amp;=\mathbb{E}\{(\alpha-\beta)^2|\Phi\}+2\Phi{}\mathbb{E}\{(\alpha-\beta)|\Phi\}-\mathbb{E}\{\chi^2|\Phi\}\end{split}\]</span></p><p>In steady state, <span class="math inline">\(\mathbb{E}\{\Delta{}W\}=0\)</span>, take expectation of both sides:</p><p><span class="math display">\[\mathbb{E}\{(\alpha-\beta)^2\}+2\mathbb{E}\{\Phi{}\}e-\mathbb{E}\{\chi^2\}=0\]</span></p><p>Consider <span class="math inline">\(\mathbb{E}\{\chi^2\}\leq{}e\beta_\max\)</span></p><h3 id="state-space-collapse">State Space Collapse</h3><p>Let <span class="math inline">\(\vec{c}&gt;0\)</span> is a vector with unit form. Let <span class="math inline">\(Q_{\parallel}=&lt;\vec{c},\vec{Q}&gt;\vec{c}\)</span>, <span class="math inline">\(Q_{\perp}=Q-Q_{\parallel}\)</span></p><h4 id="lemma-3">Lemma 3</h4><p>Define Lyapunov function</p><p><span class="math display">\[V_\perp(Q)=||Q_\perp||,W(Q)=||Q||^2,W_{\parallel}(Q)=||Q_\parallel||^2\]</span> <span class="math display">\[\Delta{}V_\perp(Q)=V_\perp(Q(t+1))-V_\perp(Q(t))\]</span></p><p>Then:</p><ul><li><span class="math display">\[\Delta{}V_\perp(Q)\leq\frac{1}{2||Q_\perp||}(\Delta{}W(Q)-\Delta{}W_\parallel(Q))\]</span></li><li><span class="math display">\[|\Delta{}V_\perp(Q)|\leq2\sqrt{L}\max(A_\max,S_\max)\]</span></li></ul><hr /><p><span class="math display">\[\begin{split}\Delta{}V_\perp(Q)&amp;=V_\perp(Q(t+1))-V_\perp(Q(t))\\&amp;=\sqrt{V_\perp(Q(t+1))^2}-\sqrt{V_\perp(Q(t))^2}\\&amp;\leq\frac{1}{2||Q_\perp(t)||}(||Q_\perp(t+1)||^2-||Q_\perp(t)||^2)\\&amp;=\frac{1}{2||Q_\perp(t)||}(\Delta{}W(Q)-\Delta{}W_{\parallel}(Q))\end{split}\]</span> <span class="math display">\[\begin{split}|\Delta{}V_\perp(Q)|&amp;=|||Q_\perp(t+1)||-||Q_\perp(t)|||\\&amp;\leq||Q_\perp(t+1)-Q_\perp(t)||\\&amp;\leq||Q(t+1)-Q(t)||+||Q_\parallel(t+1)-Q_\parallel(t)||\\&amp;\leq2||Q(t+1)-Q(t)||\\&amp;\leq2\sqrt{L}\max||Q_l(t+1)-Q_l(t)||\end{split}\]</span></p><hr /><p><span class="math display">\[\vec{c}=\vec{1}\cdot\frac{1}{\sqrt{L}}\]</span> <span class="math display">\[Q_\parallel^e=\frac{Q_\Sigma}{L}\vec{1},Q_\perp=[Q_l-\frac{1}{L}Q_\Sigma]_{l=1}^L,Q_\Sigma=\sum_lQ_l\]</span></p><h4 id="proposition">Proposition</h4><p>Consider <span class="math inline">\(\bar{Q}^e\)</span> under JSQ with <span class="math inline">\(\{A_\Sigma^e\}_t\)</span>, and <span class="math inline">\(e=\mu_\Sigma-\lambda_\Sigma^e\)</span>. Then, for any <span class="math inline">\(\delta\in(0,\mu_\max)\)</span>, <span class="math inline">\(\exists{}\)</span> a sequence of <span class="math inline">\(\{N_r\}\)</span>, s.t. <span class="math display">\[\mathbb{E}\{||\bar{Q}_\perp^2||^r\}\leq{}N_r,\forall{}e\in(0,(\mu_\min-\delta)L)\]</span></p><hr /><p><span class="math display">\[\begin{split}\mathbb{E}\{\Delta{}W(Q)|Q\}&amp;=\mathbb{E}\{||Q(t+1)||^2-||Q(t)||^2|Q\}\\&amp;\leq{}\mathbb{E}\{||Q+A-S||^2-||Q||^2|Q\}\\&amp;=2\mathbb{E}\{&lt;Q,A-S&gt;|Q\}+K_1\end{split}\]</span> <span class="math display">\[\begin{split}\mathbb{E}\{&lt;Q,A-S&gt;|Q\}&amp;=&lt;Q,\mathbb{E}\{A|Q\}-\lambda&gt;-&lt;Q,\mu-\lambda&gt;\\&amp;=\mathbb{E}\{A_\Sigma|Q\}Q_\min-&lt;Q,\lambda&gt;-\frac{e}{\sqrt{L}}&lt;Q,c&gt;\\&amp;=\lambda_\Sigma{}Q_\min-\sum_l\lambda_lQ_l-\frac{e}{\sqrt{L}}||Q_\parallel||\\&amp;=-\sum_l\lambda_l(Q_l-Q_\min)-\frac{e}{\sqrt{L}}||Q_\parallel||\\&amp;\leq\lambda_\min\sum_l|Q_l-Q_\min|-\frac{e}{\sqrt{L}}||Q_\parallel||\\&amp;=-||Q-Q_\min\cdot\vec{1}||\cdot\lambda_\min-\frac{e}{\sqrt{L}}||Q_\parallel||\\&amp;\leq-||Q-Q_\min\cdot\vec{1}||\lambda_\min-\frac{e}{\sqrt{L}}||Q_\parallel||\\&amp;\leq-||Q-\frac{1}{L}Q_\Sigma\cdot\vec{1}||\cdot\lambda_\min-\frac{e}{\sqrt{L}}||Q_\parallel||\\&amp;\leq-\delta||Q_\perp||-\frac{e}{\sqrt{L}}||Q_\parallel||\end{split}\]</span> <span class="math display">\[\begin{split}\mathbb{E}\{\Delta{}W_\parallel(Q)|Q\}&amp;=\mathbb{E}\{&lt;c,Q(t+1)&gt;^2-&lt;c,Q(t)&gt;^2|Q\}\\&amp;=\mathbb{E}\{&lt;c,Q+A-S+u&gt;^2-&lt;c,Q&gt;^2|Q\}\\&amp;\cdots\rm{here~I~omit~something}\cdots\\&amp;\geq-\frac{2e}{\sqrt{L}}||Q_\parallel||-K_2\end{split}\]</span></p><h2 id="max-weight">Max Weight</h2><p>Assumptions:</p><ul><li><span class="math inline">\(\vec{S}(t)=(S_l(t))\in\vec{S}\)</span></li><li><span class="math inline">\(A_l(t)\)</span> independent over <span class="math inline">\(l\)</span></li><li><span class="math inline">\(A_l(t)\)</span> iid over <span class="math inline">\(t\)</span></li><li><span class="math inline">\(A_l(t)\leq{}A_\max,S_l(t)\leq{}S_\max\)</span></li></ul><p>Policy:</p><p><span class="math display">\[\vec{S}(t)=\text{RAND}\{\arg\max_{s\in\vec{S}}&lt;Q(t),S&gt;\}\]</span></p><h3 id="capacity-region">Capacity Region</h3><p><span class="math display">\[\mathcal{R}=\text{conv}(\vec{S})\]</span></p><p>Assume finite size and non-negative of <span class="math inline">\(\vec{S}\)</span>, then: <span class="math display">\[\mathcal{R}=\{r\geq0,&lt;c^{(k)},r&gt;\leq{}b^{(k)}\}\]</span> <span class="math display">\[\mathcal{H}^{(k)}=\{r:&lt;c^{(k)},r&gt;=b^{(k)}\}\]</span> <span class="math display">\[\mathcal{F}^{(k)}=\mathcal{H}^{(k)}\cap{}\mathcal{R}\]</span></p><h4 id="lemma-4">Lemma 4</h4><ul><li>if <span class="math inline">\(\lambda\notin\mathcal{R}\)</span>, it is unstable</li><li><span class="math inline">\(\lambda\in\text{int}\mathcal{R}\)</span>, <span class="math inline">\(\{Q_l(t)\}\rightarrow\bar{Q}\)</span> with <span class="math inline">\(\mathbb{E}\{||Q||^r\}\leq{}M_r\)</span></li></ul><h3 id="lower-bound-1">Lower Bound</h3><p>Define:</p><p><span class="math display">\[e^{(k)}=\min_{r\in\mathcal{H}}||\lambda-r||\]</span> <span class="math display">\[\lambda^{(k)}=\lambda+e^{(k)}c^{(k)}\]</span> <span class="math display">\[K_\lambda=\{K\in\{1,\cdots,k\},\lambda^{(k)}\in\mathcal{R}\}\]</span> <span class="math display">\[K_\lambda^\circ=\{k\in{}K_\lambda,\lambda^{(k)}\in\rm{int}\mathcal{F}^{(k)}\}\]</span> <span class="math display">\[\alpha^{(k)}(t)=&lt;c^{(k)},A(t)&gt;,\beta^{(k)}(t)=b^{(k)}\]</span> <span class="math display">\[Q_\parallel^{(k)}=&lt;c^{(k)},Q(t)&gt;c^{(k)},Q_\perp=Q-Q_\parallel^{(k)}\]</span></p><h4 id="lemma-5">Lemma 5</h4><p>Assume <span class="math inline">\(\lambda\in\rm{int}\mathcal{R}\)</span> with set <span class="math inline">\(e^{(k)}\)</span>. Then under MW, for each <span class="math inline">\(k\in{}K_\lambda^\circ\)</span>, <span class="math inline">\(\exists{}\)</span> finite <span class="math inline">\(\{N_r^{(k)}\}_{k=1,2,\cdots}\)</span> s.t.</p><p><span class="math display">\[\mathbb{E}\{||\bar{Q}_\perp^{(k)}||^r\}\leq{}N_r^{(k)}\]</span></p><p>for all <span class="math inline">\(e&gt;0\)</span>, each Face <span class="math inline">\(k\)</span> belonging to <span class="math inline">\(K_\lambda^\circ\)</span> as <span class="math inline">\(e\rightarrow0\)</span> and each <span class="math inline">\(r=1,2,\cdots\)</span></p><p>Further proof is available in the reference.</p><h2 id="reference">Reference</h2><p>[1] Eryilmaz A, Srikant R. Asymptotically tight steady-state queue length bounds implied by drift conditions[J]. Queueing Systems, 2012, 72(3-4): 311-359.</p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network Optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Max Weight, Back Pressure and Utility Maximization</title>
      <link href="2019/09/16/Max%20Weight,%20Back%20Pressure%20and%20Utility%20Maximization/"/>
      <url>2019/09/16/Max%20Weight,%20Back%20Pressure%20and%20Utility%20Maximization/</url>
      
        <content type="html"><![CDATA[<h2 id="queue-control-problem">Queue Control Problem</h2><p><span class="math inline">\(A_1(t),A_2(t),Q_1(t),Q_2(t),\mu_1(t),\mu_2(t)\)</span></p><ul><li><span class="math inline">\(A_i(t)\)</span> is iid, <span class="math inline">\(\mathbb{E}\{A_i(t)\}=\lambda_i\)</span>, <span class="math inline">\(A_i(t)\in[0,A_{\max}]\)</span></li><li><span class="math inline">\(S_i(t)\)</span> is condition of link <span class="math inline">\(i\)</span>, <span class="math inline">\(S_i(t)\in\{0,1\}\)</span></li><li><span class="math inline">\(P_{xy}=P_r\{S_1(t)=x,S_2(t)=y\}\)</span></li><li>At every time, serve <span class="math inline">\(Q_1(t)\)</span> or <span class="math inline">\(Q_2(t)\)</span></li><li><span class="math inline">\(\mu_i(t)=1\text{ if } S_i(t)=1,Q_i(t)&gt;0\quad0\text{ otherwise}\)</span></li><li>Goal: stabilize both queues</li></ul><p><span class="math inline">\(~\)</span> <a id="more"></a></p><h3 id="linear-program">Linear Program</h3><p><span class="math display">\[\max~e\]</span> <span class="math display">\[\begin{split}s.t.~\lambda_1+e&amp;\leq{}P_{10}+P_{11}\theta\\\lambda_2+e&amp;\leq{}P_{01}+(1-\theta)P_{11}\end{split}\]</span></p><ul><li>optimal value <span class="math inline">\(e^\star&gt;0\)</span></li><li>LP policy is obvious</li><li>If we know all <span class="math inline">\(\lambda_i\)</span> and <span class="math inline">\(P_{xy}\)</span></li></ul><h3 id="alg-max-weight">ALG Max-Weight</h3><ul><li>Policy is simple<ul><li><span class="math inline">\(S(t)=\{1,0\}\)</span>, serve <span class="math inline">\(Q_1\)</span></li><li><span class="math inline">\(S(t)=\{0,1\}\)</span>, serve <span class="math inline">\(Q_2\)</span></li><li><span class="math inline">\(S(t)=\{1,1\}\)</span>, serve <span class="math inline">\(\max\{Q_1,Q_2\}\)</span></li></ul></li><li>Without any infomation</li></ul><hr /><p><span class="math display">\[L(t)=\frac{1}{2}Q_1^2(t)+\frac{1}{2}Q_2^2(t)\]</span> <span class="math display">\[Q_i(t+1)=(Q_i(t)-\mu_i(t)+A_i(t))^+\]</span> <span class="math display">\[\begin{split}\Delta(t)&amp;=\mathbb{E}\{L(t+1)-L(t)|Q(t)\}\\&amp;=\frac{1}{2}\mathbb{E}\{Q_1^2(t+1)-Q_1^2(t)+Q_2^2(t+1)-Q_2^2(t)|Q(t)\}\\&amp;\leq{}B-\mathbb{E}\{Q_1(t)[\mu_1(t)-A_1(t)]+Q_2(t)[\mu_2(t)-A_2(t)]|Q(t)\}\\&amp;=B+\lambda_1Q_1(t)+\lambda_2Q_2(t)-\mathbb{E}\{Q_1(t)\mu_1(t)+Q_2(t)\mu_2(t)|Q(t)\}\\&amp;\leq{}B+\lambda_1Q_1(t)+\lambda_2Q_2(t)-Q_1(t)[P_{10}+P_{11}\theta]-Q_2(t)[P_{01}+P_{11}(1-\theta)]\\&amp;=B-eQ_1(t)-eQ_2(t)\end{split}\]</span></p><h3 id="capacity-region">Capacity Region</h3><p><span class="math inline">\(\lambda=(\lambda_1,\lambda_2,\dots,\lambda_n)\)</span></p><ul><li>Def: The capacity region <span class="math inline">\(\Lambda\)</span> is the closure of <span class="math inline">\(\lambda\)</span> under which exists an algorithm that can stabilize the system</li><li>Claim: <span class="math inline">\(\Lambda=\{(\lambda_1,\lambda_2,\dots,\lambda_n)\text{ s.t. }e(\lambda)\geq0\}\)</span></li><li>Corollary: Max-weight stabilizes the system whenever <span class="math inline">\(\exists{}e\geq0\text{ s.t. } \lambda+e\in\Lambda\)</span></li><li>So, in some way, Max-weight is "Throughput Optimal"</li></ul><h3 id="caratheodorys-theorem">Caratheodory's Theorem</h3><p>Let <span class="math inline">\(X\)</span> be a subset of <span class="math inline">\(R^d\)</span>. If <span class="math inline">\(x\in\text{conv}(X)\)</span>, then <span class="math inline">\(\exists~d+1\)</span> points in <span class="math inline">\(X\)</span> (i.e. <span class="math inline">\(x_1,\dots,x_{d+1}\)</span>), s.t. <span class="math display">\[x=\sum_{i=1}^{d+1}\alpha_ix_i,\alpha_i\geq0,\sum_{i=1}^{d+1}\alpha_i=1\]</span></p><h2 id="multi-hop">Multi-Hop</h2><ul><li><span class="math inline">\(V=\{1,2,\dots,7\}\)</span></li><li><span class="math inline">\(E\)</span> are linkes</li><li><span class="math inline">\(A_n^{(k)(t)}\)</span> is packages entering <span class="math inline">\(n\)</span> for destination <span class="math inline">\(k\)</span>, <span class="math inline">\(\mathbb{E}\{A_n^{(k)}(t)\}=\lambda_n^{(k)}\in[0,A_{\max}]\)</span></li><li><span class="math inline">\(S(t)=(S_{nm}(t),[n,m]\in{}E)\)</span>, <span class="math inline">\(S_{n,m}\in\{0,1\}\)</span>, iid</li><li><span class="math inline">\(\mu_{nm}(t)=1\text{ if }S_{nm}(t)=1\text{ and use link }[n,m]\quad0\text{ otherwise}\)</span></li><li>No interference</li><li>Queueing: <span class="math inline">\(Q_n^{(k)}(t)\)</span></li><li><span class="math inline">\(Q_n^{(k)}(t+1)\leq{}(Q_n^{(k)}(t)-\sum_{[n,m]\in{}E}\mu_{nm}^{(k)}(t))^+{}+\sum_{[a,n]\in{}E}\mu_{an}^{(k)}(t)+A_n^{(k)}(t)\)</span></li><li><span class="math inline">\(Q_n^{(0)}(t)=0\)</span></li><li>Goal: stabilize all queues</li></ul><h3 id="back-pressure">Back Pressure</h3><p>At time <span class="math inline">\(t\)</span>, observe <span class="math inline">\(Q_n^{(k)}(t)\)</span> for all <span class="math inline">\(n,k\)</span></p><ul><li>For each <span class="math inline">\([n,m]\)</span>, define weight <span class="math inline">\(W_{nm}(t)=\max_k[Q_n^{(k)}(t)-Q_m^{(k)}(t)]^+\)</span> and let <span class="math inline">\(k^\star=\arg\max{}W_{nm}^{(k)}(t)\)</span></li><li>If <span class="math inline">\(W_{nm}(t)&gt;0\)</span>, <span class="math inline">\(\mu_{nm}^{(k)}(t)=\mu_{nm}(t)\text{ if }k=k^\star\quad0\text{ otherwise}\)</span></li><li>If <span class="math inline">\(W_{nm}(t)=0\)</span>, <span class="math inline">\(\mu_{nm}^{(k)}(t)=0\)</span></li></ul><h3 id="analysis">Analysis</h3><p><span class="math inline">\(Q(t)=(Q_n^{(k)}(t)),L(Q(t))=\frac{1}{2}\sum_{n,k}Q_n^{(k)}(t)^2\)</span> <span class="math display">\[\begin{split}\Delta(t)&amp;=\mathbb{E}\{L(t+1)-L(t)|Q(t)\}\\&amp;\leq{}B-\mathbb{E}\{\sum_{n,k}Q_n^{(k)}(t)[\sum_{[n,m]\in{}E}\mu_{nm}^{(k)}(t)-\sum_{[a,n]\in{}E}\mu_{an}^{(k)}(t)-A_n^{(k)}(t)]|Q(t)\}\\&amp;=B-\sum_{n,m,k}\mathbb{E}\{\mu_{nm}^{(k)}(t)[Q_n^{(k)}(t)-Q_m^{(k)}(t)]|Q(t)\}+\sum_{n,k}Q_n^{(k)}(t)\lambda_n^{(k)}\\&amp;\leq{}B-e\sum_{nm}Q_n^{(k)}(t)\end{split}\]</span></p><hr /><p><span class="math display">\[\max{}e\]</span> <span class="math display">\[\begin{split}s.t.~\lambda_n^{(k)}+e+\sum_{[a,n]}f_{an}^{(k)}&amp;\leq\sum_{[n,m]}f_{nm}^{(k)}\\\sum_kf_{nm}^{(k)}&amp;\leq\mu_{nm}\\f_{nm}^{(k)}&amp;\geq0\end{split}\]</span></p><h3 id="interference-problem">Interference Problem</h3><p><span class="math display">\[\max~\sum_{n,m,k}\mu_{nm}^{(k)}(t)[Q_n^{(k)}(t)-Q_m^{(k)}(t)]^+\]</span> <span class="math display">\[s.t.~\sum_k\mu_{nm}^{(k)}(t)\leq\mu_{nm}(I(t),S(t)),I(t)\text{ feasible}\]</span></p><h2 id="utility-maximization-in-networks">Utility Maximization in Networks</h2><ul><li><span class="math inline">\(A_n^{(k)}(t)\)</span>: # of pkts arrivals to <span class="math inline">\(n\)</span> for <span class="math inline">\(k\)</span> at t</li><li><span class="math inline">\(R_n^{(k)}(t)\)</span>: # of pkts admitted (admission control), <span class="math inline">\(0\leq{}R_n^{(k)}(t)\leq{}R_{\max}\)</span></li><li><span class="math inline">\(S(t)=(S_{nm}(t),[n,m]\in{}E)\)</span>, <span class="math inline">\(S_{n,m}\in\{0,1\}\)</span>, iid</li><li><span class="math inline">\(Q_n^{(k)}(t+1)\leq{}(Q_n^{(k)}(t)-\sum_{[n,m]\in{}E}\mu_{nm}^{(k)}(t))^+{}+\sum_{[a,n]\in{}E}\mu_{an}^{(k)}(t)+R_n^{(k)}(t)\)</span></li><li><span class="math inline">\(\bar{r}_n^{(k)}=\lim_{T\rightarrow\infty}\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\{R_n^{(k)}(t)\}\)</span></li><li><span class="math inline">\(g_n^{(k)}(\cdot)\)</span> is utility function which is usually concave increasing</li><li>Goal: <span class="math display">\[\max\sum_{n,k}g_n^{(k)}(\bar{r}_n^{(k)}),\text{ s.t. stability}\]</span></li></ul><h3 id="lyapunov-function">Lyapunov function</h3><p><span class="math display">\[L(Q(t))=\frac{1}{2}\sum_{n,k}Q_n^{(k)}(t)^2\]</span> <span class="math display">\[\begin{split}\Delta(t)&amp;\leq{}B-\mathbb{E}\{\sum_{n,k}Q_n^{(k)}(t)[\sum_{[n,m]\in{}E}\mu_{nm}^{(k)}(t)-\sum_{[a,n]\in{}E}\mu_{an}^{(k)}(t)-R_n^{(k)}(t)]|Q(t)\}\\\text{subtract from both sides the term}&amp; \\ &amp;V\sum_{n,k}\mathbb{E}\{g_n^{(k)}(R_n^{(k)}(t))|Q_n(t)\}\\\Delta(t)-V\sum_{n,k}\mathbb{E}\{g_n^{(k)}(R_n^{(k)}(t))|Q_n(t)\}&amp; \leq{}B-\sum_{n,k}\mathbb{E}\{Vg_n^{(k)}(R_n^{(k)}(t))-Q_n^{(k)}(t)R_n^{(k)}(t)|Q(t)\}\\&amp;-\sum_{n,m,k}\mathbb{E}\{\mu_{nm}^{(k)}(t)[Q_n^{(k)}(t)-Q_m^{(k)}(t)]|Q(t)\}\end{split}\]</span></p><h3 id="cross-longer-control">Cross-Longer Control</h3><p>At time <span class="math inline">\(t\)</span>, observe <span class="math inline">\(S(t)\)</span> and <span class="math inline">\(Q(t)\)</span></p><ul><li>Admission control (Application): Choose <span class="math inline">\(R_n^{(k)}(t)\)</span></li></ul><p><span class="math display">\[\max{}Vg_n^{(k)}(R_n^{(k)}(t))-Q_n^{(k)}(t)R_n^{(k)}(t),\text{ s.t. }0\leq{}R_n^{(k)}(t)\leq{}R_{\max}\]</span></p><ul><li>Scheduling and Routing (Transport): Define <span class="math inline">\(W_{nm}(t)=\max_k[Q_n^{(k)}(t)-Q_m^{(k)}(t)]^+\)</span>, choose</li></ul><p><span class="math display">\[\mu_{nm}^{(k)}(t)=\mu_{nm}(t)\text{ if }k=k^\star\quad0\text{ otherwise}\]</span></p><ul><li>Resource Allocation (Physical): Choose <span class="math inline">\(\mu(t)\)</span></li></ul><p><span class="math display">\[\max\sum_{n,m}W_{nm}(t)\mu_{nm}(t),\text{ s.t. }\mu(t)\text{ is feasible}\]</span></p><h3 id="queue-independent-policy">Queue Independent Policy</h3><p><span class="math display">\[\begin{split}\max&amp;\sum_{n,k}g_n^{(k)}(r_n^{(k)})\\\text{s.t. }r_n^{(k)}+\sum_{a,n}f_{an}^{(k)}&amp;\leq{}f_{nm}^{(k)}\\\sum_kf_{nm}^{(k)}&amp;\leq\mu_{nm}\\\mu=(\mu_{nm},[n,m]\in{}E)&amp;\in\sum_{S}\beta_S\text{conv}(\Gamma_S)\end{split}\]</span></p><p><span class="math inline">\(r_n^{(k)\star}\)</span>, <span class="math inline">\(f_{nm}^{(k)\star}\)</span>, <span class="math inline">\(\mu_{nm}^{(k)\star}\)</span> refers to a stationary randomized policy</p><p><span class="math display">\[\Rightarrow{}\Delta-V\sum_{n,k}\mathbb{E}\{g_n^{(k)}(R_n^{(k)}(t))|Q_n(t)\}\leq{}B-V\cdot\text{opt}\]</span></p><p>Sum over <span class="math inline">\(t=0,\cdots,T-1\)</span>, take expectation</p><p><span class="math display">\[\begin{split}\mathbb{E}\{L(t)\}-\mathbb{E}\{L(0)\}-\sum_tV\sum_{n,k}\mathbb{E}\{g_n^{(k)}(R_n^{(k)}(t))|Q(t)\}&amp;\leq{}BT-VT\cdot{}\text{opt}\\\sum_tV\sum_{n,k}\mathbb{E}\{g_n^{(k)}(R_n^{(k)}(t))|Q(t)\}&amp;\geq{}-BT+VT\cdot{}\text{opt}-\mathbb{E}\{L(0)\}\end{split}\]</span></p><p>If consider <span class="math inline">\(g_n^{(k)}(\cdot)\)</span> as concave increasing, we can use Jensen Inequality to put the expectation sign inside.</p><h4 id="utility-performance">Utility Performance</h4><p><span class="math display">\[\sum_{n,k}g_n^{(k)}(r_n^{(k)}(t))\geq{}\text{opt}-\frac{B}{V}\]</span></p><h3 id="delay-bound">Delay Bound</h3><p>Assume <span class="math inline">\(r_n^{(k)\star}\geq{}e&gt;0\)</span></p><p><span class="math display">\[r_n^{(k)&#39;}=r_n^{(k)\star}-e,~f_{nm}^{(k)&#39;}=f_{nm}^{(k)\star}\]</span> <span class="math display">\[\begin{split}\Delta(t)-V\mathbb{E}\{\sum_{n,k}g_n^{(k)}(R_n^{(k)}(t))|Q(t)\}&amp;\leq{}B-e\sum_{n,k}Q_n^{(k)}(t)\\\Delta(t)&amp;\leq{}B+Vg_{\max}-e\sum_{n,k}Q_n^{(k)}(t)\\\bar{Q}(t)&amp;\leq\frac{B+Vg_{\max}}{e}\sim\mathcal{O}(V)\end{split}\]</span></p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network Optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Introduction to Queue and Lyapunov Analysis</title>
      <link href="2019/09/09/Introduction%20to%20Queue%20and%20Lyapunov%20Analysis/"/>
      <url>2019/09/09/Introduction%20to%20Queue%20and%20Lyapunov%20Analysis/</url>
      
        <content type="html"><![CDATA[<h2 id="queue">Queue</h2><h3 id="definition">Definition</h3><ul><li>Arrival: <span class="math inline">\(A(t)\)</span></li><li>Cumulative arrival: <span class="math display">\[X[t_1,t_2]=\int_{t_1}^{t_2}A(t)dt\]</span></li><li>Service: <span class="math inline">\(\mu(t)\)</span></li><li>Cumulative departure: <span class="math display">\[Y[t_1,t_2]=\int_{t_1}^{t_2}Y(t)dt\leq\int_{t_1}^{t_2}\mu(t)dt\]</span></li><li><span class="math inline">\(Y(t)=Q(t)~if~Q(t)&gt;0\quad0~otherwise\)</span></li><li><span class="math inline">\(Q(t)=X[0,t]-Y[0,t],Q(0)=0\)</span></li></ul><a id="more"></a><h3 id="interval-and-conserving">Interval and Conserving</h3><ul><li>Def: An interval <span class="math inline">\(I=[t_1,t_2]\)</span> is a busy period if <span class="math inline">\(Y(t)&gt;0,\forall{}t\in{}I\)</span> and <span class="math inline">\(Y(t_1^-)=Y(t_2^+)=0\)</span></li><li>Def: A work conserving single server system is one where <span class="math inline">\(Y(t)=\mu(t)\)</span> wherever <span class="math inline">\(Q(t)&gt;0\)</span></li></ul><p>If we start from an empty system, and <span class="math inline">\(Q(t)&gt;0\)</span>, then <span class="math display">\[\exists{}t^* \text{ with } Q(t^*)=0 \text{ s.t. } Q(t)=X[t^*,t]-\int_{t^*}^t\mu(t)dt\]</span></p><h3 id="stability">Stability</h3><ul><li>Def: <span class="math inline">\(X[0,t]\)</span> has a rate <span class="math inline">\(\lambda\)</span> if <span class="math inline">\(\lim_{t\rightarrow\infty}\frac{X[0,t]}{t}=\lambda\)</span> w.p.1</li><li>Def: <span class="math inline">\(\mu(t)\)</span> has rate <span class="math inline">\(\mu\)</span> if <span class="math inline">\(\lim_{t\rightarrow\infty}\frac{\int_0^t\mu(t)}{t}=\mu\)</span> w.p.1</li><li>Def: <span class="math inline">\(Q(t)\)</span> is rate stable if <span class="math inline">\(\lim_{t\rightarrow\infty}\frac{Q(t)}{t}=0\)</span> w.p.1</li><li>Def: <span class="math inline">\(Q(t)\)</span> is mean rate stable if <span class="math inline">\(\lim_{t\rightarrow\infty}\frac{E[Q(t)]}{t}=0\)</span></li></ul><h4 id="theorem-rate-stability">Theorem-Rate Stability</h4><p>Suppose <span class="math inline">\(Q(t)=X[0,t]-Y[0,t]\)</span>, and <span class="math inline">\(X[0,t]\)</span> has rate <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu(t)\)</span> has rate <span class="math inline">\(\mu\)</span>, then <span class="math inline">\(Q(t)\)</span> is rate stable <strong>if and only if</strong> <span class="math inline">\(\lambda\leq\mu\)</span></p><hr /><p><span class="math display">\[Q(t)\text{ stable } \rightarrow\lambda\leq\mu\]</span> <span class="math display">\[\frac{Q(t)}{t}=\frac{X[0,t]}{t}-\frac{Y[0,t]}{t}\geq\frac{X[0,t]}{t}-\frac{\int_0^t\mu(t)}{t}\]</span></p><hr /><p><span class="math display">\[Q(t)\text{ stable } \leftarrow\lambda\leq\mu\]</span></p><h3 id="littles-law">Little's law</h3><p><span class="math display">\[Q_{av}=\lim_{t\rightarrow\infty}\frac{1}{t}\int_{\tau=0}^tQ(\tau)d\tau,D_{av}=\lim_{k\rightarrow\infty}\frac{1}{k}\sum_{k=1}^kD_k\]</span> <span class="math display">\[\Rightarrow{}Q_{av}=\lambda{}D_{av}\]</span></p><h2 id="lyapunov-analysis">Lyapunov Analysis</h2><h3 id="definition-1">Definition</h3><p>Denote <span class="math inline">\(\vec{Q}(t)=(Q_1(t),\dots,Q_k(t))\)</span>, Def <span class="math inline">\(L(\vec{Q}(t))\)</span> is a Lyapunov-function if</p><ul><li><span class="math inline">\(L(\vec{Q}(t))\geq0\)</span></li><li><span class="math inline">\(L(0)=0\)</span></li></ul><p>Define one-slot conditional Lyapunov drift <span class="math display">\[\Delta(t)=E\{L(\vec{Q}(t+1))-L(\vec{Q}(t))|\vec{Q}(t)\}\]</span></p><h3 id="theorem">Theorem</h3><p>Suppose <span class="math inline">\(L(\vec{Q}(t))\)</span> is a Lyapunov function and satisifes <span class="math inline">\(\Delta(t)\leq{}B-e\sum_kQ_k(t)\)</span> and <span class="math inline">\(L(\vec{Q}(0))&lt;\infty\)</span>, then</p><ul><li><span class="math inline">\(e&gt;0\rightarrow{}Q(t)\)</span> is strongly stable <span class="math display">\[\lim_{T\rightarrow\infty}\sup\frac{1}{T}\sum_{t=0}^{T-1}\sum_kE\{Q_k(t)\}\leq\frac{B}{e}\]</span></li><li><span class="math inline">\(e\geq0\)</span> and <span class="math inline">\(L(\vec{Q})=\sum_k{}w_kQ_k\)</span>, then <span class="math display">\[\lim_{t\rightarrow\infty}\frac{E\{Q_k(t)\}}{t}=0,\forall{}k\]</span></li></ul><hr /><p>Proof is made by list the inequality from <span class="math inline">\(t=0\)</span> to <span class="math inline">\(t=T\)</span> and sum them up. For the first one, divide by <span class="math inline">\(T\)</span> then is obvious. For the second one, put exception into square, the left side is <span class="math inline">\(O(\sqrt{T})\)</span>.</p><h4 id="example">Example</h4><p><span class="math inline">\(A(t), \mu(t), \sim{}Bernoulli~\lambda,\mu\)</span> <span class="math display">\[Q(t+1)=(Q(t)-\mu(t)+A(t))^+,L(Q(t))=\frac{1}{2}Q^2(t)\]</span> <span class="math display">\[\Delta(t)=\frac{1}{2}E\{Q^2(t+1)-Q^2(t)|Q(t)\}\leq\cdots=E\{\frac{1}{2}(\mu(t)-A(t))^2-Q(t)(\mu(t)-A(t))|Q(t)\}\leq\frac{1}{2}-Q(t)(\mu-\lambda)\]</span> <span class="math display">\[\bar{Q}(t)\leq\frac{1}{2(\mu-\lambda)}\]</span></p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network Optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Optimal Transport</title>
      <link href="2019/05/25/Optimal%20Transport/"/>
      <url>2019/05/25/Optimal%20Transport/</url>
      
        <content type="html"><![CDATA[<h2 id="wasserstein-distance">Wasserstein Distance</h2><h3 id="definition">Definition</h3><p>Consider, general functions <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span>, the Wasserstein distance is <span class="math display">\[\min_{\text{all map }T}\{\sum_{\text{all movements of }T}\text{distance moved}\times\text{amount moved}\}\]</span> For <span class="math inline">\(f:X\rightarrow{}R^+,g:Y\rightarrow{}R^+\)</span>, the distance can be formulated as <span class="math display">\[W_p(f,g)=\left(\inf_{T\in\mathcal{M}}\int{}|x-T(x)|^pf(x)dx\right)^{1/p}\]</span> where <span class="math inline">\(\mathcal{M}\)</span> is the set of all maps that rearrange the distribution <span class="math inline">\(f\)</span> into <span class="math inline">\(g\)</span>.</p><a id="more"></a><h3 id="quadratic-wasserstein-distance-p2">Quadratic Wasserstein distance: <span class="math inline">\(p=2\)</span></h3><p><span class="math display">\[W_2^2(f,g)=\inf_{T\in\mathcal{M}}\int{}|x-T(x)|^pf(x)dx\]</span></p><h2 id="kantorovich-problem">Kantorovich Problem</h2><h3 id="definition-1">Definition</h3><p><span class="math display">\[\inf_\gamma\left\{\int_{X\times{}Y}c(x,y)d\gamma|\gamma\geq0,\gamma\in\Pi(\mu,\nu)\right\}\]</span> where <span class="math inline">\(\Pi(\mu,\nu)=\{\gamma\in\mathcal{P}(X\times{}Y)|(P_X)\#\gamma=\mu,(P_Y)\#\gamma=\nu\}\)</span>, <span class="math inline">\(P_X\)</span> and <span class="math inline">\(P_Y\)</span> are two projections</p><h3 id="kantorovich-dual-problem">Kantorovich Dual Problem</h3><p>Consider <span class="math inline">\(\varphi\in{}L^1(\mu)\)</span> and <span class="math inline">\(\psi\in{}L^1(\nu)\)</span>, the Kantorovich dual problem is formulated as the following: <span class="math display">\[\sup_{\varphi,\psi}\left(\int_X\varphi{}d\mu+\int_Y\psi{}d\nu\right)\]</span> subject to <span class="math inline">\(\varphi(x)+\psi(y)\leq{}c(x,y)\)</span>, for any <span class="math inline">\((x,y)\in{}X\times{}Y\)</span>.</br> Note that this dual formulation is a linear optimization problem which is solvable by linear programming.</p><h2 id="dynamic-formulation">Dynamic Formulation</h2><p>The Benamou-Brenier formula identifies the squared quadratic Wasserstein metric between <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\nu\)</span> by: <span class="math display">\[W_2^2(\mu,\nu)=\inf\int_0^1\int|v(t,x)|^2\rho(t,x)dxdt\]</span> where infimum is taken among all the Borel fields <span class="math inline">\(v(t,x)\)</span> that transports <span class="math inline">\(\mu\)</span> to <span class="math inline">\(\nu\)</span> continuously in time, satisfying the zero flux condition on the boundary: <span class="math display">\[\begin{split}\frac{\partial\rho}{\partial{}t}+\nabla(v\rho)&amp;=0\\\text{subject to }\rho(0,x)=d\mu,\rho(1,x)&amp;=d\nu\end{split}\]</span></p><h2 id="monge-ampere-equation">Monge-Ampere Equation</h2><p><span class="math display">\[\left\{\begin{split}&amp;det(D^2u(x))=f(x)/g(\nabla{}u(x))\\&amp;\nabla{}u:X\rightarrow{}Y\\&amp;u\text{ is convex}\end{split}\right.\]</span> The optimal map is <span class="math inline">\(\nabla{}u\)</span>. Thus, the square of the quadratic Wasserstein distance has the form: <span class="math display">\[W_2^2(f,g)=\int{}|x-\nabla{}u(x)|^2f(x)dx\]</span></p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operations Research </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Proximal Mapping</title>
      <link href="2019/04/25/Proximal%20Mapping/"/>
      <url>2019/04/25/Proximal%20Mapping/</url>
      
        <content type="html"><![CDATA[<h2 id="closed">Closed</h2><h3 id="closed-set">Closed set</h3><p>A set <span class="math inline">\(\mathcal{C}\)</span> is closed if it contains its boundary: <span class="math display">\[x^k\in\mathcal{C},x^k\rightarrow\bar{x}\Rightarrow\bar{x}\in\mathcal{C}\]</span></p><ul><li>the intersection of closed sets is closed</li><li>the union of a finite number of closed sets is closed</li><li>inverse under linear mapping <span class="math display">\[\{x|Ax\in\mathcal{C}\}\]</span> is closed if <span class="math inline">\(\mathcal{C}\)</span> is closed</li></ul><a id="more"></a><h3 id="closed-function">Closed function</h3><p>a function is closed if its epigraph is a closed set or if all its sublevel set is a closed set</p><ul><li>If <span class="math inline">\(f\)</span> is continuous and <span class="math inline">\(dom~f\)</span> is closed, then <span class="math inline">\(f\)</span> is closed</li><li>If <span class="math inline">\(f\)</span> is continuous and <span class="math inline">\(dom~f\)</span> is open, then <span class="math inline">\(f\)</span> is closed iff it converges to <span class="math inline">\(\infty\)</span> along every sequence converging to a boundary point of <span class="math inline">\(dom~f\)</span></li></ul><h3 id="properties">Properties</h3><ul><li>sublevel sets: <span class="math inline">\(f\)</span> is closed iff all its subsevel sets are closed</li><li>minimum: if <span class="math inline">\(f\)</span> is closed with bounded sublevel sets then it has a minimizer</li></ul><h2 id="conjugate-function">Conjugate function</h2><h3 id="conjugate-functions-recall">Conjugate functions: recall</h3><ul><li>the conjugate of a function <span class="math inline">\(f\)</span> is always closed and convex</li><li>The indicator function of convex set <span class="math inline">\(\mathcal{C}\)</span>: conjugate is support function of <span class="math inline">\(\mathcal{C}\)</span></li><li>Norm: conjugate is indicator of unit dual norm ball</li></ul><h3 id="second-conjugate">Second conjugate</h3><p><span class="math display">\[f^{**}(x)=\sup_{y\in{}dom~f^*}(x^\top{}y-f^*(y)))\]</span></p><ul><li><span class="math inline">\(f^{**}\)</span> is closed and convex</li><li><span class="math inline">\(f^{**}\leq{}f(x)\)</span></li><li>if <span class="math inline">\(f\)</span> is closed and convex, then <span class="math inline">\(f^{**}\leq{}f(x)\)</span></li></ul><h3 id="calculus-rules">Calculus rules</h3><h4 id="separable-sum">Separable sum</h4><p><span class="math display">\[f(x_1,x_2)=g(x_1)+h(x_2),f^*(y_1,y_2)=g^*(y_1)+h^*(y_2)\]</span></p><h4 id="scalar-multiplication">Scalar multiplication</h4><p><span class="math display">\[\alpha{}&gt;0,f(x)=\alpha{}g(x),f^*(y)=\alpha{}g^*(y/\alpha{})\]</span></p><h4 id="addition-to-affine-function">Addition to affine function</h4><p><span class="math display">\[f(x)=g(x)+a^\top+b,f^*(y)=g^*(y-a)-b\]</span></p><h4 id="infimal-convolution">Infimal convolution</h4><p><span class="math display">\[f(x)=\inf_{u+v=x}(g(u)+h(v)),f^*(y)=g^*(y)+h^*(y)\]</span></p><h2 id="proximal-mapping">Proximal mapping</h2><p>Definition: the proximal mapping of a closed convex function <span class="math inline">\(f\)</span> is: <span class="math display">\[\text{prox}_f(x)=\arg\min_u\left(f(u)+\frac{1}{2}||u-x||_2^2\right)\]</span></p><h4 id="example">Example</h4><p><span class="math display">\[u=\text{prox}_f(x)\Leftrightarrow{}0\in\partial{}f(u)+u-x\Leftrightarrow{}x-u\in\partial{}f(u)\Leftrightarrow{}f(z)\geq{}f(u)+(x-u)^\top(z-u)\]</span> If <span class="math inline">\(f(x)=\delta_C(x)\)</span>, <span class="math inline">\(C\)</span> is closed and convex <span class="math inline">\(\Rightarrow{}(x-u)^\top(z-u)\leq0\)</span></p><h3 id="calculus-rules-1">Calculus rules</h3><p><span class="math display">\[f(x)=\lambda{}g(x/\lambda)\Rightarrow{}\text{prox}_f(x)=\lambda\text{prox}_{\lambda^{-1}g}(x/\lambda)\]</span></p><h4 id="proof">Proof</h4><p><span class="math display">\[\text{prox}_f(x)=\arg\min_y\{f(y)+\frac{1}{2}||y-x||^2\}=\arg\min_{y,z}\{\lambda{}g(z)+\frac{1}{2}||\lambda{}z-x||_2^2\left|z=\frac{y}{\lambda}\}\right.\]</span> <span class="math display">\[L(y,z;\mu)=\lambda{}g(z)+\frac{1}{2}||\lambda{}z-x||_2^2+&lt;\lambda{}z-y,\mu&gt;\]</span> <span class="math display">\[\partial_yL=0,\partial_zL=0\Rightarrow{}z=\text{prox}_{\lambda^{-1}g}(x/\lambda)\]</span></p><h3 id="moreau-decomposition">Moreau decomposition</h3><p><span class="math display">\[x=\text{prox}_f(x)+\text{prox}_{f^*}(x)\quad{}\text{for all }x\]</span></p><h3 id="composition-with-affine-mapping">Composition with affine mapping</h3><ul><li>for general <span class="math inline">\(A\)</span>, prox-operator of <span class="math inline">\(f\)</span> does not follow easily from prox-operator of <span class="math inline">\(g\)</span></li><li>however, if <span class="math inline">\(AA^\top=(1/\alpha)I\)</span></li></ul><p><span class="math display">\[f(x)=g(Ax+b)\Rightarrow{}\text{prox}_f(x)=x-\alpha{}A^\top(Ax+b-\text{prob}_{\alpha^{-1}g}(Ax+b))\]</span></p><h2 id="projections">Projections</h2><h3 id="affine-sets">Affine sets</h3><p><span class="math inline">\(C=\{x|Ax=b\}\)</span>, with <span class="math inline">\(A\in{}R^{p\times{}n}\)</span> and <span class="math inline">\(\textbf{rank}(A)=p\)</span> <span class="math display">\[P_C(x)=x+A^\top(AA^\top)^{-1}(b-Ax)\]</span> inexpensive if <span class="math inline">\(p\ll{}n\)</span>, or <span class="math inline">\(AA^\top=I\)</span></p><h3 id="simple-polyhedral-sets">Simple polyhedral sets</h3><h4 id="halfspace">Halfspace</h4><p><span class="math inline">\(C=\{x|a^\top{}x\leq{}b\}\)</span> <span class="math display">\[P_C(x)=x+\frac{b-a^\top{}x}{||a||_2^2}a\quad\text{if }a^\top{}x&gt;b,\quad{}P_C(x)=x\quad\text{if }a^\top{}x\leq{}b\]</span></p><h4 id="probability-simplex">Probability simplex</h4><p><span class="math inline">\(C=\{x|\textbf{1}^\top{}x=1,x\succeq0\}\)</span> <span class="math display">\[P_C(x)=(x-\lambda\textbf{1})_{+}\]</span> where <span class="math inline">\(\lambda\)</span> is the solution of the equation <span class="math display">\[\textbf{1}^\top(x-\lambda\textbf{1})_{+}=\sum_{i=1}^n\max\{0,x_k-\lambda\}=1\]</span></p><h2 id="support-function-norm-and-distance">Support function, Norm and Distance</h2><h3 id="support-function">Support function</h3><ul><li>conjugate of support function of closed convex set is indicator function</li></ul><p><span class="math display">\[f(x)=\sup_{y\in{}C}x^\top{}y,f^*(y)=\delta_C(y)\]</span></p><ul><li>prox-operator of support function follows from Moreau decomposition</li></ul><p><span class="math display">\[\text{prox}_{tf}(x)=x-t\text{prox}_{t^{-1}f^*}(x/t)=x-tP_C(x/t)\]</span></p><h3 id="norm">Norm</h3><ul><li>conjugate of norm is indicator function of dual norm</li></ul><p><span class="math display">\[f(x)=||x||,f^*(y)=\delta_B(y),B=\{y|~||y||_*\leq1\}\]</span></p><ul><li>prox-operator of norm follows from Moreau decomposition</li></ul><p><span class="math display">\[\text{prox}_{tf}(x)=-P_{tB}(x)\]</span></p><h3 id="euclidean-distance-to-a-set">Euclidean distance to a set</h3><p><span class="math display">\[d(x)=\inf_{y\in{}C}||x-y||_2\]</span> <span class="math display">\[\text{prox}_{td}(x)=\left\{\begin{aligned}&amp;x+\frac{t}{d(x)}(P_C(x)-x)&amp;d(x)\geq{}t\\&amp;P_C(x)&amp;~\text{otherwise}\end{aligned}\right.\]</span></p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Convex Optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Subgradient Method</title>
      <link href="2019/04/16/Subgradient%20Method/"/>
      <url>2019/04/16/Subgradient%20Method/</url>
      
        <content type="html"><![CDATA[<h2 id="subgradient">Subgradient</h2><p><span class="math inline">\(g\)</span> is a subgradient of a convex function <span class="math inline">\(f\)</span> at <span class="math inline">\(x\in{}dom~f\)</span> if <span class="math display">\[f(y)\geq{}f(x)+g^\top(y-x)\quad\text{for all }y\in{}dom~f\]</span></p><a id="more"></a><h3 id="properties">Properties</h3><ul><li><span class="math inline">\(f(x)+g^\top(y-x)\)</span> is a global lower bound on <span class="math inline">\(f(y)\)</span></li><li><span class="math inline">\(g\)</span> defines non-vertical supporting hyperplane to <span class="math inline">\(epi~f\)</span> at <span class="math inline">\((x, f (x))\)</span></li><li>if <span class="math inline">\(f\)</span> is convex and differentiable, then <span class="math inline">\(\nabla{}f(x)\)</span> is a subgradient of <span class="math inline">\(g\)</span> at <span class="math inline">\(x\)</span></li></ul><h3 id="subdifferential">Subdifferential</h3><p>the subdifferential <span class="math inline">\(\partial{}f(x)\)</span> of <span class="math inline">\(f\)</span> at <span class="math inline">\(x\)</span> is the set of all subgradients: <span class="math display">\[\partial{}f(x)=\{g|g^\top(y-x)\leq{}f(y)-f(x),\forall{}y\in{}dom~f\}\]</span></p><h3 id="monotonicity">Monotonicity</h3><p>the subdifferential of a convex function is a monotone operator: <span class="math display">\[(u-v)^\top(x-y)\geq0,\text{for all }x,y,u\in\partial{}f(x),v\in\partial{}f(y)\]</span></p><h2 id="directional-derivative">Directional Derivative</h2><h3 id="introduction">Introduction</h3><p><span class="math display">\[f(x+d)=f(x)+\nabla{}f(x)^\top{}d\]</span> <span class="math display">\[\text{If }\nabla{}f(x)^\top{}d&lt;0,d\text{ is a descent direction}\]</span></p><h3 id="definition">Definition</h3><p>The directional derivative of <span class="math inline">\(f\)</span> at <span class="math inline">\(x\)</span> in the direction <span class="math inline">\(y\)</span> is <span class="math display">\[f^{&#39;}(x;y)=\lim_{a\searrow{}0}\frac{f(x+\alpha{}y)-f(x)}{\alpha}=\lim_{t\rightarrow\infty}(tf(x+\frac{y}{t})-tf(x))\]</span></p><ul><li><span class="math inline">\(f^{&#39;}(x;y)\)</span> is the right derivative of <span class="math inline">\(g(\alpha)=f(x+\alpha{}y)\)</span> at <span class="math inline">\(\alpha=0\)</span></li></ul><h4 id="proofexistence">Proof:Existence</h4><p><span class="math display">\[h(\alpha)=\frac{f(x+\alpha{}y)-f(x)}{\alpha}\]</span> <span class="math display">\[x+\alpha_1{}y=x+\frac{\alpha_1}{\alpha_2}x-\frac{\alpha_1}{\alpha_2}x+\frac{\alpha_1}{\alpha_2}\alpha_2y=(1-\frac{\alpha_1}{\alpha_2})x+\frac{\alpha_1}{\alpha_2}(x+\alpha_2y)\]</span> <span class="math display">\[f(x+\alpha_1{}y)\leq(1-\frac{\alpha_1}{\alpha_2})f(x)+\frac{\alpha_1}{\alpha_2}f(x+\alpha_2y)\text{ (convex)}\]</span> <span class="math display">\[h(\alpha_1)\leq{}h(\alpha_2)\]</span></p><h4 id="proofhomogeneous">Proof:Homogeneous</h4><p><span class="math display">\[\text{If }x\in\text{int dom}f\Rightarrow{}\text{dom}f^{&#39;}(x,y)=R^n\]</span> <span class="math display">\[\text{Let }\beta=\alpha\lambda,\text{ it is easy to prove}\]</span></p><h3 id="directional-derivative-and-subgradients">Directional derivative and subgradients</h3><p>For convex <span class="math inline">\(f\)</span> and <span class="math inline">\(x\in\text{int dom}f\)</span>: <span class="math display">\[f^{&#39;}(x;y)=\sup_{g\in\partial{}f(x)}g^\top{}y\]</span></p><ul><li>generalize <span class="math inline">\(f^{&#39;}(x;y)\)</span> for differentiable functions</li><li>implies that <span class="math inline">\(f^{&#39;}(x;y)\)</span> exists for all <span class="math inline">\(x\in\text{int dom}f\)</span>, all <span class="math inline">\(y\)</span></li></ul><h4 id="proof">Proof</h4><p><span class="math display">\[f^{&#39;}(x;y)=\lim_{a\searrow{}0}\frac{f(x+\alpha{}y)-f(x)}{\alpha}\geq\lim_{a\searrow{}0}\frac{}{}\]</span></p><hr /><p><span class="math display">\[\text{Let }\hat{g}\in\partial_yf^{&#39;}(x;y)\]</span> <span class="math display">\[\lambda{}f^{&#39;}(x;v)=f^{&#39;}(x,\lambda{}v)\geq{}f^{&#39;}(x;y)+\hat{g}^\top(\lambda{}v-y)\]</span><span class="math display">\[\Leftrightarrow{}\lambda(f^{&#39;}(x,v)-\hat{g}^\top{}v)\geq{}f^{&#39;}(x;y)-\hat{g}^\top{}y\]</span> <span class="math display">\[\Leftrightarrow{}^{\lambda\rightarrow\infty}f^{&#39;}(x,v)\geq\hat{h}^\top{}v\]</span> <span class="math display">\[\Leftrightarrow{}f(x,v)\geq{}f(x)+f^{&#39;}(x,v)\geq{}f(x)+\hat{g}^\top{}v\Rightarrow{}\hat{g}\in\partial{}f(x)\]</span> <span class="math display">\[\Leftrightarrow{}^{\lambda\rightarrow0}f^{&#39;}(x,y)\leq{}g^\top{}y\]</span></p><h3 id="steepest-descent-direction">Steepest descent direction</h3><p>Steepest descent direction at <span class="math inline">\(x\in\text{int dom} f\)</span> is <span class="math display">\[\Delta{}x_{nsd}=\arg\min_{||y||_2\leq1}f^{&#39;}(x;y)\]</span> <span class="math display">\[\text{(P) }\min_yf^{&#39;}(x;y),s.t.||y||_2\leq1\]</span> <span class="math display">\[\text{(D) }\max_g-||g||_2,s.t.g\in\partial{}f(x)\]</span></p><h4 id="proof-1">Proof</h4><p>if <span class="math inline">\(f\)</span> is convex, <span class="math inline">\(f(y)&lt;f(x),g\in\partial{}f(x)\)</span>, then for small <span class="math inline">\(t&gt;0\)</span>: <span class="math display">\[||x-tg-y||_2^2=||x-y||_2^2-2tg^\top(x-y)+t^2||g||_2^2\leq||x-y||_2^2-2t(f(x)-f(y))+t^2||g||_2^2&lt;||x-y||_2^2\]</span> <span class="math display">\[f^\star(x^\star)=\min{}f(x),x_{k+1}=x_k-tg_k,g_k\in\partial{}f(x_k)\]</span> <span class="math display">\[f(x_k)&gt;f(x^\star),\text{but }||x_{k+1}-x^\star||&lt;||x_k-x^\star||\]</span></p><h3 id="lemma-1">Lemma 1</h3><p>Let <span class="math inline">\(x_0\in{}int~dom~f\)</span>, then <span class="math display">\[f \text{ is convex }\Rightarrow{}f\text{ is continuous at }x_0\]</span></p><h4 id="proof-2">Proof</h4><p><span class="math display">\[g(x)=f(x_0+x)-f(x_0), g(0)=0, g\text{ is convex}, 0\in~int~dom~g\]</span> <span class="math display">\[\exists\alpha~s.t.~x_0+\alpha{}y_i\in~dom~f\]</span> <span class="math display">\[\{y_1,\dots,y_{2n}\}=\{e_1,\dots,e_n,-e_1,\dots,-e_n\}\]</span> ......</p><h2 id="subgradient-method">Subgradient Method</h2><p>to minimize a nondifferentiable convex function <span class="math inline">\(f\)</span>: choose <span class="math inline">\(x^{(0)}\)</span> and repeat <span class="math display">\[x^{(k)}=x^{(k-1)}-t_kg^{(k-1)},k=1,2,\dots\]</span> <span class="math inline">\(g^{(k-1)}\)</span> is any subgradient of <span class="math inline">\(f\)</span> at <span class="math inline">\(x^{(k−1)}\)</span></p><h3 id="assumptions">Assumptions</h3><ul><li><span class="math inline">\(f\)</span> has finite optimal value <span class="math inline">\(f^\star\)</span>, minimizer <span class="math inline">\(x^\star\)</span></li><li><span class="math inline">\(f\)</span> is convex, <span class="math inline">\(dom~f = R^n\)</span></li><li><span class="math inline">\(f\)</span> is Lipschitz continuous with constant <span class="math inline">\(G &gt; 0\)</span></li></ul><p><span class="math display">\[|f(x)-f(y)|\leq{}G||x-y||_2\quad\forall{}x,y\]</span> this is equivalent to <span class="math inline">\(||g||_2\leq{}G\)</span> for all <span class="math inline">\(x\)</span> and <span class="math inline">\(g\in\partial{}f(x)\)</span></p><h3 id="analysis">Analysis</h3><ul><li>the subgradient method is not a descent method</li><li>the key quantity in the analysis is the distance to the optimal set</li></ul><p>with <span class="math inline">\(x^+=x^{(i)},x=x^{(i-1)},g=g^{(i-1)},t=t_i\)</span>: <span class="math display">\[||x^+-x^\star||_2^2=||x-tg-x^\star||_2^2\]</span> <span class="math display">\[=||x-x^\star||_2^2-2tg^\top(x-x^\star)+t^2||g_2^2||\leq||x-x^\star||_2^2-2t(f(x)-f^\star)+t^2||g_2^2||\]</span> combine inequalities for <span class="math inline">\(i=1,\dots,k\)</span>, and define <span class="math inline">\(f^{(k)}_{\text{best}}=\min_{0\leq{}i\leq{}k}f(x^{(i)})\)</span> <span class="math display">\[(f^{(k)}_{\text{best}}-f^\star)\leq\frac{||x^{(0)}-x^\star||_2^2+\sum_{i=1}^kt_i^2||g^{(i-1)}||_2^2}{2\sum_{i=1}^kt_i}\]</span></p><h4 id="fixed-step-size-t_it">Fixed step size: <span class="math inline">\(t_i=t\)</span></h4><p><span class="math display">\[f^{(k)}_{\text{best}}-f^\star\leq\frac{||x^{(0)}-x^\star||_2^2}{2kt}+\frac{G^2t}{2}\]</span></p><ul><li>does not guarantee convergence of <span class="math inline">\(f^{(k)}_{\text{best}}\)</span></li></ul><h4 id="fixed-step-length-t_isgi-1_2">Fixed step length: <span class="math inline">\(t_i=s/||g^{(i-1)}||_2\)</span></h4><p><span class="math display">\[f^{(k)}_{\text{best}}-f^\star\leq\frac{G||x^{(0)}-x^\star||_2^2}{2ks}+\frac{Gs}{2}\]</span></p><ul><li>does not guarantee convergence of <span class="math inline">\(f^{(k)}_{\text{best}}\)</span></li></ul><h4 id="diminishing-step-size-t_irightarrow0">Diminishing step size: <span class="math inline">\(t_i\rightarrow0\)</span></h4><ul><li><span class="math inline">\(f^{(k)}_{\text{best}}\)</span> converges to <span class="math inline">\(f^\star\)</span></li><li>currently we don't know the speed of convergence</li><li>large <span class="math inline">\(t_i\)</span> may converge fast at first, but then smaller <span class="math inline">\(t_i\)</span> should be used</li></ul><h4 id="optimal-step-size-when-fstar-is-known">Optimal step size when <span class="math inline">\(f^\star\)</span> is known</h4><p><span class="math display">\[t_i=\frac{f(x^{(i-1)})-f^\star}{||g^{(i-1)}||_2^2}\]</span></p><ul><li>applying recursively (with <span class="math inline">\(||x^{(0)}-x^\star||_2\leq{}R\)</span> and <span class="math inline">\(||g^{(i)}||_2\leq{}G\)</span>) gives</li></ul><p><span class="math display">\[f^{(k)}_{\text{best}}-f^\star\leq\frac{GR}{\sqrt{k}}\]</span></p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Convex Optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>故障模式影响及危害分析</title>
      <link href="2019/04/15/%E6%95%85%E9%9A%9C%E6%A8%A1%E5%BC%8F%E5%BD%B1%E5%93%8D%E5%8F%8A%E5%8D%B1%E5%AE%B3%E5%88%86%E6%9E%90/"/>
      <url>2019/04/15/%E6%95%85%E9%9A%9C%E6%A8%A1%E5%BC%8F%E5%BD%B1%E5%93%8D%E5%8F%8A%E5%8D%B1%E5%AE%B3%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="概述">概述</h2><h3 id="定义">定义</h3><ul><li>Failure Mode, Effects and Criticality analysis</li><li>归纳分析方法：分析系统中每个设备所有可能的故障模式及对 系统造成的所有可能影响，并按每个故障模式的严重程度及发 生概率予以分类。<ul><li>一种自下而上的归纳分析方法</li><li>FMEA和CA</li></ul></li></ul><a id="more"></a><h3 id="目的">目的</h3><ul><li>在设计、生产和使用阶段发现影响系统可靠性的各薄弱环节</li><li>对薄弱环节提出改进措施，提高系统可靠性水平</li></ul><h2 id="步骤">步骤</h2><h3 id="系统定义">系统定义</h3><ul><li>确定系统中进行FMECA的设备范围</li><li>系统功能任务的描述</li><li>确定系统及设备的故障判据</li></ul><h3 id="fmea">FMEA</h3><ul><li>代码：采用统一的编码体系对每个设备的每个故障模式进行编码</li><li>设备或功能标识：记录被分析设备或功能的名称标识</li><li>功能：简要描述设备的主要功能</li><li>故障模式：故障的表现形式，每一个产品有可能具有多种故障模式<ul><li>损坏型、退化型、松脱型、失调型、堵塞或渗漏型、功能型等</li></ul></li><li>故障原因<ul><li>直接原因：导致设备功能故障的设备自身的那些物理、化学或生物变化过程等</li><li>间接原因：其他设备故障、环境因素和人为因素等外部原因</li></ul></li><li>任务阶段与工作方式<ul><li>任务可能包含多个阶段，设备可能需要参与一个或多个阶段</li><li>工作方式：可替换、有冗余等</li></ul></li><li>故障影响<ul><li>局部影响：某设备的故障模式对自身和与其所在约定层次相同的其他设备的使用、功能或状态的影响</li><li>高一层次影响：某设备的故障模式对其所在约定层次的高一层次设备的使用、功能或状态的影响。</li><li>最终影响：指系统中某设备的故障模式对初始约定层次设备的使用、功能或状态的影响。</li></ul></li><li>严酷度等级<ul><li>严酷度：设备故障模式所产生后果的严重程度</li><li>严酷度等级：应考虑故障造成的最坏潜在后果，根据最终可能出现的人员伤亡、系统损坏或经济损失的程度等来确定。</li></ul></li><li>故障检测方法<ul><li>包括事前检测与事后检测</li><li>目视检查、离机检测、原位测试等手段</li></ul></li><li>补偿措施<ul><li>设计补偿措施<ul><li>设备发生故障时，能继续工作的冗余设备</li><li>安全或保险装置(如监控及报警装置)</li><li>可替换的工作方式(如备用或辅助设备)</li><li>可以消除或减轻故障影响的设计或工艺改进</li></ul></li><li>操作人员补偿措施<ul><li>特殊的使用和维护规程，尽量避免或预防故障的发生</li><li>一旦出现某故障后操作人员应采取的最恰当的补救措施</li></ul></li></ul></li></ul><h3 id="ca">CA</h3><ul><li>危害性分析CA：按每个故障模式的严重程度及其发生概率所产生的综合影响对系统中的设备分级</li><li>分析方法<ul><li>风险优先数法</li><li>危害性矩阵法</li></ul></li></ul><h4 id="风险优先数法">风险优先数法</h4><p><span class="math display">\[RPN=OPR\times{}ESR\]</span></p><ul><li><span class="math inline">\(OPR\)</span>：发生概率等级</li><li><span class="math inline">\(ESR\)</span>：影响严酷度等级</li></ul><h4 id="危害性矩阵法">危害性矩阵法</h4><ul><li>故障模式频数比 <span class="math inline">\(\alpha\)</span>：设备某故障模式占其全部故障模式的百分比率</li><li>故障影响概率 <span class="math inline">\(\beta\)</span>：某故障模式发生后，导致确定的严酷度等级的最终影响的条件概率</li><li>故障模式危害度：评价设备单一故障模式危害性</li></ul><p><span class="math display">\[C_m(j)=\alpha\beta\lambda{}pt\]</span></p><ul><li>设备危害度：评价设备的危害性</li></ul><p><span class="math display">\[C_r(j)=\sum{}C_{mi}(j)\]</span></p><h3 id="结果呈现">结果呈现</h3><ul><li>可靠性关键设备清单<ul><li>RPN 值大于某规定值的设备</li><li>危害性矩阵中落在某一规定区域之内的设备</li></ul></li><li>严重故障模式清单<ul><li>严酷度为 Ⅰ、Ⅱ 类的故障模式</li><li>故障影响严重程度被评为 9-10 分的故障模式</li></ul></li><li>单点故障模式清单<ul><li>某一设备或故障模式发生后将直接导致系统故障</li></ul></li></ul><h2 id="小结">小结</h2><ul><li>FMECA 中各故障模式的相关数据是定量化分析的基础</li><li>FMECA 是静态的、单一因素的分析方法，在动态方面还很不完善</li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reliability Engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LP, SOP and SOCP</title>
      <link href="2019/04/02/LP,%20SDP%20and%20SOCP/"/>
      <url>2019/04/02/LP,%20SDP%20and%20SOCP/</url>
      
        <content type="html"><![CDATA[<h2 id="linear-programming">Linear Programming</h2><p><span class="math display">\[\text{(P) }\min_xc^Tx,s.t.Ax=b,x\geq0\]</span> <span class="math display">\[\text{(D) }\min_yb^Ty,s.t.A^Ty+s=c,s\geq0\]</span></p><h3 id="strong-duality">Strong duality</h3><p><span class="math display">\[c^Tx=b^T\Leftrightarrow{}x^Ts=0\Leftrightarrow{}x_is_i=0\]</span></p><a id="more"></a><h3 id="kkt-system-in-lp">KKT system in LP</h3><ul><li>Primal feasibility</li></ul><p><span class="math display">\[Ax=b\land{}x\geq0\]</span></p><ul><li>Dual feasibility</li></ul><p><span class="math display">\[A^Ty+s=c\land{}s\geq0\]</span></p><ul><li>Complementarity</li></ul><p><span class="math display">\[x_is_i=0\]</span></p><h3 id="algebraic-characterization">Algebraic Characterization</h3><ul><li>Define <span class="math inline">\(x\circ{}s=(x_1s_1,\dots,x_ns_n)^\top\)</span> and</li></ul><p><span class="math display">\[L_x:y\mapsto(x_1y_1,\dots,x_ny_n)^\top,\text{ i.e. }L_x={\rm Diag}(x)\]</span></p><h2 id="semidefinite-programming-sdp">Semidefinite programming (SDP)</h2><p><span class="math display">\[\text{(P) }\min\langle{}C_1,X_1\rangle{}+\dots+\langle{}C_n,X_n\rangle{}\]</span> <span class="math display">\[s.t.~\langle{}A_{i1},X_1\rangle{}+\dots+\langle{}A_{in},X_n\rangle{}=b_i,X_i\succeq0\]</span> <span class="math display">\[\text{(D) }\max{}b^\top{}y\]</span> <span class="math display">\[s.t.~A_{1i}b_1+\dots+A_{ni}b_n+S_i=C_i,S_i\succeq0\]</span></p><h3 id="strong-duality-1">Strong duality</h3><p><span class="math display">\[\langle{}X,S\rangle{}=0\Leftrightarrow{}X\succeq0\land{}S\succeq0\land\frac{XS+SX}{2}=0\]</span></p><h2 id="second-order-cone-programming-socp">Second order cone programming (SOCP)</h2><p><span class="math display">\[\text{(P) }\min{}c^\top{}x,s.t.Ax=b,x\succeq_{\mathcal{Q}}0\]</span> <span class="math display">\[\text{(Q) }\min{}b^\top{}y,s.t.A^\top{}y+s=c,s\succeq_{\mathcal{Q}}0\]</span></p><h4 id="example">Example</h4><p><span class="math display">\[x\in{}S,\lambda_1\geq\lambda_2\geq\dots\geq\lambda_n\]</span> <span class="math display">\[(\lambda_1+\dots+\lambda_K)(X)\]</span> <span class="math display">\[\Leftrightarrow\]</span> <span class="math display">\[\min_{Y,t}Tr(Y)+Kt,~s.t.tI+Y\succeq{}X,Y\succeq0\]</span></p><h2 id="sdp-relaxation">SDP Relaxation</h2><p>Consider QCQP <span class="math display">\[\min~x^TA_0x+2b_0^Tx+c_0\text{ assume }A_i\in{}S^n\]</span> <span class="math display">\[\text{s.t. }x^TA_ix+2b_i^Tx+c_i\leq0,i=1,\dots,m\]</span></p><h3 id="max-cut">Max Cut</h3><p>For graph <span class="math inline">\((V,E)\)</span> and weights <span class="math inline">\(w_{ij}=w_{ji}\geq0\)</span>, the maxcut problem is: <span class="math display">\[(Q)~\max_x\frac{1}{2}\sum_{i&lt;j}w_{ij}(1-x_ix_j),~\text{ s.t. }x_i\in\{-1,1\}\]</span> where <span class="math inline">\(x_i=-1\)</span> means <span class="math inline">\(x\)</span> in set <span class="math inline">\(X_1\)</span> and <span class="math inline">\(x_i=1\)</span> means <span class="math inline">\(x\)</span> in set <span class="math inline">\(X_2\)</span>. And its relaxation is: <span class="math display">\[(P)~\max_{v_i\in{}R^n}\frac{1}{2}\sum_{i&lt;j}w_{ij}(1-v_iv_j),~\text{ s.t. }||v_i||_2=1\]</span> The equivalent SDP of <span class="math inline">\((P)\)</span> is : <span class="math display">\[(SDP)~\max_{X\in{}S^n}\frac{1}{2}\sum_{i&lt;j}w_{ij}(1-X_{ij}),~\text{ s.t. }X_{ii}=1,X\succeq0\]</span> where <span class="math inline">\(X=V^TV=(v_1,\dots,v_n)^T(v_1,\dots,v_n)\)</span>.<br> Add <span class="math inline">\(rank(X)=1\)</span>, then <span class="math inline">\(X=xx^T\Rightarrow{}x_i^2=1\)</span>, which means that it is equivalent to the original problem.</p><h4 id="greedy-way">Greedy Way</h4><p>Every time we pick most distant one, then <span class="math display">\[Z^*\geq\frac{1}{2}Z_{opt}\]</span></p><h4 id="rounding-procedure">Rounding Procedure</h4><ul><li>Generate a vector <span class="math inline">\(r\)</span> uniformly distributed on the unit sphere, i.e. <span class="math inline">\(||r||_2=1\)</span></li><li>Set <span class="math inline">\(x_i=1(v_i^Tr\geq0),-1(\text{otherwise})\)</span></li></ul><h4 id="theoretical-result">Theoretical Result</h4><ul><li>Let <span class="math inline">\(W\)</span> be the objective function value of <span class="math inline">\(x\)</span> and <span class="math inline">\(E(W)\)</span> be the expected value. Then</li></ul><p><span class="math display">\[E(W)=\frac{1}{\pi}\sum_{i&lt;j}w_{ij}\arccos(v_i^Tv_j)\]</span></p><ul><li>Goemans and Williamson showed:</li></ul><p><span class="math display">\[E(W)\geq\alpha\frac{1}{2}\sum_{i&lt;j}w_{ij}(1-v_i^Tv_j),\alpha=\min_{0\leq\theta\leq\pi}\frac{2}{\pi}\frac{\theta}{1-\cos\theta}&gt;0.878\]</span></p><h2 id="sdp-representablity">SDP Representablity</h2><p>A set <span class="math inline">\(X\subseteq{}R^n\)</span> is SDP-representable (or SDP-Rep for short) if it can be expressed linearly as the feasible region of an SDP: <span class="math display">\[X=\{x|(\exists{}u\in{}R^k)(\exists{}A_i,B_j,C\in{}R^{m\times{}m})\sum_ix_iA_i+\sum_ju_jB_j+C\succeq0\}\]</span> A function <span class="math inline">\(f(x)\)</span> is SDP-Rep if its epigraph is SDP-representable: <span class="math display">\[\text{epi}(f)=\{(x_0,x)|f(x)\leq{}x_0\}\]</span></p><ul><li>If <span class="math inline">\(X\)</span> is SDP-Rep, then <span class="math inline">\(\min_{x\in{}X}c^Tx\)</span> is an SDP</li><li>If <span class="math inline">\(f(x)\)</span> is SDP-Rep, then <span class="math inline">\(\min_xf(x)\)</span> is an SDP</li></ul><h3 id="calculus-of-sdp-rep-sets">'Calculus' of SDP-Rep Sets</h3><p>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are SDP-Rep then so are</p><ul><li>Minkowski sum <span class="math inline">\(X+Y\)</span></li><li>Intersection <span class="math inline">\(X\cap{}Y\)</span></li><li>Affine pre-image <span class="math inline">\(A^{-1}(X)\)</span> if <span class="math inline">\(A\)</span> is affine</li><li>Affine map <span class="math inline">\(A(X)\)</span> if <span class="math inline">\(A\)</span> is affine</li><li>Cartesian Product <span class="math inline">\(X\times{}Y=\{(x,y)|x\in{}X,y\in{}Y\}\)</span></li></ul><h4 id="proof-of-affine-map">Proof of Affine map</h4><p><span class="math display">\[Y=\{Fx+f|F\in{}R^{m\times{}n},x\in{}X\}\]</span> <span class="math display">\[m\geq{}n,rank(F)=n\]</span> <span class="math display">\[y=Fx+f\Rightarrow{}x=(F^TF)^{-1}F^T(y-f)=F^+(y-f)\]</span> <span class="math display">\[A(F^+(y-f))+B(u)+C\geq0\Rightarrow{}A(F^+y)+B(u)+C-A(F^+f)\geq0\]</span></p><hr /><p><span class="math display">\[m\leq{}n,rank(F)=m\]</span> <span class="math display">\[y=Fx\Rightarrow{}y=[F_1,F_2][x_1,x_2]^T\Rightarrow{}x_1=F^{-1}(y-F_2x_2)\]</span></p><h3 id="calculus-of-sdp-rep-functions">'Calculus' of SDP-Rep Functions</h3><p>If functions <span class="math inline">\(f_i,i=1,\dots,m\)</span> and <span class="math inline">\(g\)</span> are SDP-Rep. Then the following are SDP-Rep:</p><ul><li>nonnegative sum <span class="math inline">\(\sum\alpha_if_i\)</span> for <span class="math inline">\(\alpha_i\geq0\)</span></li><li>maximum <span class="math inline">\(\max_if_i\)</span></li><li>composition <span class="math inline">\(g(f_1(x),\dots,f_m(x))\)</span></li><li>Legendre transform <span class="math inline">\(f^*(y)=\max_xy^Tx-f(x)\)</span></li></ul><h3 id="positive-polynomials">Positive Polynomials</h3><p>The set of nonnegative polynomials of a given degree forms a proper cone <span class="math display">\[P_n=\{(p_0,\dots,p_n)|(\forall{}t\in{}I)p_o+p_1t+\dots+p_nt^n&gt;0\}\]</span></p><ul><li>The cone of positive polynomials is SDP-Rep</li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Convex Optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>可修复系统的可靠性分析</title>
      <link href="2019/04/01/%E5%8F%AF%E4%BF%AE%E5%A4%8D%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%88%86%E6%9E%90/"/>
      <url>2019/04/01/%E5%8F%AF%E4%BF%AE%E5%A4%8D%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="维修性特征量">维修性特征量</h2><h3 id="section"><br></br></h3><h4 id="维修分布函数维修度">维修分布函数/维修度</h4><p>产品从故障开始到修理完毕经历的时间 <span class="math inline">\(Y\)</span> <span class="math display">\[M(t)=P(Y\leq{}t)\]</span></p><h4 id="修复率">修复率</h4><p>尚未修复的产品在单位时间内修复完成 <span class="math display">\[\mu(t)=\frac{m(t)}{1-M(t)}\]</span></p><h4 id="平均修复时间">平均修复时间</h4><p><span class="math display">\[MTTR=\int_0^\infty{}tm(t)dt=\int_0^\infty{}tdM(t)\]</span></p><a id="more"></a><h2 id="可用性">可用性</h2><ul><li>也称有效性，综合反映可靠性和维修性，即可维修产品使用效率的广义可靠性</li><li>规定条件包括工作条件和维修条件</li></ul><h3 id="特征量">特征量</h3><h4 id="瞬时可用度">瞬时可用度</h4><ul><li>可维修产品在某时刻具有或维持功能的概率</li><li>瞬时可用度常用于理论分析</li></ul><h4 id="平均可用度">平均可用度</h4><p><span class="math display">\[\bar{A}(t_1,t_2)=\frac{1}{t_2-t_1}\int_{t_1}^{t_2}A(t)dt\]</span></p><h4 id="稳态可用度">稳态可用度</h4><p><span class="math display">\[A=A(\infty)=\lim_{t\rightarrow\infty}A(t)=\frac{MTBF}{MTBF+MTTR}\]</span> 当可靠度函数和维修度函数均是指数函数： <span class="math display">\[A=\frac{\mu}{\mu+\lambda}\]</span></p><h2 id="预防维修与事后维修">预防维修与事后维修</h2><h3 id="预防维修">预防维修</h3><ul><li>计划性的维修活动，最常用的形式是定期检修，使设备总是 保持良好的工作状态</li><li>按照规定程序，假定起始时间为 <span class="math inline">\(0\)</span>，检修时间间隔为 <span class="math inline">\(T\)</span>，则产品工作时间 <span class="math inline">\(t=jT+\tau\)</span></li></ul><h4 id="理想预防维修系统的可用度">理想预防维修系统的可用度</h4><ul><li>平均预防维修时间 <span class="math inline">\(T_p\)</span> ；平均事后维修时间 <span class="math inline">\(T_f\)</span></li><li>系统平均停工时间 <span class="math inline">\(MDT=R(T)T_p+(1-R(T))T_f\)</span></li><li>系统平均工作时间 <span class="math inline">\(MUT=\int_0^TR(t)dt\)</span></li></ul><p><span class="math display">\[A=\frac{MUT}{MUT+MDT}\]</span></p><h3 id="事后维修">事后维修</h3><ul><li>系统投入运行后，一旦发生故障，立即开始修理</li><li>系统只存在运行状态 <span class="math inline">\(S\)</span> 和失效状态 <span class="math inline">\(F\)</span></li><li>状态转移关系</li></ul><p><span class="math display">\[P_F(t+\Delta{}t)=P_S(t)\lambda(t)\Delta{}t+P_F(t)[1-\mu(t)\Delta{}t]\]</span> <span class="math display">\[P_F(t)=\exp\{-Q(t)\}\int_0^t\exp\{Q(t)\}\lambda(t)dt,Q(t)=\int_0^t[\lambda(t)+mu(t)]dt\]</span></p><h2 id="马尔科夫模型求解可修复系统可靠性">马尔科夫模型求解可修复系统可靠性</h2><h3 id="马尔科夫过程">马尔科夫过程</h3><p><span class="math display">\[P(X(t_n)=x_n|X(t_1)=x_1,\dots,X(t_{n-1})=x_{n-1})=P(X(t_n)=x_n|X(t_{n-1})=x_{n-1})\]</span> 随机过程 <span class="math inline">\(\{X(t),t\geq0\}\)</span> 是连续时间和离散状态空间 <span class="math inline">\(S=\{0,1,2,\dots,n\}\)</span> 的马尔科夫过程，若满足如下条件（即转移密度为常数），则称此过程为<strong>齐次</strong>马尔科夫过程： <span class="math display">\[P(X(t+\Delta{}t)=j|X(t)=i)\equiv{}p_{ij}(\Delta{}t)\]</span> 由归一化条件，显然有： <span class="math display">\[p_{ii}+\sum_{j\neq{}i}p_{ij}=1\]</span></p><h3 id="转移率">转移率</h3><p><span class="math display">\[q_{ij}=\lim_{\Delta{}t\rightarrow0}\frac{p_{ij}(\Delta{}t)}{\Delta{}t},q_{i}=\lim_{\Delta{}t\rightarrow0}\frac{1-p_{ii}(\Delta{}t)}{\Delta{}t}\]</span> 由全概率条件，显然有： <span class="math display">\[q_i=\sum_{j\neq{}i}q_{ij}\]</span> 转移率矩阵为： <span class="math display">\[a_{ij}=q_{ij}~(i\neq{}j)~\text{or}~-q_i~(i=j)\]</span></p><h3 id="利用转移率矩阵求解系统可靠性参数">利用转移率矩阵求解系统可靠性参数</h3><ul><li>状态概率：系统在 <span class="math inline">\(t\)</span> 时刻处于状态 <span class="math inline">\(i\)</span> 的概率</li><li>可用度：瞬时可用度、稳态可用度</li><li>系统可靠度、平均首次故障时间</li><li>状态频率、状态持续时间</li></ul><h4 id="系统状态概率">系统状态概率</h4><p>令 <span class="math display">\[P(t)=[p_1(t),p_2(t),\dots,p_n(t)]\]</span> 则有： <span class="math display">\[P^{&#39;}(t)=P(t)A\]</span> 等式两边使用拉普拉斯变换 <span class="math display">\[sP^*(s)-P(0)=P^*(s)A\]</span> <span class="math display">\[P^*(s)=P(0)(sI-A)^{-1}\]</span> 然后进行分式分解（<span class="math inline">\(s_i\)</span> 为矩阵 <span class="math inline">\(sI-A\)</span> 第 <span class="math inline">\(i\)</span> 个特征值） <span class="math display">\[P^*_j(s)=\sum_{i=0}^Nb_{ji}(s-s_i)^{-1}\]</span> 从而可以得到原函数 <span class="math display">\[P_j(t)=\sum_{i=0}^Nb_{ji}\exp(s_it)\]</span></p><h4 id="系统可用度">系统可用度</h4><ul><li>系统的瞬时可用度 <span class="math inline">\(A(t)\)</span></li></ul><p><span class="math display">\[A(t)=\sum_{j\in{}W}p_j(t)\]</span></p><ul><li>系统稳态可用度 <span class="math inline">\(A(\infty)\)</span></li></ul><p><span class="math display">\[(\pi_0,\dots,\pi_n)A=(0,\dots,0),\pi_0+\dots+\pi_n=1\]</span> <span class="math display">\[A(\infty)=\sum_{j\in{}W}\pi_j\]</span></p><h4 id="系统可靠度与平均首次故障前时间mttff">系统可靠度与平均首次故障前时间MTTFF</h4><h4 id="状态频率和持续时间">状态频率和持续时间</h4>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reliability Engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Duality</title>
      <link href="2019/03/26/Duality/"/>
      <url>2019/03/26/Duality/</url>
      
        <content type="html"><![CDATA[<h2 id="lagrange-dual-problem">Lagrange dual problem</h2><h3 id="lagrangian">Lagrangian</h3><p><span class="math display">\[\min{}f_0(x),s.t.f_i(x)\leq0,h_i(x)=0\]</span> variable <span class="math inline">\(x\in{}R^n\)</span>, domain <span class="math inline">\(\mathcal{D}\)</span>, optimal value <span class="math inline">\(p^\star\)</span> <span class="math display">\[L:R^n\times{}R^m\times{}R^p\rightarrow{}R,dom~L=\mathcal{D}\times{}R^m\times{}R^p\]</span> <span class="math display">\[L(x,\lambda,\nu)=f_0(x)+\sum_{i=1}^m\lambda_if_i(x)+\sum_{i=1}^p\nu_ih_i(x)\]</span></p><a id="more"></a><h3 id="lagrange-dual-function">Lagrange dual function</h3><p><span class="math display">\[g:R^m\times{}R^p\rightarrow{}R\]</span> <span class="math display">\[g(\lambda,\nu)=\inf_{x\in{}D}L(x,\lambda,\nu)=\inf_{x\in{}D}(f_0(x)+\sum_{i=1}^m\lambda_if_i(x)+\sum_{i=1}^p\nu_ih_i(x))\]</span> lower bound property: if <span class="math inline">\(\lambda\geq0\)</span>, then <span class="math inline">\(g(\lambda,\nu)\leq{}p^\star\)</span></p><h3 id="lagrange-dual-problem-1">Lagrange dual problem</h3><p><span class="math display">\[\max{}g(\lambda,\nu),s.t.\lambda\succeq0\]</span> optimal value <span class="math inline">\(d^\star\)</span></p><h2 id="weak-and-strong-duality">Weak and strong duality</h2><ul><li>weak duality: <span class="math inline">\(d^\star\leq{}p^\star\)</span><ul><li>always holds (for convex and nonconvex problems)</li></ul></li><li>strong duality: <span class="math inline">\(d^\star=p^\star\)</span><ul><li>(usually) holds for convex problems</li></ul></li></ul><h3 id="slaters-constraint-qualification">Slater's constraint qualification</h3><p><span class="math display">\[\text{minimize }f_0(x)\]</span> <span class="math display">\[\text{subject to }f_i(x)\leq0,Ax=b\]</span> strong duality holds if it is strictly feasible, i.e., <span class="math display">\[\exists{}x\in{}\text{relint }D:~f_i(x)&lt;0,Ax=b\]</span></p><ul><li>there exist many other types of constraint qualifications</li></ul><h2 id="geometric-interpretation">Geometric interpretation</h2><p>Omit</p><h3 id="complementary-slackness">Complementary slackness</h3><p>Assume strong duality holds, <span class="math inline">\(x^\star\)</span> is primal optimal, <span class="math inline">\((\lambda^\star,\nu^\star)\)</span> is dual optimal - <span class="math inline">\(x^\star\)</span> minimizes <span class="math inline">\(L(x,\lambda^\star,\nu^\star)\)</span> - <span class="math inline">\(\lambda_i^\star{}f_i(x^\star)=0\)</span> for <span class="math inline">\(i=1,\dots,m\)</span></p><h3 id="kkt-conditions">KKT conditions</h3><ul><li>primal constraints: <span class="math inline">\(f_i(x)\leq0,i=1,\dots,m,h_i(x)=0,i=1,\dots,p\)</span></li><li>dual constraints: <span class="math inline">\(\lambda\succeq0\)</span></li><li>complementary slackness: <span class="math inline">\(\lambda_if_i(x)=0\)</span></li><li>gradient of Lagrangian with respect to <span class="math inline">\(x\)</span> vanishes: <span class="math display">\[\nabla{}f_0(x)+\sum_{i=1}^m\lambda_i\nabla{}f_i(x)+\sum_{i=1}^p\nu_i\nabla{}h_i(x)=0\]</span></li></ul><h3 id="kkt-conditions-for-convex-problem">KKT conditions for convex problem</h3><p>If <span class="math inline">\(\tilde{x},\tilde{\lambda},\tilde{\nu}\)</span> satisfy KKT for a convex problem, then they are optimal.</br> If Slater’s condition is satisfied, then <span class="math inline">\(x\)</span> is optimal if and only if there exist <span class="math inline">\(\lambda, \nu\)</span> that satisfy KKT conditions.</p><h2 id="perturbation-and-sensitivity-analysis">Perturbation and sensitivity analysis</h2><p><span class="math display">\[f_i(x)\leq0\Rightarrow{}f_i(x)\leq{}u_i\]</span> <span class="math display">\[h_i(x)=0\Rightarrow{}h_i(x)=v_i\]</span> <span class="math display">\[g(\lambda,\nu)\Rightarrow{}g(\lambda,\nu)-u^T\lambda-v^T\nu\]</span></p><hr /><p><span class="math display">\[p^\star(u,v)\geq{}g(\lambda^\star,\nu^\star)-u^T\lambda^\star-v^T\nu^\star=p^\star(0,0)-\lambda^\star-\nu^\star\]</span></p><h3 id="local-sensitivity">Local sensitivity</h3><p>If <span class="math inline">\(p^\star(u,v)\)</span> is differentiable at <span class="math inline">\((0,0)\)</span>, then <span class="math display">\[\lambda_i^\star=-\frac{\partial{}p^\star(0,0)}{\partial{}u_i},\nu_i^\star=-\frac{\partial{}p^\star(0,0)}{\partial{}v_i}\]</span></p><h2 id="duality-and-problem-reformulations">Duality and problem reformulations</h2><h3 id="introducing-new-variables-and-equality-constraints">Introducing new variables and equality constraints</h3><p><span class="math display">\[\text{minimize }f_0(Ax+b)\]</span></p><ul><li>dual function is constant</li><li>we have strong duality, but dual is quite useless</li></ul><p><span class="math display">\[\Rightarrow\text{minimize }f_0(y)\text{, subject to }Ax+b-y=0\]</span></p><h3 id="implicit-constraints">Implicit constraints</h3><p><span class="math display">\[\text{minimize }c^Tx\text{, subject to }Ax=b,-1\preceq{}x\preceq{}1\]</span> <span class="math display">\[\Rightarrow\text{minimize }f_0(x)=c^Tx(-1\preceq{}x\preceq{}1),\infty(\text{otherwise})\text{, subject to }Ax=b\]</span></p><h3 id="problems-with-generalized-inequalities">Problems with generalized inequalities</h3><p><span class="math display">\[\text{minimize }f_0(x)\text{, subject to }f_i(x)\preceq{}_{K_i}0,h_i(x)=0\]</span></p><h3 id="semidefinite-program">Semidefinite program</h3><p><span class="math display">\[\text{minimize }c^Tx,\text{, subject to }x_1F_1+\dots+x_nF_n\preceq{}G\]</span></p><ul><li>Lagrange multiplier is matrix <span class="math inline">\(Z\in{}S^k\)</span></li><li>Lagranigian <span class="math display">\[L(x,Z)=c^Tx+tr(Z(x_1F_1+\dots+x_nF_n-G))\]</span></li><li>dual function <span class="math display">\[g(Z)=\inf_xL(x,Z)=-tr(GZ)(\text{for }tr(F_iZ)+c_i=0),-\infty(\text{otherwise})\]</span></li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Convex Optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Simplex Algorithm</title>
      <link href="2019/03/22/Simplex%20Algorithm/"/>
      <url>2019/03/22/Simplex%20Algorithm/</url>
      
        <content type="html"><![CDATA[<h2 id="convert-lp-to-a-standard-form">Convert LP to a Standard Form</h2><p><span class="math display">\[\min{}c^\top{}x,\text{subject to }Ax=b\land{}x\geq0\]</span></p><h3 id="for-inequality">For Inequality</h3><ul><li><span class="math inline">\(x+y\geq{}a\rightarrow{}x+y-z=a,z\geq0\)</span></li><li><span class="math inline">\(x+y\leq{}a\rightarrow{}x+y+s=a,s\geq0\)</span></li><li>Unrestricted <span class="math inline">\(\rightarrow{}x=y-z,y\geq0,z\geq0\)</span></li></ul><a id="more"></a><h2 id="preview-of-simplex-algorithm">Preview of Simplex Algorithm</h2><h3 id="basic-solutions">Basic solutions</h3><p><span class="math display">\[Ax=b,A\in{}R^{m\times{}n},x\in{}R^n,n\geq{}m\]</span> Set <span class="math inline">\(n-m\)</span> variables to <span class="math inline">\(0\)</span> and solving for the remaining <span class="math inline">\(m\)</span> variables.</br> The columns for the remaining <span class="math inline">\(m\)</span> variables are linear independent.</br> <span class="math display">\[\text{Total number: }C_n^m\]</span></p><h3 id="basic-feasible-solutions">Basic feasible solutions</h3><ul><li>Feasible region for any LP problem is a convex set</li><li>If a LP has an optimal solution, there must be an extreme point of the feasible region that is optimal</li></ul><h4 id="proof">Proof</h4><p><span class="math display">\[\text{Suppose }x^\star=\sum_{i=1}^n\alpha_ix_i\text{ is an optimal solution}\]</span> <span class="math display">\[c^\top{}x^\star=c^\top{}\sum_{i=1}^n\alpha_ix_i&gt;\sum_{i=1}^n\alpha_ic^\top{}x^\star=c^\top{}x^\star\]</span></p><h3 id="adjacent-basic-feasible-solutions">Adjacent Basic Feasible Solutions</h3><p>Two basic feasible solutions are said to be <em>adjacent</em> if their sets of basic variables have <span class="math inline">\(m-1\)</span> basic variables in common</p><h2 id="general-description-of-the-simplex-algorithm">General Description of the Simplex Algorithm</h2><ol type="1"><li>Find an initial bfs of LP</li><li>Change bfs to its adjacent bfs</li><li>Recalculate by Gaussian elimination</li><li>For maximum, until the first row is all nonnegative; For minimum, until the first row is all nonpositive</li></ol><h3 id="example">Example</h3><p>Standard form: <span class="math display">\[\max{}z=3x_1+5x_2\]</span> <span class="math display">\[\begin{split}            \text{subject to }\quad{}x_1+s_1&amp;=8\\            2x_2+s_2&amp;=12\\            3x_1+4x_2+s_3&amp;=36\\            x_1,x_2,s_1,s_2,s_3&amp;\geq0        \end{split}            \label{p1s}\]</span></p><p>Choose <span class="math inline">\((s_1,s_2,s_3)\)</span> as BFS, we have table:</p><table><thead><tr class="header"><th style="text-align: center;"><span class="math inline">\(z\)</span></th><th style="text-align: center;"><span class="math inline">\(x_1\)</span></th><th style="text-align: center;"><span class="math inline">\(x_2\)</span></th><th style="text-align: center;"><span class="math inline">\(s_1\)</span></th><th style="text-align: center;"><span class="math inline">\(s_2\)</span></th><th style="text-align: center;"><span class="math inline">\(s_3\)</span></th><th style="text-align: center;">rhs</th><th style="text-align: center;">Basic Variable</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">-3</td><td style="text-align: center;">-5</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;"><span class="math inline">\(z=0\)</span></td></tr><tr class="even"><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">8</td><td style="text-align: center;"><span class="math inline">\(s_1=8\)</span></td></tr><tr class="odd"><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">2</td><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">12</td><td style="text-align: center;"><span class="math inline">\(s_2=12\)</span></td></tr><tr class="even"><td style="text-align: center;">0</td><td style="text-align: center;">3</td><td style="text-align: center;">4</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">36</td><td style="text-align: center;"><span class="math inline">\(s_3=36\)</span></td></tr></tbody></table><p>Choose <span class="math inline">\((s_1,x_2,s_3)\)</span> as BFS, we have table:</p><table><thead><tr class="header"><th style="text-align: center;"><span class="math inline">\(z\)</span></th><th style="text-align: center;"><span class="math inline">\(x_1\)</span></th><th style="text-align: center;"><span class="math inline">\(x_2\)</span></th><th style="text-align: center;"><span class="math inline">\(s_1\)</span></th><th style="text-align: center;"><span class="math inline">\(s_2\)</span></th><th style="text-align: center;"><span class="math inline">\(s_3\)</span></th><th style="text-align: center;">rhs</th><th style="text-align: center;">Basic Variable</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">2.5</td><td style="text-align: center;">0</td><td style="text-align: center;">30</td><td style="text-align: center;"><span class="math inline">\(z=30\)</span></td></tr><tr class="even"><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">8</td><td style="text-align: center;"><span class="math inline">\(s_1=8\)</span></td></tr><tr class="odd"><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">0.5</td><td style="text-align: center;">0</td><td style="text-align: center;">6</td><td style="text-align: center;"><span class="math inline">\(x_2=6\)</span></td></tr><tr class="even"><td style="text-align: center;">0</td><td style="text-align: center;">3</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">-2</td><td style="text-align: center;">1</td><td style="text-align: center;">12</td><td style="text-align: center;"><span class="math inline">\(s_3=12\)</span></td></tr></tbody></table><p>Choose <span class="math inline">\((s_1,x_2,x_1)\)</span> as BFS, we have table:</p><table><thead><tr class="header"><th style="text-align: center;"><span class="math inline">\(z\)</span></th><th style="text-align: center;"><span class="math inline">\(x_1\)</span></th><th style="text-align: center;"><span class="math inline">\(x_2\)</span></th><th style="text-align: center;"><span class="math inline">\(s_1\)</span></th><th style="text-align: center;"><span class="math inline">\(s_2\)</span></th><th style="text-align: center;"><span class="math inline">\(s_3\)</span></th><th style="text-align: center;">rhs</th><th style="text-align: center;">Basic Variable</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">0.5</td><td style="text-align: center;">0</td><td style="text-align: center;">42</td><td style="text-align: center;"><span class="math inline">\(z=42\)</span></td></tr><tr class="even"><td style="text-align: center;">-</td><td style="text-align: center;">-</td><td style="text-align: center;">-</td><td style="text-align: center;">-</td><td style="text-align: center;">-</td><td style="text-align: center;">-</td><td style="text-align: center;">-</td><td style="text-align: center;">-</td></tr><tr class="odd"><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">0.5</td><td style="text-align: center;">0</td><td style="text-align: center;">12</td><td style="text-align: center;"><span class="math inline">\(x_2=6\)</span></td></tr><tr class="even"><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">-2/3</td><td style="text-align: center;">1/3</td><td style="text-align: center;">4</td><td style="text-align: center;"><span class="math inline">\(x_1=4\)</span></td></tr></tbody></table><p>So the final result is <span class="math display">\[x_1=4,x_2=6,z_{max}=42\]</span></p><h3 id="degeneracy">Degeneracy</h3><p>An LP is degenerate if it has at least one basic feasible solution in which a basic feasible variable is equal to <span class="math inline">\(0\)</span></p><ul><li>pivoting may not improve the objective value</li><li>simplex method may end up in cycles</li></ul><h2 id="two-bfs-methods">Two BFS Methods</h2><h3 id="big-m-method">Big M Method</h3><p><span class="math display">\[\min{}f(x),\text{ subject to }Ax=b(b\succeq0)\]</span> <span class="math display">\[\Rightarrow\min{}f(x)+M^\top{}a,\text{ subject to }Ax+Ia=b\]</span></p><p>Introduce <span class="math inline">\(a_i\)</span> to every row which has a negative coefficient (on <span class="math inline">\(s\)</span> or <span class="math inline">\(z\)</span>), then we can get bfs easily</p><p><span class="math display">\[(x=0,a=b)\]</span></p><p>If we can't reduce all parameters of <span class="math inline">\(a\)</span> to 0, then the original problem is infeasible</p><h3 id="two-phase-method">Two-Phase Method</h3><p><span class="math display">\[\min{}f(x),\text{ subject to }Ax=b(b\succeq0)\]</span> <span class="math display">\[\Rightarrow\min{}I^\top{}a,\text{ subject to }Ax+Ia=b,a\succeq0\]</span> If <span class="math inline">\(a^\star\neq0\)</span>, then the original problem is infeasible</p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operations Research </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Convex Optimization Problems</title>
      <link href="2019/03/19/Convex%20Optimization%20Problems/"/>
      <url>2019/03/19/Convex%20Optimization%20Problems/</url>
      
        <content type="html"><![CDATA[<h2 id="optimization-problem-in-standard-form">Optimization problem in standard form</h2><p><span class="math display">\[\text{minimize }f_0(x)\]</span> <span class="math display">\[\text{subject to }f_i(x)\leq0\quad{}\land{}\quad{}Ax=b\]</span></p><a id="more"></a><h3 id="theorem-optimal-and-locally-optimal-options">Theorem: Optimal and locally optimal options</h3><p>Any locally optimal point of a convex problem is (globally) optimal. #### Proof Suppose <span class="math inline">\(x\)</span> is locally optimal, but there exists a feasible <span class="math inline">\(y\)</span> with <span class="math inline">\(f_0(y)&lt;f_0(x)\)</span>, for <span class="math inline">\(z\)</span> in the small neighbour of <span class="math inline">\(x\)</span>, contradiction must exist</p><h3 id="theorem">Theorem</h3><p><span class="math inline">\(x\)</span> is optimal if and only if it is feasible and <span class="math display">\[\nabla{}f_0(x)^T(y-x)\geq0\quad\text{for all feasible }y\]</span></p><h4 id="proof">Proof</h4><p><span class="math display">\[f_0(y)\geq{}f_0(x)+\nabla{}f_0(x)^T(y-x)\geq{}f_0(x)\]</span></p><hr /><p><span class="math display">\[\text{Suppose }\exists{}y,~s.t.~\nabla{}f_0(x)^T(y-x)&lt;0\]</span> <span class="math display">\[g(t)=f(x+y(y-x)),g^{&#39;}(0)=\nabla{}f_0(x)^T(y-x)&lt;0\]</span> <span class="math display">\[\exists{}\bar{t},g(\bar{t})&lt;g(0)=f_0(x)\]</span></p><p>Also, we can view this with Taylor expansion</p><h3 id="equivalent-convex-problems">Equivalent convex problems</h3><h4 id="eliminating-equality-constrains">Eliminating equality constrains</h4><p><span class="math display">\[Ax=b\rightarrow{}x=Fz+x_0~\text{for some }z\]</span></p><h4 id="introducing-equality-constraints">Introducing equality constraints</h4><p><span class="math display">\[y_i=A_ix+b\]</span></p><h4 id="introducing-slack-variables">Introducing slack variables</h4><p><span class="math display">\[a_i^Tx\leq{}b_i\rightarrow{}a_i^Tx+s_i=b_i\land{}s_i\geq0\]</span></p><h2 id="quasiconvex-optimization">Quasiconvex optimization</h2><p>If <span class="math inline">\(f_0\)</span> is quasiconvex, there exists a family of functions <span class="math inline">\(\phi_t\)</span> such that:</p><ul><li><span class="math inline">\(\phi_t(x)\)</span> is convex in <span class="math inline">\(x\)</span> for fixed <span class="math inline">\(t\)</span></li><li>t-sublevel set of <span class="math inline">\(f_0\)</span> is 0-sublevel set of <span class="math inline">\(\phi_t\)</span>, i.e. <span class="math display">\[f_0(x)\leq{}t\leftrightarrow{}\phi_t(x)\leq0\]</span></li></ul><h2 id="linear-program-lp">Linear program (LP)</h2><p><span class="math display">\[\text{minimize }c^Tx+d\]</span> <span class="math display">\[\text{subject to }Gx\leq{}h\land{}Ax=b\]</span></p><ul><li>convex problem with affine objective and constraint functions</li><li>feasible set is a polyhedron</li></ul><h3 id="linear-fractional-program">Linear fractional program</h3><p><span class="math display">\[\text{minimize }f_0(x)\]</span> <span class="math display">\[\text{subject to }Gx\leq{}h\land{}Ax=b\]</span> <span class="math display">\[f_0(x)=\frac{c^Tx+d}{c^Tx+f}, dom~f_0(x)=\{c^Tx+f&gt;0\}\]</span></p><ul><li>a quasiconvex optimization problem; can be solved by bisection</li><li>also equivalent to the LP (variables <span class="math inline">\(y\)</span>, <span class="math inline">\(z\)</span>)</li></ul><p><span class="math display">\[\text{minimize }c^Ty+dz\]</span> <span class="math display">\[\text{subject to }Gy\leq{}hz,Ay=bz,e^Ty+fz=1,z\geq0\]</span></p><h4 id="proof-1">Proof</h4><p><span class="math display">\[\forall{}x\in{}X_1,y=\frac{x}{e^Tx+f},z=\frac{1}{e^Tx+f}\rightarrow{}(y,z)\in{}X_2\rightarrow{}p_1^*\geq{}p_2^*\]</span></p><hr /><p><span class="math display">\[\forall{}(y,z)\in{}X_2, z\neq0,x=\frac{y}{z}\in{}X_1\]</span> <span class="math display">\[\forall{}(y,z)\in{}X_2, z=0,\text{Choose }x_0\in{}X_1,x_0+ty\in{}X_1(t\geq0)\]</span> <span class="math display">\[\lim_{t\rightarrow\infty}\frac{c^T(x_0+ty)+d}{e^T(x_0+ty)+f}=c^Ty,p_2^*\geq{}p_1^*\]</span></p><h2 id="quadratic-program-qp">Quadratic program (QP)</h2><p><span class="math display">\[A\in{}R^{m\times{}n},A=U\Sigma{}V^T,\Sigma=diag(\lambda_1,...,\lambda_r,0,...)\]</span> <span class="math display">\[A^\dagger=V\Sigma^\dagger{}U^T,\Sigma^\dagger=diag(1/\lambda_1,...,1/\lambda_r,0,...)\]</span></p><h2 id="quadratically-constrained-quadratic-program-qcqp">Quadratically constrained quadratic program (QCQP)</h2><p><span class="math display">\[\text{minimize }(1/2)x^TP_0x+q_0^Tx+r_0\]</span> <span class="math display">\[\text{subject to }(1/2)x^TP_ix+q_i^Tx+r_i\leq0, Ax=b\]</span></p><ul><li><span class="math inline">\(P_i\in{}S_{+}^{n}\)</span></li><li>objective and constraints are convex quadratic</li></ul><h3 id="least-squares">Least squares</h3><p><span class="math display">\[\text{minimize }||Ax-b||_2^2\]</span></p><ul><li>analytical solution <span class="math inline">\(x^\star=A^\dagger{}b\)</span></li></ul><h2 id="robust-linear-program">Robust linear program</h2><p><span class="math display">\[\text{minimize }c^Tx\]</span> <span class="math display">\[\text{subject to }prob(a_i^Tx\leq{}b_i)\geq\eta,i=1,...,m\]</span></p><h2 id="semidefinite-program-sdp">Semidefinite program (SDP)</h2><p><span class="math display">\[\text{minimize }c^Tx\]</span> <span class="math display">\[\text{subject to }x_1F_1+x_2F_2+\dots+x_nF_n+G\preceq0,Ax=b\]</span></p><ul><li>inequality constraint is called linear matrix inequality (LMI)</li><li>includes problems with multiple LMI constraints</li></ul>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Convex Optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>不可修复系统的可靠性分析</title>
      <link href="2019/03/18/%E4%B8%8D%E5%8F%AF%E4%BF%AE%E5%A4%8D%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%88%86%E6%9E%90/"/>
      <url>2019/03/18/%E4%B8%8D%E5%8F%AF%E4%BF%AE%E5%A4%8D%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="可靠性逻辑框图">可靠性逻辑框图</h2><h3 id="系统可靠性">系统可靠性</h3><ul><li>在<strong>元件故障数据和系统结构已知</strong>的情况下，预测系统的可靠性</li><li>硬件可靠性/人员操作可靠性/软件可靠性</li></ul><a id="more"></a><h3 id="系统可靠性框图">系统可靠性框图</h3><p>描述系统与其组成单元之间的<strong>故障逻辑</strong>关系，以系统工程图为基础。</p><ul><li>方框:单元或功能</li><li>逻辑关系:功能布局</li><li>连线:系统功能流程的方向</li><li>节点(节点可以在需要时才加以标注)<ul><li>输入节点:系统功能流程的起点</li><li>输出节点:系统功能流程的终点</li><li>中间节点</li></ul></li></ul><h2 id="典型不可修系统的可靠性分析">典型不可修系统的可靠性分析</h2><h3 id="可靠性分析假设">可靠性分析假设</h3><ul><li>系统及组成单元只有故障与正常两种状态</li><li>不同方框表示的不同单元的故障概率是相互独立的</li><li>不考虑输入错误引起的系统故障</li><li>假设系统的整个软件是完全可靠的</li><li>假设人员操作是完全可靠的。</li></ul><h3 id="串联系统">串联系统</h3><p><span class="math display">\[S=x_1\cap{}x_2\cap{}\dots\cap{}x_n\]</span> <span class="math display">\[\bar{S}=\bar{x}_1\cup\bar{x}_2\cup\dots\cup\bar{x}_n\]</span> <span class="math display">\[R_S(t)=\prod_{i=1}^nR_i(t)\]</span></p><ul><li>当各单元的寿命分布均为指数分布时，系统的寿命也服从指数分布</li><li>串联系统中提高可靠度最小的设备的可靠性，对系统可靠性的提高贡献最大</li></ul><h3 id="并联系统">并联系统</h3><p><span class="math display">\[S=x_1\cup{}x_2\cup{}\dots\cup{}x_n\]</span> <span class="math display">\[\bar{S}=\bar{x}_1\cap\bar{x}_2\cap\dots\cap\bar{x}_n\]</span> <span class="math display">\[R_S(t)=1-\prod_{i=1}^n(1-e^{-\lambda_it})\]</span> <span class="math display">\[MTTF_S=\sum_{i=1}^n(i\lambda)^{-1}\]</span></p><ul><li>三并联到四并联基本上可以满足要求</li><li>并联系统中提高可靠度最大的设备的可靠性，对系统可靠性的提高贡献最大</li></ul><h3 id="kn表决系统"><span class="math inline">\(k/n\)</span>表决系统</h3><p><span class="math display">\[R_S(t)=\sum_{i=0}^{n-k}C_n^i[1-R(t)]^i[R(t)]^{n-i}\]</span> <span class="math display">\[\text{For exponential distribution, }MTTF_S=\sum_{i=k}^n\frac{1}{i\lambda}\]</span></p><h3 id="储备系统">储备系统</h3><p>组成系统的各单元<strong>只有一个单元工作</strong>，当工作单元故障时，通过转换装置接到另一个单元继续工作，直到所有单元都故障时系统才故障，称为非工作贮备系统(又可称为旁联系统)</p><h4 id="卷积方法">卷积方法</h4><p><span class="math display">\[f_{12}(t)=f_1(t)*f_2(t)=\int_0^tf_2(t-t_1)f_1(t)dt_1\]</span> <span class="math inline">\(f_1(t)=\lambda_1e^{-\lambda_1t},f_2(t)=\lambda_2e^{-\lambda_2t}\)</span> <span class="math display">\[L[f_{12}(t)]=L[f_1(t)*f_2(t)]=L[f_1(t)]\cdot{}L[f_2(t)]=\frac{\lambda_1}{s+\lambda_1}\frac{\lambda_2}{s+\lambda_2}\]</span> <span class="math display">\[\Rightarrow{}f_{12}(t)=\frac{\lambda_1\lambda_2}{\lambda_1-\lambda_2}(e^{-\lambda_2t}-e^{-\lambda_1t})\]</span></p><h4 id="复合事件概率法">复合事件概率法</h4><ul><li>两设备的失效可认为是独立的</li><li>计算储备系统时需考虑两者产生的非独立性（在时间上）</li></ul><p><span class="math display">\[R_{12}(t)=R_1(t)+\int_0^tR_2(t-t_1)f_1(t_1)dt_1\]</span></p><ul><li>考虑冗余设备的备用失效 <span class="math inline">\(R_2^{-}(\cdot)\)</span></li><li>考虑不完全切换 <span class="math inline">\(R_{SW}\)</span></li></ul><p><span class="math display">\[R_{12}(t)=R_1(t)+R_{SW}\int_0^tR_2(t-t_1)R_2^{-}(t_1)f_1(t_1)dt_1\]</span></p><h2 id="网络系统">网络系统</h2><h3 id="全概率分解法分析复杂系统可靠性">全概率分解法分析复杂系统可靠性</h3><p><span class="math display">\[R_S(t)=P(S)=P(x)P(S|x)+P(\bar{x})P(S|\bar{x})\]</span></p><ul><li><span class="math inline">\(S(x)\)</span> 表示把网络 <span class="math inline">\(S\)</span> 中设备 <span class="math inline">\(x\)</span> 的两端节点合成一个节点而产生的新网络</li><li><span class="math inline">\(S(\bar{x})\)</span> 表示把网络 <span class="math inline">\(S\)</span> 中设备 <span class="math inline">\(x\)</span> 去掉(即两个端点之间不存在经由 <span class="math inline">\(x\)</span> 的联系)而产生的新网络</li></ul><p><span class="math display">\[R_S(t)=P(S)=P(x)P(S(x))+P(\bar{x})P(S(\bar{x}))\]</span></p><h4 id="选用分解弧的原则">选用分解弧的原则</h4><ul><li>对任意无向弧可以作为分解弧</li><li>与输入节点与输出节点相连的弧可以作为分解弧</li><li>对任意有向弧，其两端点的任何一个<strong>只有流入或流出</strong>的弧，可以作为分解弧，若弧的两端都有流入和流出的弧不可作为分解弧（<strong>因为不可以引入原本不存在的通路</strong>）</li></ul><h3 id="最小路集最小割集法分析系统可靠性">最小路集/最小割集法分析系统可靠性</h3><h4 id="结构函数">结构函数</h4><p><span class="math display">\[Y=\varphi(X)=\varphi(x_1,x_2,\dots,x_n)\]</span> <span class="math display">\[\bar{\varphi}(X)=1-\varphi(\overline{1-X})\]</span> <span class="math display">\[C_1(X)=\{i|x_i=1\},C_0(X)=\{i|x_i=0\}\]</span></p><ul><li>路集中任何一个设备变成失效则系统失效，此路集为最小路集</li><li>割集中任何一个设备变成成功则系统成功，此割集为最小割集</li></ul><h4 id="单调关联系统的表示">单调关联系统的表示</h4><p>设最小路集为 <span class="math inline">\(p_1,\dots,p_m\)</span>，最小割集为 <span class="math inline">\(k_1,\dots,k_m\)</span> <span class="math display">\[\varphi(x)=\bigcup_{j=1}^m\bigcap_{i\in{}p_j}x_i=\bigcap_{j=1}^l\bigcup_{i\in{}k_j}x_i\]</span></p><h3 id="最小路集最小割集求解">最小路集/最小割集求解</h3><h4 id="联络矩阵法">联络矩阵法</h4><p><span class="math display">\[C:\{C_{ij}=x\text{ if arc }x\text{ exists between }i,j\text{; }0\text{ otherwise}\}\]</span> <span class="math display">\[C^r=C\times{}C^{r-1}\]</span> 如果研究 <span class="math inline">\(I\)</span> 到 <span class="math inline">\(L\)</span> 的可靠性</p><ul><li>只需求出<span class="math inline">\(C^2,C^3,\dots,C^{n-1}\)</span>中第 <span class="math inline">\(L\)</span> 列</li><li><span class="math inline">\(C^{n-1}\)</span>只需求出第 <span class="math inline">\(I\)</span> 行</li></ul><h4 id="布尔行列式">布尔行列式</h4><ul><li>给定联络矩阵 <span class="math inline">\(C\)</span> ，令 <span class="math inline">\(D=C+I\)</span></li><li>删去输入节点列，输出节点行，得到 <span class="math inline">\(S\)</span></li><li><span class="math inline">\(|S|\)</span> 展开并且各项取正</li></ul><h4 id="最小割集">最小割集</h4><p><span class="math inline">\(S\)</span> 最小割集为 <span class="math inline">\(\bar{S}\)</span> 最小路集</p><h3 id="利用最小路集最小割集求解系统可靠度">利用最小路集/最小割集求解系统可靠度</h3><h4 id="精确解">精确解</h4><p>最小路集/最小割集一般相交（可以直接用容斥原理求解），可对其进行“不交化”，得到相互独立的最小路集/最小割集 <span class="math display">\[K_1\cup{}K_2=K_1+\bar{K}_1K_2\]</span></p><h4 id="近似解">近似解</h4><ul><li>区间估计：当设备可靠度较高，容斥原理展式的首项或前两项起主要作用</li><li>点估计</li></ul><h3 id="特殊情况三角形与星形">特殊情况：三角形与星形</h3>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reliability Engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Convex Functions</title>
      <link href="2019/03/07/Convex%20Functions/"/>
      <url>2019/03/07/Convex%20Functions/</url>
      
        <content type="html"><![CDATA[<h2 id="basic-properties-and-examples">Basic properties and examples</h2><h3 id="definition">Definition</h3><p><span class="math inline">\(f:R^n\rightarrow{}R\)</span> is convex if <strong>dom</strong><span class="math inline">\(f\)</span> is a convex set and <span class="math display">\[f(\theta{}x+(1-\theta)y)\leq\theta{}f(x)+(1-\theta)f(y)\]</span> for all <span class="math inline">\(x,y\in\)</span> <strong>dom</strong><span class="math inline">\(f\)</span>, <span class="math inline">\(0\leq\theta\leq1\)</span></p><a id="more"></a><ul><li><em>strictly convex</em> if we choose <span class="math inline">\(&lt;\)</span> instead of <span class="math inline">\(\leq\)</span></li></ul><h3 id="examples-on-r-rn-and-rmtimesn">Examples on <span class="math inline">\(R\)</span>, <span class="math inline">\(R^n\)</span> and <span class="math inline">\(R^{m\times{}n}\)</span></h3><h3 id="restriction-of-a-convex-function-to-a-line">Restriction of a convex function to a line</h3><p><span class="math inline">\(f:R^n\rightarrow{}R\)</span> is convex if and only if the function <span class="math inline">\(g:R\rightarrow{}R\)</span> <span class="math display">\[g(t)=f(x+tv), dom g=\{\}\]</span> #### Proof <span class="math display">\[\forall{}t_1,t_2,x+t_1v\in{}dom~f,x+t_2v\in{}dom~f\]</span> <span class="math display">\[g(\theta{}t_1+(1-\theta)t_2)=f(x+(\theta{}t_1+(1-\theta{})t_2)v)\]</span> <span class="math display">\[=f(\theta(x+t_1v)+(1-\theta)(x+t_2v))\]</span> <span class="math display">\[\leq{}\theta{}f(x+t_1v)+(1-\theta)f(x+t_2v)\]</span></p><hr /><p><span class="math display">\[let~x_1,x_2\in{}dom~f, de\!{}fine~x=x_1,v=x_2-x_1,g(t)=f(x+tv)\]</span> <span class="math display">\[f(\theta{}x_1+(1-\theta)x_2)=f(x_1+(1-\theta)(x_2-x_1))=g(1-\theta)\]</span> <span class="math display">\[\leq{}\theta{}g(0)+(1-\theta)g(1)=\theta{}f(x_1)+(1-\theta)f(x_2)\]</span></p><h4 id="example">Example</h4><p><span class="math inline">\(f:S^n\rightarrow{}R\)</span> with <span class="math inline">\(f(X)=\log\det{}X\)</span>, <strong>dom</strong> <span class="math inline">\(f=S^n_{++}\)</span> ### First-order condition Differentiable <span class="math inline">\(f\)</span> with convex domain is convex iff <span class="math display">\[f(y)\geq{}f(x)+\nabla{}f(x)^T(y-x)\quad\forall{}x,y\in{}dom~f\]</span> #### Proof <span class="math display">\[t&gt;0,~f(x+t(y-x))\leq{}(1-t)f(x)+tf(y)\]</span> <span class="math display">\[f(y)\geq{}f(x)+\frac{f(x+t(y-x))-f(x)}{t}\]</span> <span class="math display">\[f(y)\geq{}f(x)+f^{&#39;}(x)(y-x)\]</span></p><hr /><p><span class="math display">\[f(x)\geq{}f^{&#39;}(z)(x-z),f(y)\geq{}f^{&#39;}(z)(y-z)\]</span> <span class="math display">\[let~z=\theta{}x+(1-\theta{})y\]</span> <span class="math display">\[\theta{}f(x)+(1-\theta)f(y)\geq{}f(z)\]</span> ### Second-order condition Twice differentiable <span class="math inline">\(f\)</span> with convex domain is convex iff <span class="math display">\[\nabla^2f(x)\succeq0\quad\forall{}x\in{}dom~f\]</span> if <span class="math inline">\(\nabla^2f(x)\succ0\)</span> for all <span class="math inline">\(x\in{}dom~f\)</span>, then <span class="math inline">\(f\)</span> is strictly convex ### Epigraph and sublevel set <span class="math inline">\(\alpha\)</span>-sublevel set of <span class="math inline">\(f:R^n\rightarrow{}R\)</span> <span class="math display">\[C_\alpha=\{x\in{}dom~f|f(x)\leq\alpha\}\]</span> sublevel sets of convex functions are convex (converse is false) epigraph of <span class="math inline">\(f:R^n\rightarrow{}R\)</span> <span class="math display">\[epi~f=\{(x,t)\in{}R^{n+1}|x\in{}dom~f,f(x)\leq{}t\}\]</span> <span class="math inline">\(f\)</span> is convex iff <span class="math inline">\(epi~f\)</span> is a convex set ## Operations that preserve convexity ### Positive weighted sum &amp; composition with affine function</p><ul><li>nonnegative multiple</li><li>sum</li><li>composition with affine function</li></ul><h3 id="pointwise-maximum">Pointwise Maximum</h3><p>if <span class="math inline">\(f_1,...,f_m\)</span> are convex, then <span class="math display">\[f(x)=\max\{f_1(x),...,f_m(x)\}\]</span> is convex ### Pointwise Supremum if <span class="math inline">\(f(x,y)\)</span> is convex in <span class="math inline">\(x\)</span> for each <span class="math inline">\(y\in\mathcal{A}\)</span>, then <span class="math display">\[g(x)=\sup_{y\in\mathcal{A}}f(x,y)\]</span> is convex ### Theorem Let <span class="math inline">\(f:R^n\rightarrow{}R\)</span> convex and <span class="math inline">\(dom~f:R^n\)</span>, then <span class="math display">\[f(x)=\sup\{g(x)|g~is~af\!{}fine,g(z)\leq{}f(z),\forall{}z\}\]</span> #### Proof <span class="math inline">\(\geq\)</span>, obvious</p><hr /><p><span class="math inline">\(\leq\)</span></br> <span class="math display">\[(x,f(x))\in{}bd~epi~f\]</span> <span class="math display">\[\exists{}(a,b)\neq0~s.t.~a^Tz+bt\leq{}a^Tx+bf(x)\]</span> <span class="math display">\[a^Tz+b(f(z)+s)\leq{}a^Tx+bf(x)\]</span> <span class="math display">\[b\leq0,\text{otherwise }bs\rightarrow{}\infty\]</span> <span class="math display">\[b=0,z=x+a\rightarrow{}a=0,\text{contradiction}\]</span> <span class="math display">\[b&lt;0,s=0\rightarrow{}f(z)\geq{}f(x)+\frac{a^T(x-z)}{b}=g(z)\]</span> ### Jensen's inequality if <span class="math inline">\(f\)</span> is convex, then<span class="math display">\[f(Ez)\leq{}Ef(z)\]</span> #### Proof <span class="math display">\[Let~x_0=\int_{\Omega}x\rho{}(x)dx\]</span> <span class="math display">\[\exists{}a,b~s.t.~ax+b\leq{}f(x)~\text{and}~ax_0+b=f(x_0)\]</span> <span class="math display">\[\int_{\Omega}f(x)\rho{}(x)dx\geq{}\int_{\Omega}(ax+b)\rho(x)dx=ax_0+b=f(x_0)\]</span> ### Composition with scalar functions composition of <span class="math inline">\(g:R^n\rightarrow{}R\)</span> and <span class="math inline">\(h:R\rightarrow{}R\)</span> <span class="math display">\[f(x)=h(g(x))\]</span> <span class="math inline">\(f\)</span> is convex if</p><ul><li><span class="math inline">\(g\)</span> convex, <span class="math inline">\(h\)</span> convex, <span class="math inline">\(\tilde{h}\)</span> nondecreasing</li><li><span class="math inline">\(g\)</span> concave, <span class="math inline">\(h\)</span> convex, <span class="math inline">\(\tilde{h}\)</span> nonincreasing</li></ul><h3 id="minimization">Minimization</h3><p>if <span class="math inline">\(f(x,y)\)</span> is convex in <span class="math inline">\((x,y)\)</span> and <span class="math inline">\(C\)</span> is a convex set, then<span class="math display">\[g(x)=\inf_{y\in{}C}f(x,y)\]</span> is convex ### Perspective the perspective of a function <span class="math inline">\(f:R^n\rightarrow{}R\)</span> is the function <span class="math inline">\(g:R^n\times{}R\rightarrow{}R\)</span> <span class="math display">\[g(x,t)=tf(x/t),~dom~g=\{(x,t)|x/t\in{}dom~f,t&gt;0\}\]</span> <span class="math inline">\(g\)</span> is convex if <span class="math inline">\(f\)</span> is convex #### Proof use epi graph <span class="math display">\[(x,t,s)\in{}epi~g\]</span> <span class="math display">\[s\geq{}tf(x/t)\]</span> <span class="math display">\[s/t\geq{}f(x/t)\]</span> <span class="math display">\[(x/t,s/t)\in{}epi~f\]</span> ## Conjugate function the conjugate of a function <span class="math inline">\(f\)</span> is <span class="math display">\[f^*(y)=\sup_{x\in{}dom~f}(y^Tx-f(x))\]</span></p><ul><li><span class="math inline">\(f^*\)</span> is convex (even if <span class="math inline">\(f\)</span> is not)</li><li><span class="math inline">\(f(x)+f(y)\geq{}x^Ty\)</span></li><li><span class="math inline">\(f\)</span> is convex and closed (<span class="math inline">\(epi~f\)</span> is closed), then <span class="math inline">\(f^{**}=f\)</span></li></ul><h4 id="proof">Proof</h4><p><span class="math display">\[f(x)\geq{}x^Ty-f(y)\]</span> <span class="math display">\[f(x)\geq{}\sup_{y\in{}dom~f^*}(y^Tx-f(x))=f^{**}(x)\]</span> <span class="math display">\[epi~f\subseteq{}epi~f^{**}\]</span> <span class="math display">\[Let~(x,f^{**}(x))\notin{}epi~f\]</span> <span class="math display">\[\exists{}[a,b]\neq0,~s.t.[a,b][z-x,t-f^{**}(x)]^T\leq{}c&lt;0,\forall(z,t)\in{}epi~f\]</span> <span class="math display">\[t=f(z)+s,s\geq0\]</span> <span class="math display">\[b&lt;0,a^T(z-x)+b(f(z)-f^{**}(x)+s)\leq{}c\]</span> <span class="math display">\[\text{Define }y=-\frac{a}{b},~y^Tz-f(z)-s-y^Tx+f^{**}(x)\leq-\frac{c}{b}\]</span> <span class="math display">\[\text{Let }s=0,\text{make }\sup\]</span></p><hr /><p><span class="math display">\[b=0,Let~y\in{}dom~f^*~and~\varepsilon&gt;0\]</span> <span class="math display">\[[a+\varepsilon{}\hat{y},-\varepsilon][z-x,t-f^{**}(x)^T\]</span> <span class="math display">\[=a^T(z-x)+\varepsilon\hat{y}^T(z-x)-\varepsilon(t-f^{**}(x))\]</span> <span class="math display">\[\leq{}c+\varepsilon(f^*(\hat{y})+f^{**}(x)-\hat{y}^Tx)=\tilde{c}&lt;0\]</span> #### Example <span class="math display">\[f(X)=\log\det{}X,X\in{}S_+^n\]</span> <span class="math display">\[f^*(Y)=\sup_{X&gt;0}\{&lt;X,Y&gt;-f(X)\}\]</span> <span class="math display">\[Y\geq0,f^*(Y)=+\infty\]</span> <span class="math display">\[Y&lt;0,Y-(X^{*})^{-1}=0\rightarrow{}f^*(Y)=Tr(I)-\log\det{}Y^{-1}\]</span> <span class="math display">\[Y \ngeq \&amp;\nleq0\rightarrow{}f^*(Y)=+\infty(\exists{}u,s.t.Yu=\lambda{}u,\text{choose }X=tuu^T,t&gt;0)\]</span> ## Quasiconvex functions ### Definition <span class="math inline">\(f:R^n\rightarrow{}R\)</span> is quasiconvex if <strong>dom</strong> <span class="math inline">\(f\)</span> is convex and its sublevel sets are all convex ### Modified Jensen inequality <span class="math display">\[0\leq\theta\leq1\rightarrow{}f(\theta{}x+(1-\theta)y)\leq\max\{f(x),f(y)\}\]</span> #### Proof <span class="math display">\[\alpha=f(x)&gt;f(y)\rightarrow{}S_\alpha=\{x|f(x)\leq\alpha\}\]</span> <span class="math display">\[[x,y]\subset{}S_\alpha\rightarrow{}f([x,y])\leq\alpha\]</span> ### First-order condition Differentiable <span class="math inline">\(f\)</span> with convex domain is quasiconvex iff <span class="math display">\[f(y)\leq{}f(x)\rightarrow\triangledown{}f(x)^T(y-x)\leq0\]</span> #### Proof <span class="math display">\[g(t)=f(x+t(y-x))\rightarrow{}g^{&#39;}(0)=\triangledown{}f(x)^T(y-x)\leq0\]</span></p><hr /><p><span class="math display">\[\text{Assume } z\in[x,y],f(z)&gt;f(x)\&amp;{}f(z)&gt;f(y)\]</span> <span class="math display">\[\triangledown{}f(z)^T(x-z)\leq0~\&amp;~\triangledown{}f(z)^T(y-z)\leq0\]</span> <span class="math display">\[\triangledown{}f(z)=0\]</span> <span class="math inline">\(z_0\)</span> in the neighbour of <span class="math inline">\(z\)</span>, <span class="math inline">\(\triangledown{}f(z)\neq0,f(z_0)&gt;f(x),f(z_0)&gt;f(y)\)</span>, contradict ### Second-order condition Differentiable <span class="math inline">\(f\)</span> with convex domain is quasiconvex iff <span class="math display">\[f^{&#39;}(x)=0\rightarrow{}f^{&#39;&#39;}(x)\geq0\]</span> #### Proof <span class="math display">\[\exists{}c\in[a,b],f^{&#39;}(c)=0\land{}f^{&#39;&#39;}(c)&lt;0\]</span> <span class="math display">\[\exists{}\varepsilon{}f(c)&gt;f(c-\varepsilon),f(c)&gt;f(c+\varepsilon)\]</span> <span class="math display">\[\exists{}\delta&gt;0,f(c)-\delta&gt;f(c-\varepsilon),f(c)+\delta&gt;f(c+\varepsilon)\]</span> <span class="math display">\[c-\varepsilon,c+\varepsilon\in\{x|f(x)\leq{}f(c)-\delta\},c\notin\{x|f(x)\leq{}f(c)-\delta\}\]</span> <span class="math inline">\(\{x|f(x)\leq{}f(c)-\delta\}\)</span> is not convex, contradict</p><hr /><p><span class="math display">\[f^{&#39;}\neq0\rightarrow{}f\uparrow{}or\downarrow\rightarrow{}f\in\text{quasiconvex}\]</span> <span class="math display">\[d=\sup\{c|f^{&#39;}(c)=0\}\]</span> <span class="math display">\[\forall{}x\geq{}d,f{&#39;}(x)\geq0\rightarrow{}f(x)\geq{}f(d)\]</span> <span class="math display">\[\forall{}x\leq{}d,f{&#39;}(x)\leq0\rightarrow{}f(x)\leq{}f(d)\]</span> ## Log-concave and Log-convex functions ### Definition A positive function <span class="math inline">\(f\)</span> is log-concave if <span class="math inline">\(\log{}f\)</span> is concave<br>A positive function <span class="math inline">\(f\)</span> is log-convex if <span class="math inline">\(\log{}f\)</span> is convex</p><ul><li>powers:<span class="math inline">\(x^a\)</span> on <span class="math inline">\(R_{++}\)</span> is log-convex for <span class="math inline">\(a\leq0\)</span>, log-concave for <span class="math inline">\(a\geq0\)</span></li><li>many common probability densities are log-concave</li><li>cumulative Gaussian distribution function is log-concave</li></ul><h3 id="second-order-condition">Second-order condition</h3><p>Twice differentiable <span class="math inline">\(f\)</span> with convex domain is log-concave if and only if <span class="math display">\[\forall{}x,f(x)\triangledown^2f(x)\preceq\triangledown{}f(x)\triangledown{}f(x)^T\]</span> ### Properties</p><ul><li>product of log-concave functions is log-concave</li><li>sum of log-concave functions is not always log-concave</li><li>if <span class="math inline">\(f:R^n\times{}R^m\rightarrow{}R\)</span> is log-concave, then <span class="math display">\[g(x)=\int{}f(x,y)dy\]</span> is log-concave (not easy to show)</li><li>convolution <span class="math inline">\(f*g\)</span> of log-concave functions <span class="math inline">\(f,g\)</span> is log-concave</li></ul><p><span class="math display">\[(f*g)(x)=\int{}f(x-y)g(y)dy\]</span></p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Convex Optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基本参数与参数估计基础</title>
      <link href="2019/03/04/%E5%9F%BA%E6%9C%AC%E5%8F%82%E6%95%B0%E4%B8%8E%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1%E5%9F%BA%E7%A1%80/"/>
      <url>2019/03/04/%E5%9F%BA%E6%9C%AC%E5%8F%82%E6%95%B0%E4%B8%8E%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="基本参数">基本参数</h2><h3 id="可靠度与不可靠度">可靠度与不可靠度</h3><ul><li><span class="math inline">\(n(t)\)</span>:在<span class="math inline">\(0\sim{}t\)</span>时刻的工作时间内产品的累计失效数</li><li><span class="math inline">\(N_0\)</span>:<span class="math inline">\(t=0\)</span>时在规定条件下进行工作的产品数</li></ul><p><span class="math display">\[Reliability(t)=R(t)=\frac{N_0-n(t)}{N_0}\]</span> <span class="math display">\[Fallibility(t)=F(t)=\frac{n(t)}{N_0}\]</span></p><a id="more"></a><h3 id="失效率">失效率</h3><p><span class="math display">\[\lambda(t)=\lim_{\Delta{}t\rightarrow0}\frac{P(t&lt;T\leq{}t+\Delta{}t|T&gt;t)}{\Delta{}t}=\frac{F^{&#39;}(t)}{1-F(t)}=-\frac{R^{&#39;}(t)}{R(t)}\]</span> <span class="math display">\[\hat{\lambda}(t)=\frac{n(t+\Delta{}t)-n(t)}{\Delta{}t(N_0-n(t))}\]</span></p><ul><li>单位:<span class="math inline">\(1Fit=10^{-9}/h\)</span></li><li><span class="math inline">\(R(t)=\exp\{-\int_0^t\lambda(t)dt\}\)</span></li><li><span class="math inline">\(f(t)=\lambda(t)\exp\{-\int_0^t\lambda(t)dt\}\)</span></li></ul><h4 id="浴盆曲线">浴盆曲线</h4><ul><li>大多数产品的失效率随时间的变化曲线形似浴盆</li><li>由于产品失效机理的不同，失效率随时间的变化大致可以分为三个阶段：早期故障、偶然故障和耗损故障</li></ul><h3 id="平均寿命">平均寿命</h3><h4 id="平均故障前时间mttf-mean-time-to-failure">平均故障前时间(MTTF, Mean Time To Failure)</h4><p>设<span class="math inline">\(n\)</span>个不可修复产品在同样条件下进行试验，测得其全部故障时间为<span class="math inline">\(t_1,t_2,...,t_n\)</span>，则其平均故障前时间为: <span class="math display">\[T_{TF}=\frac{1}{n}\sum_{i=1}^nt_i\]</span></p><h4 id="平均故障间隔时间mtbf-mean-time-between-failure">平均故障间隔时间(MTBF, Mean Time Between Failure)</h4><p>设<span class="math inline">\(1\)</span>个可修复产品在使用过程中发生了<span class="math inline">\(n\)</span>次故障，每次故障修复后又重新投入使用，测得其每次工作持续时间为<span class="math inline">\(t_1,t_2,...,t_n\)</span>，则其平均故障间隔时间为： <span class="math display">\[T_{BF}=\frac{1}{n}\sum_{i=1}^nt_i\]</span></p><h4 id="平均寿命-1">平均寿命</h4><p><span class="math display">\[\theta=\int_0^\infty{}tf(t)dt=\int_0^\infty{}R(t)dt\]</span></p><h4 id="可靠寿命">可靠寿命</h4><p><span class="math display">\[t_R=R^{-1}(r)\]</span></p><h3 id="常用的可靠性定量指标">常用的可靠性定量指标</h3><h4 id="指数分布lambdaconst">指数分布:<span class="math inline">\(\lambda=const\)</span></h4><ul><li><span class="math inline">\(R(t)=\exp\{-\lambda{}t\}\)</span></li><li><span class="math inline">\(f(t)=\lambda\exp\{-\lambda{}t\}\)</span></li><li><span class="math inline">\(\theta=MTTF=\lambda^{-1}\)</span></li></ul><h3 id="常用分布">常用分布</h3><h4 id="对数正态分布">对数正态分布</h4><p><span class="math inline">\(T\)</span>的对数<span class="math inline">\(\ln{}T\)</span>服从正态分布，则<span class="math inline">\(T\)</span>服从对数正态分布，即<span class="math inline">\(X=\ln{}T\sim{}N(\mu,\sigma^2)\)</span> <span class="math display">\[f(t)=\frac{1}{\sigma{}t\sqrt{2\pi}}\exp\{-\frac{(\ln{}t-\mu)^2}{2\sigma^2}\}\]</span></p><ul><li>均值:<span class="math inline">\(E(T)=\exp\{\mu+\frac{\sigma^2}{2}\}\)</span></li><li>方差:<span class="math inline">\(D(T)=\exp\{2(\mu+\frac{\sigma^2}{2})\}(e^{\sigma^2}-1)\)</span></li></ul><h4 id="威布尔分布">威布尔分布</h4><p><span class="math display">\[f(t)=\frac{m}{t_0}(t-\gamma)^{m-1}\exp\{-(t-\gamma)\frac{m}{t_0}\}\]</span></p><ul><li>均值:<span class="math inline">\(E(T)=\gamma+t_0^{\frac{1}{m}}\Gamma(1+\frac{1}{m})\)</span></li><li>方差:<span class="math inline">\(D(T)=t_0^{\frac{2}{m}}[\Gamma(1+\frac{2}{m})-\Gamma^2(1+\frac{1}{m})]\)</span></li></ul><h2 id="参数估计基础">参数估计基础</h2><h3 id="截尾实验">截尾实验</h3><h4 id="无替换定数截尾试验">无替换定数截尾试验</h4><p>随机抽取<span class="math inline">\(n\)</span>件产品进行寿命试验，试验到出现事先指定的<span class="math inline">\(r\)</span>个产品失效停止试验。</p><ul><li>总试验时间:<span class="math display">\[T_r=\sum_{i=1}^rt_i(n-r)t_r\]</span></li><li>点估计:<span class="math inline">\(\lambda=r/T_r\)</span></li><li>区间估计:<span class="math inline">\(2\lambda{}T_r\sim{}\chi^2(2r)\)</span></li></ul><h4 id="有替换定数截尾试验">有替换定数截尾试验</h4><p>随机抽取<span class="math inline">\(n\)</span>件产品进行寿命试验，试验到规定失效数<span class="math inline">\(r\)</span>时停止试验。<span class="math inline">\(r\)</span>个失效样品的失效时间记为:<span class="math inline">\(t_1\leq{}t_2\leq\dots\leq{}t_r\)</span></p><ul><li>总试验时间:<span class="math inline">\(T_r=nt_r\)</span></li></ul><h4 id="无替换定时截尾试验">无替换定时截尾试验</h4><p>随机抽取<span class="math inline">\(n\)</span>件产品进行寿命试验，试验到出现事先规定的时间<span class="math inline">\(t_0\)</span>停止试验，共有<span class="math inline">\(r\)</span>个失效</p><ul><li>总试验时间:<span class="math display">\[T_0=\sum_{i=1}^rt_i(n-r)t_0\]</span></li><li>点估计:<span class="math inline">\(\lambda=r/T_0\)</span></li></ul><h4 id="有替换定时截尾试验">有替换定时截尾试验</h4><p>随机抽取<span class="math inline">\(n\)</span>件产品进行寿命试验，试验到出现事先规定的时间<span class="math inline">\(t_0\)</span>停止试验，共有<span class="math inline">\(r\)</span>个失效</p><ul><li>总试验时间:<span class="math inline">\(T_0=nt_0\)</span></li></ul><h3 id="贝叶斯估计简介">贝叶斯估计简介</h3><p>略</p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reliability Engineering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无限阶段折扣问题</title>
      <link href="2019/01/24/%E6%97%A0%E9%99%90%E9%98%B6%E6%AE%B5%E6%8A%98%E6%89%A3%E9%97%AE%E9%A2%98/"/>
      <url>2019/01/24/%E6%97%A0%E9%99%90%E9%98%B6%E6%AE%B5%E6%8A%98%E6%89%A3%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h2 id="引言成本总和的最小化">引言——成本总和的最小化</h2><h3 id="无限阶段问题的成本总和">无限阶段问题的成本总和</h3><p>定义非时变离散时间动态系统： <span class="math display">\[x_{k+1}=f(x_k,u_k,w_k)\]</span> <span class="math display">\[x_k\in{}S,u_k\in{}U(x_k)\subset{}C,w_k\sim{}P(\cdot{}|x_k,u_k)\]</span></p><a id="more"></a><p>给定初始状态<span class="math inline">\(x_0\)</span>，成本函数<span class="math inline">\(g(\cdot,\cdot,\cdot):S\times{}C\times{}D\rightarrow\mathcal{R}\)</span>和折扣因子<span class="math inline">\(\alpha\)</span>，现需要找到<span class="math inline">\(\pi=\{\mu_0,\mu_1,...\},\mu_k\in{}U(x_k)\)</span>，使得如下定义的成本最小： <span class="math display">\[J_\pi(x_0)=\lim_{N\rightarrow{}\infty}E_{w_k}\{\sum_{k=0}^{N-1}\alpha^kg(x_k,\mu_k(x_k),w_k)\}\]</span> <br/>对于所有合法的<span class="math inline">\(\pi\)</span>构成的集合记为<span class="math inline">\(\Pi\)</span>，则记最优成本函数为：</br> <span class="math display">\[J^*(x)=\min_{\pi\in\Pi}J_\pi(x)\quad{}x\in{}S\]</span> <br/>如果对于所有初始状态，其最优策略相同，则称该问题为稳定问题，该最优策略为最优稳定策略：</br> <span class="math display">\[J_\mu(x)=J^*(x)\]</span></p><h3 id="有限阶段问题的dp算法">有限阶段问题的DP算法</h3><p>对于<span class="math inline">\(N\)</span>个阶段的成本问题，DP算法为： <span class="math display">\[J_{N-k}(x)=\min_{u\in{}U(x)}E\{\alpha^{N-k}g(x,u,w)+J_{N-k+1}(f(x,u,w))\}\]</span> <span class="math display">\[J_N(x)=\alpha^NJ(x)\]</span> 重新作如下记号： <span class="math display">\[V_k(x)=\frac{J_{N-k}(x)}{\alpha^{N-k}},\quad{}V_0(x)=J(x)\]</span> <span class="math display">\[V_{k+1}(x)=\min_{u\in{}U(x)}E\{g(x,u,w)+\alpha{}V_k(f(x,u,w))\}\]</span></p><h3 id="简记与单调性">简记与单调性</h3><p>对于<span class="math inline">\(J:S\rightarrow\mathcal{R}\)</span>，采用<span class="math inline">\(TJ\)</span>记对<span class="math inline">\(J\)</span>应用DP算法： <span class="math display">\[(TJ)(x)=\min_{u\in{}U(x)}E\{g(x,u,w)+\alpha{}J(f(x,u,w))\}\]</span> 我们视<span class="math inline">\(T\)</span>为<span class="math inline">\(S\)</span>上函数<span class="math inline">\(J\)</span>到<span class="math inline">\(TJ\)</span>的映射。 同样，有如下简记： <span class="math display">\[(T_\mu{}J)(x)=E\{g(x,\mu(x),w)+\alpha{}J(f(x,\mu(x),w))\}\]</span> <span class="math display">\[(T^kJ)(x)=(T(T^{k-1}J))(x),\quad{}(T^0J)(x)=J(x)\]</span></p><h4 id="引理-1.1.1-单调性引理">引理 1.1.1: 单调性引理</h4><p>对于任何函数<span class="math inline">\(J:S\rightarrow{}\mathcal{R}\)</span>和<span class="math inline">\(J^{&#39;}:S\rightarrow\mathcal{R}\)</span> <span class="math display">\[J(x)\leq{}J^{&#39;}(x)\quad{}\text{for all }x\in{}S\]</span> 对于任何稳定策略<span class="math inline">\(\mu:S\rightarrow{}C\)</span>： <span class="math display">\[(T^kJ)(x)\leq{}(T^kJ^{&#39;})(x)\quad{}\text{for all }x\in{}S,k=1,2,...,\]</span> <span class="math display">\[(T_\mu^kJ)(x)\leq{}(T_\mu^kJ^{&#39;})(x)\quad{}\text{for all }x\in{}S,k=1,2,...,\]</span></p><h4 id="引理-1.1.2">引理 1.1.2</h4><p>定义单位函数为<span class="math inline">\(e(x)\equiv1(\forall{}x\in{}S)\)</span>，则对于任何函数<span class="math inline">\(J:S\rightarrow{}\mathcal{R}\)</span>，稳定策略<span class="math inline">\(\mu:S\rightarrow{}C\)</span>，标量<span class="math inline">\(r\)</span>： <span class="math display">\[(T^k(J+re))(x)=(T^kJ)(x)+\alpha^kr\quad{}\text{for all }x\in{}S\]</span> <span class="math display">\[(T_\mu^k(J+re))(x)=(T_\mu^kJ)(x)+\alpha^kr\quad{}\text{for all }x\in{}S\]</span></p><h3 id="随机的过去依赖策略">随机的过去依赖策略</h3><h4 id="命题-1.1.1-markov策略的合理性">命题 1.1.1： Markov策略的合理性</h4><p>假设策略集合是可数的，初始状态是可数集合上的分布。则每对<span class="math inline">\((x_k,u_k)\)</span>以及与随机的过去依赖策略相对应的每阶段的期望成本，同样可以以随机Markov策略获得。</p><h2 id="有界的阶段成本的折扣问题">有界的阶段成本的折扣问题</h2><h4 id="假设d-折扣成本-有界的阶段成本">假设D： 折扣成本-有界的阶段成本</h4><p>存在标量<span class="math inline">\(M\)</span>使阶段成本<span class="math inline">\(g\)</span>满足 <span class="math display">\[|g(x,u,w)|\leq{}M,\quad\text{for all }(x,u,w)\in{}S\times{}C\times{}D\]</span></p><h4 id="命题-1.2.1-dp算法的收敛性">命题 1.2.1： DP算法的收敛性</h4><p>对于有界函数<span class="math inline">\(J:S\rightarrow{}\mathcal{R}\)</span>，最优成本函数满足： <span class="math display">\[J^*(x)=\lim_{N\rightarrow\infty}(T^NJ)(x)\quad\text{for all }x\in{}S\]</span></p><h4 id="推论-1.2.1.1">推论 1.2.1.1</h4><p>对于稳定策略<span class="math inline">\(\mu\)</span>，相关联的成本函数满足： <span class="math display">\[J_{\mu}(x)=\lim_{N\rightarrow\infty}(T_{\mu}^NJ)(x)\quad\text{for all }x\in{}S\]</span></p><h4 id="命题-1.2.2贝尔曼方程">命题 1.2.2：贝尔曼方程</h4><p>最优成本函数满足： <span class="math display">\[J^*=TJ^*\]</span> 此外，<span class="math inline">\(J^*\)</span>也是有界成本函数中满足这一方程的唯一解</p><h4 id="推论-1.2.2.1">推论 1.2.2.1</h4><p>对于稳定策略<span class="math inline">\(\mu\)</span>，相关联的成本函数满足： <span class="math display">\[J_{\mu}=T_{\mu}J_{\mu}\]</span> 此外，<span class="math inline">\(J_{\mu}\)</span>也是有界成本函数中满足这一方程的唯一解</p><h4 id="命题-1.2.3最优的充要条件">命题 1.2.3：最优的充要条件</h4><p>稳定策略<span class="math inline">\(\mu\)</span>是最优的当且仅当对于<span class="math inline">\(\forall{}x\in{}S\)</span>，<span class="math inline">\(\mu(x)\)</span>取得了贝尔曼方程的最小值，即： <span class="math display">\[TJ^*=T_{\mu}J^*\]</span></p><h4 id="命题-1.2.4">命题 1.2.4</h4><p>对于任意两个有界函数<span class="math inline">\(J:S\rightarrow{}\mathcal{R},J^{&#39;}:S\rightarrow{}\mathcal{R}\)</span>，有： <span class="math display">\[(\forall{}k)~\max_{x\in{}S}|(T^kJ(x)-(T^kJ^{&#39;})(x))|\leq\alpha^k\max_{x\in{}S}|J(x)-J^{&#39;}(x)|\]</span></p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dynamic Programming </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>$\rm \LaTeX$ Manual</title>
      <link href="2019/01/22/Latex%20Manual/"/>
      <url>2019/01/22/Latex%20Manual/</url>
      
        <content type="html"><![CDATA[<h2 id="text">Text</h2><a id="more"></a><h2 id="figure">Figure</h2><h3 id="two-column-figure">Two Column Figure</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[htbp]</span><br><span class="line">    <span class="keyword">\begin</span>&#123;minipage&#125;[t]&#123;0.5<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">        <span class="keyword">\includegraphics</span>[]&#123;&#125;</span><br><span class="line">    <span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line">    <span class="keyword">\begin</span>&#123;minipage&#125;[t]&#123;0.5<span class="keyword">\linewidth</span>&#125;</span><br><span class="line">        <span class="keyword">\includegraphics</span>[]&#123;&#125;</span><br><span class="line">    <span class="keyword">\end</span>&#123;minipage&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure><h2 id="table">Table</h2><h3 id="cross-row-table">Cross Row Table</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>&#123;multirow&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;table&#125;[htbp]</span><br><span class="line">    <span class="keyword">\centering</span></span><br><span class="line">    <span class="keyword">\begin</span>&#123;tabular&#125;&#123;|c|c|&#125;</span><br><span class="line">        <span class="keyword">\hline</span></span><br><span class="line">        <span class="keyword">\multirow</span>&#123;2&#125;&#123;*&#125;&#123;Cross It&#125;<span class="built_in">&amp;</span>N<span class="keyword">\\</span></span><br><span class="line">        <span class="built_in">&amp;</span>N<span class="keyword">\\</span></span><br><span class="line">        <span class="keyword">\hline</span></span><br><span class="line">    <span class="keyword">\end</span>&#123;tabular&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;table&#125;</span><br></pre></td></tr></table></figure><h3 id="newline-in-table">Newline in Table</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>&#123;makecell&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;table&#125;[htbp]</span><br><span class="line">    <span class="keyword">\centering</span></span><br><span class="line">    <span class="keyword">\begin</span>&#123;tabular&#125;&#123;c&#125;</span><br><span class="line">    <span class="keyword">\hline</span></span><br><span class="line">    <span class="keyword">\makecell</span>&#123;First Line<span class="keyword">\\</span>Second Line&#125;<span class="keyword">\\</span></span><br><span class="line">    <span class="keyword">\hline</span></span><br><span class="line">    <span class="keyword">\end</span>&#123;tabular&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;table&#125;</span><br></pre></td></tr></table></figure><h2 id="equation">Equation</h2><h3 id="un-italic">Un-Italic</h3><table><thead><tr class="header"><th style="text-align: center;">Code</th><th style="text-align: center;">Display</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><code>$x+y$</code></td><td style="text-align: center;"><span class="math inline">\(x+y\)</span></td></tr><tr class="even"><td style="text-align: center;"><code>$\rm x+y$</code></td><td style="text-align: center;"><span class="math inline">\(\rm x+y\)</span></td></tr><tr class="odd"><td style="text-align: center;"><code>$\text&#123;x+y&#125;$</code></td><td style="text-align: center;"><span class="math inline">\(\text{x+y}\)</span></td></tr></tbody></table><h2 id="others">Others</h2><h3 id="two-column-document">Two Column Document</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\documentclass</span>[UTF8,a4paper,14pt,twocolumn]&#123;ctexart&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;document&#125;</span><br><span class="line">    <span class="keyword">\twocolumn</span>[</span><br><span class="line">    <span class="keyword">\begin</span>&#123;@twocolumnfalse&#125;</span><br><span class="line">        <span class="comment">% something here may cross two column</span></span><br><span class="line">    <span class="keyword">\end</span>&#123;@twocolumnfalse&#125;]</span><br><span class="line"><span class="keyword">\end</span>&#123;document&#125;</span><br></pre></td></tr></table></figure><h3 id="hyperlink">Hyperlink</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>[colorlinks,linkcolor=blue]&#123;hyperref&#125;</span><br><span class="line"><span class="comment">% include this package as the final one</span></span><br><span class="line"><span class="keyword">\href</span>&#123;<span class="link">https://www.google.com</span>&#125;&#123;Google&#125;</span><br></pre></td></tr></table></figure><h3 id="code-display">Code Display</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>&#123;listings&#125;</span><br><span class="line"><span class="keyword">\lstset</span>&#123;numbers=left,</span><br><span class="line">    numberstyle=<span class="keyword">\tiny</span>,</span><br><span class="line">    basicstyle=<span class="keyword">\small</span><span class="keyword">\ttfamily</span>,</span><br><span class="line">    stringstyle=<span class="keyword">\color</span>&#123;purple&#125;,</span><br><span class="line">    keywordstyle=<span class="keyword">\color</span>&#123;red!25!green!33!blue!100&#125;<span class="keyword">\bfseries</span>,</span><br><span class="line">    commentstyle=<span class="keyword">\color</span>&#123;olive&#125;,</span><br><span class="line">    <span class="comment">%directivestyle=\color&#123;blue&#125;,</span></span><br><span class="line">    frame=shadowbox,</span><br><span class="line">    framerule=0pt,</span><br><span class="line">    backgroundcolor=<span class="keyword">\color</span>&#123;red!0.5!green!0.5!blue!0.5!&#125;,</span><br><span class="line">    rulesepcolor=<span class="keyword">\color</span>&#123;red!20!green!20!blue!20&#125;&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;lstlisting&#125;[language=&#123;[ANSI]C&#125;]</span><br><span class="line"><span class="keyword">\end</span>&#123;lstlisting&#125;</span><br></pre></td></tr></table></figure><p>or a more convenient way:</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>&#123;listings&#125;</span><br><span class="line"><span class="keyword">\usepackage</span>[cache=false]&#123;minted&#125;</span><br><span class="line"><span class="keyword">\begin</span>&#123;minted&#125;[frame=single, tabsize=4]&#123;js&#125;<span class="string"></span></span><br><span class="line"><span class="string">print(&quot;\n&quot;)</span></span><br><span class="line"><span class="string"></span><span class="keyword">\end</span>&#123;minted&#125;</span><br><span class="line"><span class="keyword">\mintinline</span>&#123;python&#125;&#123;<span class="string">print(&quot;\n&quot;)</span>&#125;</span><br></pre></td></tr></table></figure><h3 id="tight-list">Tight List</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\providecommand</span>&#123;<span class="keyword">\tightlist</span>&#125;&#123;<span class="comment">%\setlength&#123;\itemsep&#125;&#123;0pt&#125;\setlength&#123;\parskip&#125;&#123;0pt&#125;&#125;</span></span><br></pre></td></tr></table></figure><h3 id="insert-author-info">Insert Author Info</h3><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>[colorlinks,linkcolor=blue]&#123;hyperref&#125;</span><br><span class="line"><span class="keyword">\hypersetup</span>&#123;</span><br><span class="line">    pdftitle=&#123;None&#125;,</span><br><span class="line">    pdfauthor=&#123;Nobody&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Computer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Latex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="2019/01/22/hello-world/"/>
      <url>2019/01/22/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><a id="more"></a><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> Life </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
